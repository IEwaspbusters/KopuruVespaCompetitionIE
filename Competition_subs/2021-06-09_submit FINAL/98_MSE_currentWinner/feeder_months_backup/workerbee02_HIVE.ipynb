{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nkDv5dppU6B"
   },
   "source": [
    "# HIVE algorithm **Kopuru Vespa Velutina Competition**\n",
    "\n",
    "Purpose: to process the weather data from Biscay's weather stations into a workable dataset.\n",
    "\n",
    "Output: METEO dataset *(WBds02_METEO.csv)*\n",
    "\n",
    "@authors:\n",
    "* mario.bejar@student.ie.edu\n",
    "* pedro.geirinhas@student.ie.edu\n",
    "* a.berrizbeitia@student.ie.edu\n",
    "* pcasaverde@student.ie.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../../../../Input_open_data' # use your path\n",
    "files = glob.glob(path + \"/*.csv\") #We create a list with all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We filter meteo files\n",
    "files_meteo=[]\n",
    "\n",
    "for csv in files:\n",
    "    if csv.find(\"2019\")  != -1 or csv.find(\"2018\")  != -1 or csv.find(\"2017\") != -1or  csv.find(\"2016\") != -1:\n",
    "        files_meteo.append(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe\n",
    "df = pd.concat([pd.read_csv(fp, header=None, sep=';').assign(new=os.path.basename(fp).split('.')[0]) for fp in files_meteo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=df.iloc[0], inplace=True)\n",
    "df.columns\n",
    "df.rename(columns={'ds06-2016_DÍAS DE HELADA 2016': 'new'}, inplace= True)\n",
    "df=df.loc[~df['COD.'].isin(['KOD.','COD.' ]),:].dropna(subset=['COD.']).drop(columns=[\"cota (m)\", \"SUMA\"])\n",
    "\n",
    "# Extract year from the string  \n",
    "df['year'] = df['new'].str.extract('(\\d\\d\\d\\d)', expand=True)\n",
    "\n",
    "#Función para crear codigo_merge\n",
    "def str_join(df, sep, *cols):\n",
    "    from functools import reduce\n",
    "    return reduce(lambda x, y: x.astype(str).str.cat(y.astype(str), sep=sep), \n",
    "                 [df[col] for col in cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new'] = df['new'].str.slice(10, 100) #Cleaning the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu=pd.DataFrame(df.new.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../../Input_open_data\\\\ds06-2016_DÍAS DE HELADA 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds06-2017_DÍAS DE HELADA 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds06-2018_DÍAS DE HELADA 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds06-2019_DÍAS DE HELADA 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds07-2016_DÍAS DE PRECIPITACIÓN 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds07-2017_DÍAS DE PRECIPITACIÓN 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds07-2018_DÍAS DE PRECIPITACIÓN 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds07-2019_DÍAS DE PRECIPITACIÓN 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds08-2016_DÍAS DE PRECIPITACIÓN IGUAL O SUPERIOR A 1 mm 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds08-2017_DÍAS DE PRECIPITACIÓN IGUAL O SUPERIOR A 1 mm 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds08-2018_DÍAS DE PRECIPITACIÓN IGUAL O SUPERIOR A 1 mm 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds08-2019_DÍAS DE PRECIPITACIÓN IGUAL O SUPERIOR A 1 mm 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds09-2016_HUMEDAD MEDIA DIARIA (%) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds09-2017_HUMEDAD MEDIA DIARIA (%) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds09-2018_HUMEDAD MEDIA DIARIA (%) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds09-2019_HUMEDAD MEDIA DIARIA (%) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds10-2016_IRRADIACIÓN MEDIA DIARIA (MJm2) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds10-2017_IRRADIACIÓN MEDIA DIARIA (MJm2) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds10-2018_IRRADIACIÓN MEDIA DIARIA (MJm2) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds10-2019_IRRADIACIÓN MEDIA DIARIA (MJm2) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds11-2016_MEDIA DE LAS VELOCIDADES MÁXIMAS (kmh) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds11-2017_MEDIA DE LAS VELOCIDADES MÁXIMAS (kmh) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds11-2018_MEDIA DE LAS VELOCIDADES MÁXIMAS (kmh) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds11-2019_MEDIA DE LAS VELOCIDADES MÁXIMAS (kmh) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds12-2016_NIVEL MÁXIMO (m) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds12-2017_NIVEL MÁXIMO (m).csv',\n",
       " '../../../../Input_open_data\\\\ds12-2018_NIVEL MÁXIMO (m) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds12-2019_NIVEL MÁXIMO (m) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds13-2016_NIVEL MEDIO (m) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds13-2017_NIVEL MEDIO (m) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds13-2018_NIVEL MEDIO (m) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds13-2019_NIVEL MEDIO (m) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds14-2019_NIVEL MÍNIMO (m) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds15-2016_PRECIPITACIÓN ACUMULADA (lm2) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds15-2017_PRECIPITACIÓN ACUMULADA (lm2) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds15-2018_PRECIPITACIÓN ACUMULADA (lm2) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds15-2019_PRECIPITACIÓN ACUMULADA (lm2) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds16-2016_PRECIPITACIÓN MÁXIMA EN 10 MINUTOS (lm2) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds16-2017_PRECIPITACIÓN MÁXIMA EN 10 MINUTOS (lm2) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds16-2018_PRECIPITACIÓN MÁXIMA EN 10 MINUTOS (lm2) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds16-2019_PRECIPITACIÓN MÁXIMA EN 10 MINUTOS (lm2) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds17-2016_PRECIPITACIÓN MÁXIMA EN UN DÍA (lm2) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds17-2017_PRECIPITACIÓN MÁXIMA EN UN DÍA (lm2) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds17-2018_PRECIPITACIÓN MÁXIMA EN UN DÍA (lm2) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds17-2019_PRECIPITACIÓN MÁXIMA EN UN DÍA (lm2) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds18-2016_TEMPERATURA MÁXIMA ABSOLUTA (ºC) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds18-2017_TEMPERATURA MÁXIMA ABSOLUTA (ºC) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds18-2018_TEMPERATURA MÁXIMA ABSOLUTA (ºC) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds18-2019_TEMPERATURA MÁXIMA ABSOLUTA (ºC) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds19-2016_TEMPERATURA MÁXIMA MEDIA (ºC) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds19-2017_TEMPERATURA MÁXIMA MEDIA (ºC) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds19-2018_TEMPERATURA MÁXIMA MEDIA (ºC) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds19-2019_TEMPERATURA MÁXIMA MEDIA (ºC) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds20-2016_TEMPERATURA MEDIA (ºC) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds20-2017_TEMPERATURA MEDIA (ºC) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds20-2018_TEMPERATURA MEDIA (ºC) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds20-2019_TEMPERATURA MEDIA (ºC) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds21-2016_TEMPERATURA MÍNIMA ABSOLUTA (ºC) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds21-2017_TEMPERATURA MÍNIMA ABSOLUTA (ºC) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds21-2018_TEMPERATURA MÍNIMA ABSOLUTA (ºC) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds21-2019_TEMPERATURA MÍNIMA ABSOLUTA (ºC) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds22-2016_TEMPERATURA MÍNIMA MEDIA (ºC) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds22-2017_TEMPERATURA MÍNIMA MEDIA (ºC) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds22-2018_TEMPERATURA MÍNIMA MEDIA (ºC) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds22-2019_TEMPERATURA MÍNIMA MEDIA (ºC) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds23-2016_VELOCIDAD DE LA RACHA MÁXIMA (kmh) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds23-2017_VELOCIDAD DE LA RACHA MÁXIMA (kmh) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds23-2018_VELOCIDAD DE LA RACHA MÁXIMA (kmh) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds23-2019_VELOCIDAD DE LA RACHA MÁXIMA (kmh) 2019.csv',\n",
       " '../../../../Input_open_data\\\\ds24-2016_VELOCIDAD MEDIA (kmh) 2016.csv',\n",
       " '../../../../Input_open_data\\\\ds24-2017_VELOCIDAD MEDIA (kmh) 2017.csv',\n",
       " '../../../../Input_open_data\\\\ds24-2018_VELOCIDAD MEDIA (kmh) 2018.csv',\n",
       " '../../../../Input_open_data\\\\ds24-2019_VELOCIDAD MEDIA (kmh) 2019.csv']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD.</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>ENE</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>ABR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AGO</th>\n",
       "      <th>SET</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DIC</th>\n",
       "      <th>new</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [COD., ESTACION, ENE, FEB, MAR, ABR, MAY, JUN, JUL, AGO, SET, OCT, NOV, DIC, new, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['new'].str.contains('PRECIPITACIÓN'))&(df['new'].str.contains('10 MINUTOS')),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD.</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>ENE</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>ABR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AGO</th>\n",
       "      <th>SET</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DIC</th>\n",
       "      <th>new</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C035</td>\n",
       "      <td>Altube</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C001</td>\n",
       "      <td>Arkaute</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>10.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C034</td>\n",
       "      <td>Espejo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C0AA</td>\n",
       "      <td>Etura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C040</td>\n",
       "      <td>Gasteiz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.7</td>\n",
       "      <td>15.3</td>\n",
       "      <td>10.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>C0DC</td>\n",
       "      <td>Ibai Eder</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>C0EC</td>\n",
       "      <td>Lasarte</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>13.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>C043</td>\n",
       "      <td>Ordizia</td>\n",
       "      <td>3.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>C007</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>C029</td>\n",
       "      <td>Zizurkil</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>17.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>IRRADIACIÓN MEDIA DIARIA (MJm2) 2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD.     ESTACION  ENE   FEB   MAR   ABR   MAY   JUN   JUL   AGO   SET  \\\n",
       "3   C035       Altube  4.5   6.8   8.0  14.5  19.4  20.9  19.7  21.0  15.4   \n",
       "4   C001      Arkaute  5.0   7.1   9.7  15.2  19.2  21.3  21.9  21.8  15.1   \n",
       "5   C034       Espejo  NaN   NaN   7.0  14.5  19.0  21.3  22.0  21.1  14.9   \n",
       "6   C0AA        Etura  NaN   7.6  10.0  15.0  19.5  21.1  21.8  21.6  15.4   \n",
       "7   C040      Gasteiz  5.0   7.3  10.0  15.4  20.5  21.1  21.6  21.7  15.3   \n",
       "..   ...          ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "33  C0DC    Ibai Eder  3.0   9.4  13.5  14.2  17.7  20.6  18.8  16.7  15.0   \n",
       "34  C0EC      Lasarte  3.7   9.9  13.4  14.5  17.7  18.7  16.8  16.3  14.1   \n",
       "35  C043      Ordizia  3.7  10.2  13.8  15.1  17.9  21.0  19.3  17.4  15.0   \n",
       "36  C007  Santa Clara  3.8  10.9  14.5  15.0  19.0  19.9  18.8  17.1  16.2   \n",
       "37  C029     Zizurkil  3.9  10.3  13.2  14.7  17.1  18.5  17.3  15.9  14.6   \n",
       "\n",
       "     OCT  NOV  DIC                                    new  year  \n",
       "3   10.5  5.5  5.0  IRRADIACIÓN MEDIA DIARIA (MJm2) 2016  2016  \n",
       "4   10.6  5.8  4.4  IRRADIACIÓN MEDIA DIARIA (MJm2) 2016  2016  \n",
       "5   10.4  5.3  3.6  IRRADIACIÓN MEDIA DIARIA (MJm2) 2016  2016  \n",
       "6   10.4  5.4  4.3  IRRADIACIÓN MEDIA DIARIA (MJm2) 2016  2016  \n",
       "7   10.7  6.0  5.0  IRRADIACIÓN MEDIA DIARIA (MJm2) 2016  2016  \n",
       "..   ...  ...  ...                                    ...   ...  \n",
       "33   9.1  3.7  3.7  IRRADIACIÓN MEDIA DIARIA (MJm2) 2019  2019  \n",
       "34   8.7  3.6  4.1  IRRADIACIÓN MEDIA DIARIA (MJm2) 2019  2019  \n",
       "35   8.9  3.9  4.3  IRRADIACIÓN MEDIA DIARIA (MJm2) 2019  2019  \n",
       "36   8.4  3.7  4.3  IRRADIACIÓN MEDIA DIARIA (MJm2) 2019  2019  \n",
       "37   9.1  3.9  4.3  IRRADIACIÓN MEDIA DIARIA (MJm2) 2019  2019  \n",
       "\n",
       "[147 rows x 16 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['new'].str.contains('IRRADIACIÓN')),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Freeze----------------------------\n",
    "freez= df[df['new'].str.contains(\"HELADA\")].drop(columns=['new'])\n",
    "freez=pd.melt(freez, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='freez')\n",
    "\n",
    "freez['merge_cod'] = str_join(freez,'_' , 'COD.','ESTACION','year', 'month')\n",
    "freez.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "cols= ['merge_cod', 'freez']\n",
    "freez= freez.reindex(columns= cols)\n",
    "\n",
    "## Rain ------------------------------\n",
    "rain= df[df['new'].str.contains(\"DÍAS DE PRECIPITACIÓN 20\")].drop(columns=['new'])\n",
    "rain=pd.melt(rain, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='rain')\n",
    "\n",
    "rain['merge_cod'] = str_join(rain,'_' , 'COD.','ESTACION','year', 'month')\n",
    "\n",
    "rain.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "## rain_1mm----------------------------\n",
    "\n",
    "rain_1mm= df[df['new'].str.contains(\"DÍAS DE PRECIPITACIÓN IGUAL O SUPERIOR\")].drop(columns=['new'])\n",
    "rain_1mm=pd.melt(rain_1mm, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='rain_1mm')\n",
    "\n",
    "rain_1mm['merge_cod'] = str_join(rain_1mm,'_' , 'COD.','ESTACION','year', 'month')\n",
    "rain_1mm.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "## rain_cum------------------------------\n",
    "rain_cum= df[df['new'].str.contains(\"PRECIPITACIÓN ACUMULADA\")].drop(columns=['new'])\n",
    "rain_cum=pd.melt(rain_cum, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='rain_cum')\n",
    "\n",
    "rain_cum['merge_cod'] = str_join(rain_cum,'_' , 'COD.','ESTACION','year', 'month')\n",
    "rain_cum.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## rain_max_10------------------------------\n",
    "rain_max_10= df[df['new'].str.contains(\"PRECIPITACIÓN MÁXIMA EN 10 MINUTOS\")].drop(columns=['new'])\n",
    "rain_max_10=pd.melt(rain_max_10, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='rain_max_10')\n",
    "\n",
    "rain_max_10['merge_cod'] = str_join(rain_max_10,'_' , 'COD.','ESTACION','year', 'month')\n",
    "rain_max_10.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## rain_max_day------------------------------\n",
    "rain_max_day= df[df['new'].str.contains(\"PRECIPITACIÓN MÁXIMA EN UN DÍA\")].drop(columns=['new'])\n",
    "rain_max_day=pd.melt(rain_max_day, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='rain_max_day')\n",
    "\n",
    "rain_max_day['merge_cod'] = str_join(rain_max_day,'_' , 'COD.','ESTACION','year', 'month')\n",
    "rain_max_day.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "## hum------------------------------\n",
    "hum= df[df['new'].str.contains(\"HUMEDAD MEDIA\")].drop(columns=['new'])\n",
    "hum=pd.melt(hum, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='hum')\n",
    "\n",
    "hum['merge_cod'] = str_join(hum,'_' , 'COD.','ESTACION','year', 'month')\n",
    "hum.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## sun------------------------------\n",
    "sun= df[df['new'].str.contains(\"IRRADIACIÓN MEDIA\")].drop(columns=['new'])\n",
    "sun=pd.melt(sun, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='sun')\n",
    "\n",
    "sun['merge_cod'] = str_join(sun,'_' , 'COD.','ESTACION','year', 'month')\n",
    "sun.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## lev_max------------------------------\n",
    "lev_max= df[df['new'].str.contains(\"NIVEL MÁXIMO\")].drop(columns=['new'])\n",
    "lev_max=pd.melt(lev_max, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='lev_max')\n",
    "\n",
    "lev_max['merge_cod'] = str_join(lev_max,'_' , 'COD.','ESTACION','year', 'month')\n",
    "lev_max.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "\n",
    "## lev_mid------------------------------\n",
    "lev_mid= df[df['new'].str.contains(\"NIVEL MEDIO\")].drop(columns=['new'])\n",
    "lev_mid=pd.melt(lev_mid, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='lev_mid')\n",
    "\n",
    "lev_mid['merge_cod'] = str_join(lev_mid,'_' , 'COD.','ESTACION','year', 'month')\n",
    "lev_mid.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "## lev_min------------------------------only 2019\n",
    "lev_min= df[df['new'].str.contains(\"NIVEL MÍNIMO\")].drop(columns=['new'])\n",
    "lev_min=pd.melt(lev_min, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='lev_min')\n",
    "\n",
    "lev_min['merge_cod'] = str_join(lev_min,'_' , 'COD.','ESTACION','year', 'month')\n",
    "lev_min.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## temp_max_abs------------------------------\n",
    "temp_max_abs= df[df['new'].str.contains(\"TEMPERATURA MÁXIMA ABSOLUTA\")].drop(columns=['new'])\n",
    "temp_max_abs=pd.melt(temp_max_abs, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='temp_max_abs')\n",
    "\n",
    "temp_max_abs['merge_cod'] = str_join(temp_max_abs,'_' , 'COD.','ESTACION','year', 'month')\n",
    "temp_max_abs.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## temp_max_avg-----------------------------\n",
    "temp_max_avg= df[df['new'].str.contains(\"TEMPERATURA MÁXIMA MEDIA\")].drop(columns=['new'])\n",
    "temp_max_avg=pd.melt(temp_max_avg, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='temp_max_avg')\n",
    "\n",
    "temp_max_avg['merge_cod'] = str_join(temp_max_avg,'_' , 'COD.','ESTACION','year', 'month')\n",
    "temp_max_avg.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "## temp_avg----------------------------\n",
    "temp_avg= df[df['new'].str.contains(\"TEMPERATURA MEDIA\")].drop(columns=['new'])\n",
    "temp_avg=pd.melt(temp_avg, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='temp_avg')\n",
    "\n",
    "temp_avg['merge_cod'] = str_join(temp_avg,'_' , 'COD.','ESTACION','year', 'month')\n",
    "temp_avg.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## temp_min_abs----------------------------\n",
    "temp_min_abs= df[df['new'].str.contains(\"TEMPERATURA MÍNIMA ABSOLUTA\")].drop(columns=['new'])\n",
    "temp_min_abs=pd.melt(temp_min_abs, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='temp_min_abs')\n",
    "\n",
    "temp_min_abs['merge_cod'] = str_join(temp_min_abs,'_' , 'COD.','ESTACION','year', 'month')\n",
    "temp_min_abs.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## wind_max----------------------------\n",
    "wind_max= df[df['new'].str.contains(\"VELOCIDAD DE LA RACHA MÁXIMA\")].drop(columns=['new'])\n",
    "wind_max=pd.melt(wind_max, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='wind_max')\n",
    "\n",
    "wind_max['merge_cod'] = str_join(wind_max,'_' , 'COD.','ESTACION','year', 'month')\n",
    "wind_max.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "\n",
    "## wind_avg----------------------------\n",
    "wind_avg= df[df['new'].str.contains(\"VELOCIDAD MEDIA\")].drop(columns=['new'])\n",
    "wind_avg=pd.melt(wind_avg, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='wind_avg')\n",
    "\n",
    "wind_avg['merge_cod'] = str_join(wind_avg,'_' , 'COD.','ESTACION','year', 'month')\n",
    "wind_avg.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "## wind_max_avg----------------------------\n",
    "wind_max_avg= df[df['new'].str.contains(\"MEDIA DE LAS VELOCIDADES MÁXIMAS\")].drop(columns=['new'])\n",
    "wind_max_avg=pd.melt(wind_max_avg, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='wind_max_avg')\n",
    "\n",
    "wind_max_avg['merge_cod'] = str_join(wind_max_avg,'_' , 'COD.','ESTACION','year', 'month')\n",
    "wind_max_avg.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n",
    "\n",
    "## temp_min_avg\n",
    "\n",
    "temp_min_avg= df[df['new'].str.contains(\"TEMPERATURA MÍNIMA MEDIA\")].drop(columns=['new'])\n",
    "temp_min_avg=pd.melt(temp_min_avg, id_vars=['COD.', 'ESTACION', 'year'], value_vars=['ENE', 'FEB', 'MAR', 'ABR', 'MAY',\n",
    "                                                                'JUN', 'JUL', 'AGO', 'SET', 'OCT', 'NOV','DIC'], var_name='month',value_name='temp_min_avg')\n",
    "\n",
    "temp_min_avg['merge_cod'] = str_join(temp_min_avg,'_' , 'COD.','ESTACION','year', 'month')\n",
    "temp_min_avg.drop(columns= ['COD.', 'ESTACION', 'year', 'month'], inplace= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data= freez.merge(hum, on='merge_cod', how= 'outer' ).merge(\n",
    "    lev_max, on='merge_cod', how= 'outer' ).merge(\n",
    "    lev_mid, on='merge_cod', how= 'outer' ).merge(\n",
    "    lev_min, on='merge_cod', how= 'outer' ).merge(\n",
    "    rain, on='merge_cod', how= 'outer' ).merge(\n",
    "    rain_1mm, on='merge_cod', how= 'outer' ).merge(\n",
    "    rain_cum, on='merge_cod', how= 'outer' ).merge(\n",
    "    rain_max_10, on='merge_cod', how= 'outer' ).merge(\n",
    "    rain_max_day, on='merge_cod', how= 'outer' ).merge(\n",
    "    sun, on='merge_cod', how= 'outer' ).merge(\n",
    "    temp_avg, on='merge_cod', how= 'outer' ).merge(\n",
    "    temp_max_abs, on='merge_cod', how= 'outer' ).merge(\n",
    "    temp_max_avg, on='merge_cod', how= 'outer' ).merge(\n",
    "    temp_min_abs, on='merge_cod', how= 'outer' ).merge(\n",
    "    wind_avg, on='merge_cod', how= 'outer' ).merge(\n",
    "    wind_max, on='merge_cod', how= 'outer' ).merge(\n",
    "    wind_max_avg, on='merge_cod', how= 'outer' ).merge(\n",
    "    temp_min_avg, on='merge_cod', how= 'outer' )\n",
    "\n",
    "m_data['code_merge']= m_data['merge_cod']\n",
    "m_data[['codigo',' estacion','year', 'month']]= m_data.merge_cod.str.split(\"_\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5040, 25)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merge_cod          0\n",
       " estacion          0\n",
       "codigo             0\n",
       "code_merge         0\n",
       "year               0\n",
       "month              0\n",
       "freez            176\n",
       "temp_max_abs     176\n",
       "temp_min_abs     178\n",
       "temp_min_avg     190\n",
       "temp_max_avg     190\n",
       "temp_avg         190\n",
       "hum              339\n",
       "rain_max_10      631\n",
       "rain_cum         631\n",
       "rain             631\n",
       "rain_max_day     632\n",
       "rain_1mm         635\n",
       "wind_max        2276\n",
       "wind_max_avg    2308\n",
       "wind_avg        2321\n",
       "lev_max         2725\n",
       "lev_mid         2733\n",
       "sun             3329\n",
       "lev_min         4445\n",
       "dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_data.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_data.to_csv (r'estaciones.csv', index = False, header=True)\n",
    "\n",
    "#fruta\n",
    "fruta= pd.read_csv('../../../Input_open_data/FRUTALES-DECLARADOS-KOPURU.csv', sep=';')\n",
    "#fruta.to_csv (r'fruta.csv', index = False, header=True)\n",
    "\n",
    "#met\n",
    "met= pd.read_csv('../../../Input_open_data/LOCALIZACION-ESTACIONES-METEOROLOGICAS.csv', sep=';')\n",
    "#met.to_csv (r'met.csv', index = False, header=True)\n",
    "\n",
    "#apicu\n",
    "apicu= pd.read_csv('../../../Input_open_data/APICULTURA_COLMENAS_KOPURU.csv', sep=';')\n",
    "#apicu.to_csv (r'apicu.csv', index = False, header=True)\n",
    "\n",
    "#nido\n",
    "nido=pd.read_excel('../../../Input_open_data/datos-nidos-avispa-asiatica.xlsx')\n",
    "#nido.to_csv (r'nido.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datawig import SimpleImputer\n",
    "from datawig.utils import random_split\n",
    "from sklearn.metrics import f1_score, classification_report, precision_score, recall_score, r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['merge_cod', 'freez', 'hum', 'lev_max', 'lev_mid', 'lev_min', 'rain',\n",
       "       'rain_1mm', 'rain_cum', 'rain_max_10', 'rain_max_day', 'sun',\n",
       "       'temp_avg', 'temp_max_abs', 'temp_max_avg', 'temp_min_abs', 'wind_avg',\n",
       "       'wind_max', 'wind_max_avg', 'temp_min_avg', 'code_merge', 'codigo',\n",
       "       ' estacion', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seasons= pd.read_csv('D:/Bootcamp/Data/estaciones.csv')\n",
    "seasons = m_data.copy()\n",
    "seasons.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rain----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_2, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_rain = SimpleImputer(\n",
    "input_columns=['month','hum', 'temp_avg','wind_avg', 'freez','rain_1mm','rain_cum','rain_max_10','rain_max_day'],\n",
    "output_column='rain',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_rain.fit(train_df=df_train)\n",
    "predictions_rain = imputer_rain.predict(df_test)\n",
    "\n",
    "pre_rain= predictions_rain.loc[~predictions_rain['rain'].isnull(),['rain','rain_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_rain = r2_score(pre_rain['rain'], pre_rain['rain_imputed'])\n",
    "msq_rain = mean_squared_error(pre_rain['rain'], pre_rain['rain_imputed'])\n",
    "\n",
    "seasons_3= imputer_rain.predict(seasons_2.loc[seasons_2['rain'].isnull(),:])\n",
    "del seasons_3[\"rain\"]\n",
    "seasons_3=seasons_3.rename(columns={'rain_imputed':'rain'}).append(seasons_2.loc[~seasons['rain'].isnull(),:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Impute the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ColumnOverwriteException",
     "evalue": "DataFrame contains column temp_avg_imputed_proba; remove column and try again",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mColumnOverwriteException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-255-9f36e927df9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m \u001b[0mseasons_19\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimputer_temp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseasons_18\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseasons_18\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'temp_min_avg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mseasons_19\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"temp_min_avg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[0mseasons_19\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseasons_19\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'temp_min_avg_imputed'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'temp_min_avg'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseasons_18\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mseasons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'temp_min_avg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\env\\lib\\site-packages\\datawig\\simple_imputer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data_frame, precision_threshold, imputation_suffix, score_suffix, inplace)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \"\"\"\n\u001b[0;32m    419\u001b[0m         imputations = self.imputer.predict(data_frame, precision_threshold, imputation_suffix,\n\u001b[1;32m--> 420\u001b[1;33m                                            score_suffix, inplace=inplace)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimputations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\env\\lib\\site-packages\\datawig\\imputer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data_frame, precision_threshold, imputation_suffix, score_suffix, inplace)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     raise ColumnOverwriteException(\n\u001b[0;32m    841\u001b[0m                         \"DataFrame contains column {}; remove column and try again\".format(\n\u001b[1;32m--> 842\u001b[1;33m                             imputation_proba_col))\n\u001b[0m\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                 \u001b[0mimputed_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimputed_value_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mColumnOverwriteException\u001b[0m: DataFrame contains column temp_avg_imputed_proba; remove column and try again"
     ]
    }
   ],
   "source": [
    "#Hum----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_hum = SimpleImputer(\n",
    "input_columns=['month','freez', 'temp_avg', 'rain','wind_avg','rain_1mm','rain_cum','rain_max_10','rain_max_day'],\n",
    "output_column='hum',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_hum.fit(train_df=df_train)\n",
    "predictions_hum = imputer_hum.predict(df_test)\n",
    "\n",
    "pre_hum= predictions_hum.loc[~predictions_hum['hum'].isnull(),['hum','hum_imputed'] ]\n",
    "\n",
    "#Calculate f1 score\n",
    "r2_hum = r2_score(pre_hum['hum'], pre_hum['hum_imputed'])\n",
    "msq_hum = mean_squared_error(pre_hum['hum'], pre_hum['hum_imputed'])\n",
    "\n",
    "\n",
    "#completing hum data\n",
    "\n",
    "seasons_1= imputer_hum.predict(seasons.loc[seasons['hum'].isnull(),:])\n",
    "del seasons_1[\"hum\"]\n",
    "seasons_1=seasons_1.rename(columns={'hum_imputed':'hum'}).append(seasons.loc[~seasons['hum'].isnull(),:])\n",
    "\n",
    "\n",
    "#Freez----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test= random_split(seasons_1, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_freez = SimpleImputer(\n",
    "input_columns=['month','hum', 'temp_avg', 'rain','wind_avg'],\n",
    "output_column='freez',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_freez.fit(train_df=df_train)\n",
    "predictions_freez = imputer_freez.predict(df_test)\n",
    "\n",
    "pre_freez= predictions_freez.loc[~predictions_freez['freez'].isnull(),['freez','freez_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_freez = r2_score(pre_freez['freez'], pre_freez['freez_imputed'])\n",
    "msq_freez = mean_squared_error(pre_freez['freez'], pre_freez['freez_imputed'])\n",
    "\n",
    "seasons_2= imputer_freez.predict(seasons_1.loc[seasons_1['freez'].isnull(),:])\n",
    "del seasons_2[\"freez\"]\n",
    "seasons_2=seasons_2.rename(columns={'freez_imputed':'freez'}).append(seasons_1.loc[~seasons['freez'].isnull(),:])\n",
    "\n",
    "\n",
    "\n",
    "#Rain----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_2, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_rain = SimpleImputer(\n",
    "input_columns=['month','hum', 'temp_avg','wind_avg', 'freez','rain_1mm','rain_cum','rain_max_10','rain_max_day'],\n",
    "output_column='rain',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_rain.fit(train_df=df_train)\n",
    "predictions_rain = imputer_rain.predict(df_test)\n",
    "\n",
    "pre_rain= predictions_rain.loc[~predictions_rain['rain'].isnull(),['rain','rain_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_rain = r2_score(pre_rain['rain'], pre_rain['rain_imputed'])\n",
    "msq_rain = mean_squared_error(pre_rain['rain'], pre_rain['rain_imputed'])\n",
    "\n",
    "seasons_3= imputer_rain.predict(seasons_2.loc[seasons_2['rain'].isnull(),:])\n",
    "del seasons_3[\"rain\"]\n",
    "seasons_3=seasons_3.rename(columns={'rain_imputed':'rain'}).append(seasons_2.loc[~seasons['rain'].isnull(),:])\n",
    "\n",
    "\n",
    "#lev_max----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_3, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_lev_max = SimpleImputer(\n",
    "input_columns=['hum', 'temp_avg','wind_avg', 'rain', 'freez','sun','lev_mid','lev_min'],\n",
    "output_column='lev_max',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_lev_max.fit(train_df=df_train)\n",
    "predictions_lev_max = imputer_lev_max.predict(df_test)\n",
    "\n",
    "pre_lev_max= predictions_lev_max.loc[~predictions_lev_max['lev_max'].isnull(),['lev_max','lev_max_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_lev_max = r2_score(pre_lev_max['lev_max'], pre_lev_max['lev_max_imputed'])\n",
    "msq_lev_max = mean_squared_error(pre_lev_max['lev_max'], pre_lev_max['lev_max_imputed'])\n",
    "\n",
    "seasons_4= imputer_lev_max.predict(seasons_3.loc[seasons_3['lev_max'].isnull(),:])\n",
    "del seasons_4[\"lev_max\"]\n",
    "seasons_4=seasons_4.rename(columns={'lev_max_imputed':'lev_max'}).append(seasons_3.loc[~seasons['lev_max'].isnull(),:])\n",
    "\n",
    "\n",
    "#lev_mid----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_4, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_lev_mid = SimpleImputer(\n",
    "input_columns=['hum', 'temp_avg','wind_avg', 'rain', 'freez','sun','lev_min','lev_max'],\n",
    "output_column='lev_mid',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_lev_mid.fit(train_df=df_train)\n",
    "predictions_lev_mid = imputer_lev_mid.predict(df_test)\n",
    "\n",
    "pre_lev_mid= predictions_lev_mid.loc[~predictions_lev_mid['lev_mid'].isnull(),['lev_mid','lev_mid_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_lev_mid = r2_score(pre_lev_mid['lev_mid'], pre_lev_mid['lev_mid_imputed'])\n",
    "msq_lev_mid = mean_squared_error(pre_lev_mid['lev_mid'], pre_lev_mid['lev_mid_imputed'])\n",
    "\n",
    "seasons_5= imputer_lev_mid.predict(seasons_4.loc[seasons_4['lev_mid'].isnull(),:])\n",
    "del seasons_5[\"lev_mid\"]\n",
    "seasons_5=seasons_5.rename(columns={'lev_mid_imputed':'lev_mid'}).append(seasons_4.loc[~seasons['lev_mid'].isnull(),:])\n",
    "\n",
    "\n",
    "\n",
    "#lev_min----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_5, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_lev_min = SimpleImputer(\n",
    "input_columns=['hum', 'temp_avg','wind_avg', 'rain', 'freez','sun','lev_mid','lev_max'],\n",
    "output_column='lev_min',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_lev_min.fit(train_df=df_train)\n",
    "predictions_lev_min = imputer_lev_min.predict(df_test)\n",
    "\n",
    "pre_lev_min= predictions_lev_min.loc[~predictions_lev_min['lev_min'].isnull(),['lev_min','lev_min_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_lev_min = r2_score(pre_lev_min['lev_min'], pre_lev_min['lev_min_imputed'])\n",
    "msq_lev_min = mean_squared_error(pre_lev_min['lev_min'], pre_lev_min['lev_min_imputed'])\n",
    "\n",
    "seasons_6= imputer_lev_min.predict(seasons_5.loc[seasons_5['lev_min'].isnull(),:])\n",
    "del seasons_6[\"lev_min\"]\n",
    "seasons_6=seasons_6.rename(columns={'lev_min_imputed':'lev_min'}).append(seasons_5.loc[~seasons['lev_min'].isnull(),:])\n",
    "\n",
    "\n",
    "#rain_1mm----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_6, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_rain_1mmn = SimpleImputer(\n",
    "input_columns=['hum', 'temp_avg','wind_avg', 'rain', 'freez','sun','rain_cum','rain_max_10','rain_max_day'],\n",
    "output_column='rain_1mm',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_rain_1mmn.fit(train_df=df_train)\n",
    "predictions_rain_1mm = imputer_rain_1mmn.predict(df_test)\n",
    "\n",
    "pre_rain_1mm= predictions_rain_1mm.loc[~predictions_rain_1mm['rain_1mm'].isnull(),['rain_1mm','rain_1mm_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_rain_1mm = r2_score(pre_rain_1mm['rain_1mm'], pre_rain_1mm['rain_1mm_imputed'])\n",
    "msq_rain_1mm = mean_squared_error(pre_rain_1mm['rain_1mm'], pre_rain_1mm['rain_1mm_imputed'])\n",
    "\n",
    "seasons_7= imputer_rain_1mmn.predict(seasons_6.loc[seasons_6['rain_1mm'].isnull(),:])\n",
    "del seasons_7[\"rain_1mm\"]\n",
    "seasons_7=seasons_7.rename(columns={'rain_1mm_imputed':'rain_1mm'}).append(seasons_6.loc[~seasons['rain_1mm'].isnull(),:])\n",
    "\n",
    "\n",
    "#rain_cum ----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_7, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_rain_cum  = SimpleImputer(\n",
    "input_columns=['hum', 'temp_avg','wind_avg', 'freez','sun','rain_1mm','rain_max_10','rain_max_day','lev_max','lev_mid','lev_min'],\n",
    "output_column='rain_cum',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_rain_cum.fit(train_df=df_train)\n",
    "predictions_rain_cum  = imputer_rain_cum.predict(df_test)\n",
    "\n",
    "pre_rain_cum = predictions_rain_cum.loc[~predictions_rain_cum ['rain_cum'].isnull(),['rain_cum','rain_cum_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_rain_cum = r2_score(pre_rain_cum['rain_cum'], pre_rain_cum['rain_cum_imputed'])\n",
    "msq_rain_cum = mean_squared_error(pre_rain_cum['rain_cum'], pre_rain_cum['rain_cum_imputed'])\n",
    "\n",
    "seasons_8= imputer_rain_cum.predict(seasons_7.loc[seasons_7['rain_cum'].isnull(),:])\n",
    "del seasons_8[\"rain_cum\"]\n",
    "seasons_8=seasons_8.rename(columns={'rain_cum_imputed':'rain_cum'}).append(seasons_7.loc[~seasons['rain_cum'].isnull(),:])\n",
    "\n",
    "#rain_max_10----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_8, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_rain_max_10 = SimpleImputer(\n",
    "input_columns=['hum', 'temp_avg','wind_avg', 'rain', 'freez','sun','rain_cum','rain_1mm','rain_max_day'],\n",
    "output_column='rain_max_10',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_rain_max_10.fit(train_df=df_train)\n",
    "predictions_rain_max_10 = imputer_rain_max_10.predict(df_test)\n",
    "\n",
    "pre_rain_max_10= predictions_rain_max_10.loc[~predictions_rain_max_10['rain_max_10'].isnull(),['rain_max_10','rain_max_10_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_rain_max_10 = r2_score(pre_rain_max_10['rain_max_10'], pre_rain_max_10['rain_max_10_imputed'])\n",
    "msq_rain_max_10= mean_squared_error(pre_rain_max_10['rain_max_10'], pre_rain_max_10['rain_max_10_imputed'])\n",
    "\n",
    "seasons_9= imputer_rain_max_10.predict(seasons_8.loc[seasons_8['rain_max_10'].isnull(),:])\n",
    "del seasons_9[\"rain_max_10\"]\n",
    "seasons_9=seasons_9.rename(columns={'rain_max_10_imputed':'rain_max_10'}).append(seasons_8.loc[~seasons['rain_max_10'].isnull(),:])\n",
    "\n",
    "\n",
    "#rain_max_day----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_9, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_rain_max_day = SimpleImputer(\n",
    "input_columns=['month','hum', 'temp_avg','wind_avg', 'rain', 'freez','sun','rain_cum','rain_1mm','rain_max_10'],\n",
    "output_column='rain_max_day',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_rain_max_day.fit(train_df=df_train)\n",
    "predictions_rain_max_day = imputer_rain_max_day.predict(df_test)\n",
    "\n",
    "pre_rain_max_day =predictions_rain_max_day.loc[~predictions_rain_max_day['rain_max_day'].isnull(),['rain_max_day','rain_max_day_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_rain_max_day = r2_score(pre_rain_max_day['rain_max_day'], pre_rain_max_day['rain_max_day_imputed'])\n",
    "msq_rain_max_day= mean_squared_error(pre_rain_max_day['rain_max_day'], pre_rain_max_day['rain_max_day_imputed'])\n",
    "\n",
    "seasons_10= imputer_rain_max_day.predict(seasons_9.loc[seasons_9['rain_max_day'].isnull(),:])\n",
    "del seasons_10[\"rain_max_day\"]\n",
    "seasons_10=seasons_10.rename(columns={'rain_max_day_imputed':'rain_max_day'}).append(seasons_9.loc[~seasons['rain_max_10'].isnull(),:])\n",
    "\n",
    "\n",
    "\n",
    "#temp_avg----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_10, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_temp_avg = SimpleImputer(\n",
    "input_columns=['hum','wind_avg', 'rain', 'freez','sun','temp_max_abs','temp_max_avg','temp_min_abs', 'temp_min_avg'],\n",
    "output_column='temp_avg',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_temp_avg.fit(train_df=df_train)\n",
    "predictions_temp_avg = imputer_temp_avg.predict(df_test)\n",
    "\n",
    "pre_temp_avg =predictions_temp_avg.loc[~predictions_temp_avg['temp_avg'].isnull(),['temp_avg','temp_avg_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_temp_avg = r2_score(pre_temp_avg['temp_avg'], pre_temp_avg['temp_avg_imputed'])\n",
    "msq_temp_avg= mean_squared_error(pre_temp_avg['temp_avg'], pre_temp_avg['temp_avg_imputed'])\n",
    "\n",
    "seasons_11= imputer_temp_avg.predict(seasons_10.loc[seasons_10['temp_avg'].isnull(),:])\n",
    "del seasons_11[\"temp_avg\"]\n",
    "seasons_11=seasons_11.rename(columns={'temp_avg_imputed':'temp_avg'}).append(seasons_10.loc[~seasons['temp_avg'].isnull(),:])\n",
    "\n",
    "\n",
    "\n",
    "#temp_max_abs----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_11, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_temp_max_abs = SimpleImputer(\n",
    "input_columns=['hum','wind_avg', 'rain', 'freez','sun','temp_max_avg','temp_avg','temp_min_abs'],\n",
    "output_column='temp_max_abs',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_temp_max_abs.fit(train_df=df_train)\n",
    "predictions_temp_max_abs = imputer_temp_max_abs.predict(df_test)\n",
    "\n",
    "pre_temp_max_abs=predictions_temp_max_abs.loc[~predictions_temp_max_abs['temp_max_abs'].isnull(),['temp_max_abs','temp_max_abs_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_temp_max_abs= r2_score(pre_temp_max_abs['temp_max_abs'], pre_temp_max_abs['temp_max_abs_imputed'])\n",
    "msq_temp_max_abs= mean_squared_error(pre_temp_max_abs['temp_max_abs'], pre_temp_max_abs['temp_max_abs_imputed'])\n",
    "\n",
    "seasons_12= imputer_temp_max_abs.predict(seasons_11.loc[seasons_11['temp_max_abs'].isnull(),:])\n",
    "del seasons_12[\"temp_max_abs\"]\n",
    "seasons_12=seasons_12.rename(columns={'temp_max_abs_imputed':'temp_max_abs'}).append(seasons_11.loc[~seasons['temp_max_abs'].isnull(),:])\n",
    "\n",
    "\n",
    "#temp_max_avg----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_12, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_temp_max_avg = SimpleImputer(\n",
    "input_columns=['hum','wind_avg', 'rain', 'freez','sun','temp_max_abs','temp_avg','temp_min_abs'],\n",
    "output_column='temp_max_avg',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_temp_max_avg.fit(train_df=df_train)\n",
    "predictions_temp_max_avg= imputer_temp_max_avg.predict(df_test)\n",
    "\n",
    "pre_temp_max_avg=predictions_temp_max_avg.loc[~predictions_temp_max_avg['temp_max_avg'].isnull(),['temp_max_avg','temp_max_avg_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_temp_max_avg= r2_score(pre_temp_max_avg['temp_max_avg'], pre_temp_max_avg['temp_max_avg_imputed'])\n",
    "msq_temp_max_avg= mean_squared_error(pre_temp_max_avg['temp_max_avg'], pre_temp_max_avg['temp_max_avg_imputed'])\n",
    "\n",
    "seasons_13= imputer_temp_max_avg.predict(seasons_12.loc[seasons_12['temp_max_avg'].isnull(),:])\n",
    "del seasons_13[\"temp_max_avg\"]\n",
    "seasons_13=seasons_13.rename(columns={'temp_max_avg_imputed':'temp_max_avg'}).append(seasons_12.loc[~seasons['temp_max_avg'].isnull(),:])\n",
    "\n",
    "\n",
    "#temp_min_abs----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_13, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_temp_min_abs = SimpleImputer(\n",
    "input_columns=['hum','wind_avg', 'rain', 'freez','sun','temp_max_abs','temp_avg','temp_max_avg'],\n",
    "output_column='temp_min_abs',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_temp_min_abs.fit(train_df=df_train)\n",
    "predictions_temp_min_abs= imputer_temp_min_abs.predict(df_test)\n",
    "\n",
    "pre_temp_min_abs=predictions_temp_min_abs.loc[~predictions_temp_min_abs['temp_min_abs'].isnull(),['temp_min_abs','temp_min_abs_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_temp_min_abs= r2_score(pre_temp_min_abs['temp_min_abs'], pre_temp_min_abs['temp_min_abs_imputed'])\n",
    "msq_temp_min_abs= mean_squared_error(pre_temp_min_abs['temp_min_abs'], pre_temp_min_abs['temp_min_abs_imputed'])\n",
    "\n",
    "seasons_14= imputer_temp_min_abs.predict(seasons_13.loc[seasons_13['temp_min_abs'].isnull(),:])\n",
    "del seasons_14[\"temp_min_abs\"]\n",
    "seasons_14=seasons_14.rename(columns={'temp_min_abs_imputed':'temp_min_abs'}).append(seasons_13.loc[~seasons['temp_min_abs'].isnull(),:])\n",
    "\n",
    "\n",
    "#wind_avg----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_14, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_wind_avg = SimpleImputer(\n",
    "input_columns=['hum','wind_max', 'rain', 'freez','sun','temp_avg', 'wind_max_avg'],\n",
    "output_column='wind_avg',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_wind_avg.fit(train_df=df_train)\n",
    "predictions_wind_avg= imputer_wind_avg.predict(df_test)\n",
    "\n",
    "pre_wind_avg=predictions_wind_avg.loc[~predictions_wind_avg['wind_avg'].isnull(),['wind_avg','wind_avg_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_wind_avg= r2_score(pre_wind_avg['wind_avg'], pre_wind_avg['wind_avg_imputed'])\n",
    "msq_wind_avg= mean_squared_error(pre_wind_avg['wind_avg'], pre_wind_avg['wind_avg_imputed'])\n",
    "\n",
    "seasons_15= imputer_wind_avg.predict(seasons_14.loc[seasons_14['wind_avg'].isnull(),:])\n",
    "del seasons_15[\"wind_avg\"]\n",
    "seasons_15=seasons_15.rename(columns={'wind_avg_imputed':'wind_avg'}).append(seasons_14.loc[~seasons['wind_avg'].isnull(),:])\n",
    "\n",
    "\n",
    "#wind_max----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_15, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_wind_max = SimpleImputer(\n",
    "input_columns=['hum','wind_avg', 'rain', 'freez','sun','temp_avg', 'wind_max_avg'],\n",
    "output_column='wind_max',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_wind_max.fit(train_df=df_train)\n",
    "predictions_wind_max= imputer_wind_max.predict(df_test)\n",
    "\n",
    "pre_wind_max=predictions_wind_max.loc[~predictions_wind_max['wind_max'].isnull(),['wind_max','wind_max_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_wind_max= r2_score(pre_wind_max['wind_max'], pre_wind_max['wind_max_imputed'])\n",
    "msq_wind_max= mean_squared_error(pre_wind_max['wind_max'], pre_wind_max['wind_max_imputed'])\n",
    "\n",
    "seasons_16= imputer_wind_max.predict(seasons_15.loc[seasons_15['wind_max'].isnull(),:])\n",
    "del seasons_16[\"wind_max\"]\n",
    "seasons_16=seasons_16.rename(columns={'wind_max_imputed':'wind_max'}).append(seasons_15.loc[~seasons['wind_max'].isnull(),:])\n",
    "\n",
    "\n",
    "\n",
    "#wind_max_avg----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_16, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_wind_max_avg = SimpleImputer(\n",
    "input_columns=['hum','wind_max', 'rain', 'freez','sun','temp_avg', 'wind_max_avg'],\n",
    "output_column='wind_max_avg',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_wind_max_avg.fit(train_df=df_train)\n",
    "predictions_wind_max_avg= imputer_wind_max_avg.predict(df_test)\n",
    "\n",
    "pre_wind_max_avg=predictions_wind_max_avg.loc[~predictions_wind_max_avg['wind_max_avg'].isnull(),['wind_max_avg','wind_max_avg_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_wind_max_avg= r2_score(pre_wind_max_avg['wind_max_avg'], pre_wind_max_avg['wind_max_avg_imputed'])\n",
    "msq_wind_max_avg= mean_squared_error(pre_wind_max_avg['wind_max_avg'], pre_wind_max_avg['wind_max_avg_imputed'])\n",
    "\n",
    "seasons_17= imputer_wind_max_avg.predict(seasons_16.loc[seasons_16['wind_max_avg'].isnull(),:])\n",
    "del seasons_17[\"wind_max_avg\"]\n",
    "seasons_17=seasons_17.rename(columns={'wind_max_avg_imputed':'wind_max_avg'}).append(seasons_16.loc[~seasons['wind_max_avg'].isnull(),:])\n",
    "\n",
    "\n",
    "#sun----------------------------------------------------------------------------------------\n",
    "\n",
    "df_train, df_test = random_split(seasons_17, split_ratios=[0.8, 0.2])\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer_sun= SimpleImputer(\n",
    "input_columns=['hum','wind_avg', 'rain', 'freez','sun','temp_avg'],\n",
    "output_column='sun',\n",
    "output_path = 'imputer_model'\n",
    ")\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer_sun.fit(train_df=df_train)\n",
    "predictions_sun= imputer_sun.predict(df_test)\n",
    "\n",
    "pre_sun=predictions_sun.loc[~predictions_sun['sun'].isnull(),['sun','sun_imputed'] ]\n",
    "\n",
    "#Calculate R2 & MSE\n",
    "r2_sun= r2_score(pre_sun['sun'], pre_sun['sun_imputed'])\n",
    "msq_sun= mean_squared_error(pre_sun['sun'], pre_sun['sun_imputed'])\n",
    "\n",
    "seasons_18= imputer_sun.predict(seasons_17.loc[seasons_17['sun'].isnull(),:])\n",
    "del seasons_18[\"sun\"]\n",
    "seasons_18=seasons_18.rename(columns={'sun_imputed':'sun'}).append(seasons_17.loc[~seasons['sun'].isnull(),:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['merge_cod', 'temp_min_avg', 'code_merge', 'codigo', ' estacion',\n",
       "       'year', 'month', 'hum', 'hum_imputed_proba', 'freez',\n",
       "       'freez_imputed_proba', 'rain', 'rain_imputed_proba', 'lev_max',\n",
       "       'lev_max_imputed_proba', 'lev_mid', 'lev_mid_imputed_proba', 'lev_min',\n",
       "       'lev_min_imputed_proba', 'rain_1mm', 'rain_1mm_imputed_proba',\n",
       "       'rain_cum', 'rain_cum_imputed_proba', 'rain_max_10',\n",
       "       'rain_max_10_imputed_proba', 'rain_max_day',\n",
       "       'rain_max_day_imputed_proba', 'temp_avg', 'temp_avg_imputed_proba',\n",
       "       'temp_max_abs', 'temp_max_abs_imputed_proba', 'temp_max_avg',\n",
       "       'temp_max_avg_imputed_proba', 'temp_min_abs',\n",
       "       'temp_min_abs_imputed_proba', 'wind_avg', 'wind_avg_imputed_proba',\n",
       "       'wind_max', 'wind_max_imputed_proba', 'wind_max_avg',\n",
       "       'wind_max_avg_imputed_proba', 'sun', 'sun_imputed_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data= seasons_18.loc[:,['codigo', ' estacion','year', 'month', 'hum', 'freez', 'rain', 'lev_max',\n",
    "       'lev_mid',  'lev_min','rain_1mm', 'rain_cum',  'rain_max_10','rain_max_day',\n",
    "       'temp_avg', 'temp_max_abs', 'temp_max_avg','temp_min_abs','wind_avg',\n",
    "       'wind_max', 'wind_max_avg','sun', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>estacion</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hum</th>\n",
       "      <th>freez</th>\n",
       "      <th>rain</th>\n",
       "      <th>lev_max</th>\n",
       "      <th>lev_mid</th>\n",
       "      <th>lev_min</th>\n",
       "      <th>...</th>\n",
       "      <th>rain_max_10</th>\n",
       "      <th>rain_max_day</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>temp_max_abs</th>\n",
       "      <th>temp_max_avg</th>\n",
       "      <th>temp_min_abs</th>\n",
       "      <th>wind_avg</th>\n",
       "      <th>wind_max</th>\n",
       "      <th>wind_max_avg</th>\n",
       "      <th>sun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>C0A4</td>\n",
       "      <td>Albaina</td>\n",
       "      <td>2017</td>\n",
       "      <td>ENE</td>\n",
       "      <td>83.8</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>79.2</td>\n",
       "      <td>40.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>C00B</td>\n",
       "      <td>Tobillas</td>\n",
       "      <td>2017</td>\n",
       "      <td>ENE</td>\n",
       "      <td>83.8</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>79.2</td>\n",
       "      <td>40.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>C009</td>\n",
       "      <td>Galdakao</td>\n",
       "      <td>2017</td>\n",
       "      <td>ENE</td>\n",
       "      <td>83.8</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>79.2</td>\n",
       "      <td>40.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>C0F1</td>\n",
       "      <td>Eskas</td>\n",
       "      <td>2017</td>\n",
       "      <td>ENE</td>\n",
       "      <td>83.8</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>79.2</td>\n",
       "      <td>40.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>C0A4</td>\n",
       "      <td>Albaina</td>\n",
       "      <td>2017</td>\n",
       "      <td>FEB</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>61.9</td>\n",
       "      <td>41.9</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>C0EC</td>\n",
       "      <td>Lasarte</td>\n",
       "      <td>2019</td>\n",
       "      <td>NOV</td>\n",
       "      <td>86.1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.757</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.363</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>40.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>22.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>74.9</td>\n",
       "      <td>37.8</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>C0AA</td>\n",
       "      <td>Etura</td>\n",
       "      <td>2019</td>\n",
       "      <td>DIC</td>\n",
       "      <td>86.0</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2.786</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>27.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>86.4</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>C057</td>\n",
       "      <td>Mungia</td>\n",
       "      <td>2019</td>\n",
       "      <td>DIC</td>\n",
       "      <td>78.4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5.246</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.480</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>30.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>104.4</td>\n",
       "      <td>44.7</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>C054</td>\n",
       "      <td>Otxandio</td>\n",
       "      <td>2019</td>\n",
       "      <td>DIC</td>\n",
       "      <td>85.9</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2.966</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>36.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>17.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.6</td>\n",
       "      <td>33.3</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>C0EC</td>\n",
       "      <td>Lasarte</td>\n",
       "      <td>2019</td>\n",
       "      <td>DIC</td>\n",
       "      <td>78.1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.521</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.9</td>\n",
       "      <td>10.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>80.6</td>\n",
       "      <td>39.7</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5041 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     codigo  estacion  year month   hum freez rain lev_max lev_mid lev_min  \\\n",
       "98     C0A4   Albaina  2017   ENE  83.8    15   22   0.626   0.306   0.417   \n",
       "125    C00B  Tobillas  2017   ENE  83.8    15   22   0.626   0.306   0.417   \n",
       "144    C009  Galdakao  2017   ENE  83.8    15   22   0.626   0.306   0.417   \n",
       "184    C0F1     Eskas  2017   ENE  83.8    15   22   0.626   0.306   0.417   \n",
       "507    C0A4   Albaina  2017   FEB  79.0     0    4   0.306   0.306   0.417   \n",
       "...     ...       ...   ...   ...   ...   ...  ...     ...     ...     ...   \n",
       "4487   C0EC   Lasarte  2019   NOV  86.1     0   26   2.757   1.032   0.363   \n",
       "4813   C0AA     Etura  2019   DIC  86.0    10   13   2.786   0.595   0.392   \n",
       "4859   C057    Mungia  2019   DIC  78.4     2   15   5.246   0.920   0.480   \n",
       "4866   C054  Otxandio  2019   DIC  85.9     9   13   2.966   0.320   0.120   \n",
       "4896   C0EC   Lasarte  2019   DIC  78.1     0   14   3.310   0.798   0.521   \n",
       "\n",
       "      ... rain_max_10 rain_max_day temp_avg temp_max_abs temp_max_avg  \\\n",
       "98    ...         1.7         19.8      9.2         19.8         13.4   \n",
       "125   ...         1.7         19.8      9.2         19.8         13.4   \n",
       "144   ...         1.7         19.8      9.2         19.8         13.4   \n",
       "184   ...         1.7         19.8      9.2         19.8         13.4   \n",
       "507   ...         0.3            9     14.6         20.2         14.8   \n",
       "...   ...         ...          ...      ...          ...          ...   \n",
       "4487  ...         5.1         40.9     10.6         22.3         14.1   \n",
       "4813  ...         0.9         27.7      5.9         16.4         10.7   \n",
       "4859  ...         3.6         30.9     11.3         23.4         16.6   \n",
       "4866  ...         2.1         36.5      6.4         17.4         10.7   \n",
       "4896  ...         2.2         40.9     10.7         21.4         15.5   \n",
       "\n",
       "     temp_min_abs wind_avg wind_max wind_max_avg   sun  \n",
       "98           -1.9     10.8     79.2         40.4   4.0  \n",
       "125          -1.9     10.8     79.2         40.4   4.0  \n",
       "144          -1.9     10.8     79.2         40.4   4.0  \n",
       "184          -1.9     10.8     79.2         40.4   4.0  \n",
       "507           2.6      5.4     61.9         41.9  10.8  \n",
       "...           ...      ...      ...          ...   ...  \n",
       "4487          3.2      6.9     74.9         37.8   3.6  \n",
       "4813         -3.5     10.1     86.4         36.8   4.7  \n",
       "4859         -0.6      9.5    104.4         44.7   4.2  \n",
       "4866         -4.1      6.3     70.6         33.3   4.4  \n",
       "4896          1.8      7.8     80.6         39.7   4.1  \n",
       "\n",
       "[5041 rows x 22 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasons_18.to_csv('seasons_impute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp_season= pd.read_csv('seasons_impute.csv')\n",
    "imp_season = seasons_18.copy()\n",
    "imp_season.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generate the YEARLY dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017\n",
    "imp_season_anual_17= imp_season.loc[imp_season.year==2017,['codigo', 'freez', 'hum','lev_max', 'lev_mid', 'lev_min', 'rain',\n",
    "                                'rain_1mm', 'rain_cum', 'rain_max_10', 'rain_max_day', 'sun',\n",
    "                                'temp_avg', 'temp_max_abs', 'temp_max_avg', 'temp_min_abs', 'wind_avg','wind_max', 'wind_max_avg','year']]\n",
    "\n",
    "imp_season_anual_17=imp_season_anual_17.groupby(['codigo','year'],as_index=True ).agg({'freez':'mean', \n",
    "                         'hum':'mean', \n",
    "                         'lev_max':'max', \n",
    "                         'lev_mid':'mean',\n",
    "                         'lev_min':'min', \n",
    "                         'rain':'mean', \n",
    "                         'rain_1mm':'mean',\n",
    "                         'rain_cum':'mean', \n",
    "                         'rain_max_10':'max', \n",
    "                         'rain_max_day':'max',                         \n",
    "                         'sun':'mean',\n",
    "                         'temp_avg':'mean',\n",
    "                         'temp_max_abs':'max',\n",
    "                         'temp_max_avg':'max', \n",
    "                         'temp_min_abs':'min', \n",
    "                         'rain_max_day':'max',                         \n",
    "                         'wind_avg':'mean',\n",
    "                         'wind_max':'max',                                            \n",
    "                         'wind_max_avg':'max'}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "#2018\n",
    "imp_season_anual_18= imp_season.loc[imp_season.year==2018,['codigo', 'freez', 'hum','lev_max', 'lev_mid', 'lev_min', 'rain',\n",
    "                                'rain_1mm', 'rain_cum', 'rain_max_10', 'rain_max_day', 'sun',\n",
    "                                'temp_avg', 'temp_max_abs', 'temp_max_avg', 'temp_min_abs', 'wind_avg','wind_max', 'wind_max_avg','year']]\n",
    "\n",
    "imp_season_anual_18=imp_season_anual_18.groupby(['codigo','year'],as_index=True ).agg({'freez':'mean', \n",
    "                         'hum':'mean', \n",
    "                         'lev_max':'max', \n",
    "                         'lev_mid':'mean',\n",
    "                         'lev_min':'min', \n",
    "                         'rain':'mean', \n",
    "                         'rain_1mm':'mean',\n",
    "                         'rain_cum':'mean', \n",
    "                         'rain_max_10':'max', \n",
    "                         'rain_max_day':'max',                         \n",
    "                         'sun':'mean',\n",
    "                         'temp_avg':'mean',\n",
    "                         'temp_max_abs':'max',\n",
    "                         'temp_max_avg':'max', \n",
    "                         'temp_min_abs':'min', \n",
    "                         'rain_max_day':'max',                         \n",
    "                         'wind_avg':'mean',\n",
    "                         'wind_max':'max',                                            \n",
    "                         'wind_max_avg':'max'}).reset_index()\n",
    "\n",
    "#2019\n",
    "imp_season_anual_19= imp_season.loc[imp_season.year==2019,['codigo', 'freez', 'hum','lev_max', 'lev_mid', 'lev_min', 'rain',\n",
    "                                'rain_1mm', 'rain_cum', 'rain_max_10', 'rain_max_day', 'sun',\n",
    "                                'temp_avg', 'temp_max_abs', 'temp_max_avg', 'temp_min_abs', 'wind_avg','wind_max', 'wind_max_avg','year']]\n",
    "\n",
    "imp_season_anual_19=imp_season_anual_19.groupby(['codigo','year'],as_index=True ).agg({'freez':'mean', \n",
    "                         'hum':'mean', \n",
    "                         'lev_max':'max', \n",
    "                         'lev_mid':'mean',\n",
    "                         'lev_min':'min', \n",
    "                         'rain':'mean', \n",
    "                         'rain_1mm':'mean',\n",
    "                         'rain_cum':'mean', \n",
    "                         'rain_max_10':'max', \n",
    "                         'rain_max_day':'max',                         \n",
    "                         'sun':'mean',\n",
    "                         'temp_avg':'mean',\n",
    "                         'temp_max_abs':'max',\n",
    "                         'temp_max_avg':'max', \n",
    "                         'temp_min_abs':'min', \n",
    "                         'rain_max_day':'max',                         \n",
    "                         'wind_avg':'mean',\n",
    "                         'wind_max':'max',                                            \n",
    "                         'wind_max_avg':'max'}).reset_index()\n",
    "\n",
    "imp_season_anual= imp_season_anual_17.append(imp_season_anual_18).append(imp_season_anual_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_season_anual.to_csv('WBds02_METEO.csv',index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
