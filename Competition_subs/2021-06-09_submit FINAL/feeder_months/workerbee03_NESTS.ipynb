{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nkDv5dppU6B"
   },
   "source": [
    "# NESTS algorithm **Kopuru Vespa Velutina Competition**\n",
    "\n",
    "Purpose: Bring together weather data, geographic data, food availability data, and identified nests in each municipality of Biscay in order to have a dataset suitable for analysis and potential predictions in a Machine Learning model.\n",
    "\n",
    "Outputs: QUEENtrain and QUEENpredict datasets *(WBds03_QUEENtrain.csv & WBds03_QUEENpredict.csv)*\n",
    "\n",
    "@authors:\n",
    "* mario.bejar@student.ie.edu\n",
    "* pedro.geirinhas@student.ie.edu\n",
    "* a.berrizbeitia@student.ie.edu\n",
    "* pcasaverde@student.ie.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silueta(iterations_int, features_df):\n",
    "    \n",
    "    silhouettes = []\n",
    "\n",
    "    for i in range(2,iterations_int,1):\n",
    "      model = KMeans(n_clusters=i)\n",
    "      aux = features_df\n",
    "      model.fit(aux)\n",
    "      labels = model.labels_\n",
    "      sol = silhouette_score(aux, labels)\n",
    "      silhouettes.append(sol)\n",
    "\n",
    "    silhouette = pd.DataFrame()\n",
    "    silhouette['Labels'] = silhouettes\n",
    "    silhouette['NumberOfClusters'] = range(2,iterations_int,1)\n",
    "    \n",
    "    return silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedias(numClusters_int, features_df):\n",
    "    model = KMeans(n_clusters = numClusters_int)\n",
    "\n",
    "    aux = features_df\n",
    "    model.fit(aux)\n",
    "    modelLabels = model.labels_\n",
    "    modelCenters = model.cluster_centers_\n",
    "\n",
    "    return pd.Series(modelLabels, index=features_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codos(numClusters_int, features_df):\n",
    "    inertias = []\n",
    "    for i in range(1,numClusters_int,1):\n",
    "      model = KMeans(n_clusters=i)\n",
    "      aux = features_df\n",
    "      model.fit(aux)\n",
    "      inertias.append(model.inertia_)\n",
    "\n",
    "    elbow = pd.DataFrame()\n",
    "    elbow['Inertia'] = inertias\n",
    "    elbow['NumberOfClusters'] = range(1,numClusters_int,1)\n",
    "\n",
    "    return elbow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = pd.read_csv('../../../Input_open_data/ds01_PLANTILLA-RETO-AVISPAS-KOPURU.csv', sep=\";\")\n",
    "df02 = pd.read_csv('../../../Input_open_data/ds02_datos-nidos-avispa-asiatica.csv', sep=\",\")\n",
    "df03 = pd.read_csv('../../../Input_open_data/ds03_APICULTURA_COLMENAS_KOPURU.csv', sep=\";\")\n",
    "df04 = pd.read_csv('../../../Input_open_data/ds04_FRUTALES-DECLARADOS-KOPURU.csv', sep=\";\")\n",
    "WBdf01 = pd.read_csv('./WBds01_GEO.csv', sep=',')\n",
    "WBdf02 = pd.read_csv('./WBds02_METEO.csv', sep=',')\n",
    "df_population = pd.read_csv('../../../Other_open_data/population.csv', sep=',')\n",
    "template = pd.read_csv('../../../Input_open_data/ds01_PLANTILLA-RETO-AVISPAS-KOPURU.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the names right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping and Renaming columns in accordance to the DataMap\n",
    "# DataMap's URL: https://docs.google.com/spreadsheets/d/1Ad7s4IOmj9Tn2WcEOz4ArwedTzDs9Y0_EaUSm6uRHMQ/edit#gid=0\n",
    "\n",
    "df01.columns = ['municip_code', 'municip_name', 'nests_2020']\n",
    "df01.drop(columns=['nests_2020'], inplace=True) # just note that this is the final variable to predict in the competition\n",
    "\n",
    "df02.drop(columns=['JARDUERA_ZENBAKIA/NUM_ACTUACION', 'ERABILTZAILEA_EU/USUARIO_EU', 'ERABILTZAILEA_CAS/USUARIO_CAS', 'HELBIDEA/DIRECCION', 'EGOERA_EU/ESTADO_EU', 'ITXIERA_DATA/FECHA CIERRE', 'ITXIERAKO AGENTEA_EU/AGENTE CIERRE_EU', 'ITXIERAKO AGENTEA_CAS/AGENTE CIERRE_CAS'], inplace=True)\n",
    "df02.columns = ['waspbust_id', 'year', 'nest_foundDate', 'municip_name', 'species', 'nest_locType', 'nest_hight', 'nest_diameter', 'nest_longitude', 'nest_latitude', 'nest_status']\n",
    "\n",
    "df03.drop(columns=['CP'], inplace=True)\n",
    "df03.columns = ['municip_name','municip_code','colonies_amount']\n",
    "\n",
    "df04.columns = ['agriculture_type','municip_code','municip_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't have the \"months\" specified for any of the records in 2017 ('nest_foundDate' is incorrect for this year), so we'll drop those records\n",
    "df02 = df02.drop(df02[df02['year'] == 2017].index, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6682, 11)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning municipality names in ds02 with names from ds01\n",
    "df02_wrong_mun = ['ABADIÑO' ,'ABANTO Y CIERVANA' ,'ABANTO Y CIERVANA-ABANTO ZIERBENA' ,'AJANGIZ' ,'ALONSOTEGI' ,'AMOREBIETA-ETXANO' ,'AMOROTO' ,'ARAKALDO' ,'ARANTZAZU' ,'AREATZA' ,'ARRANKUDIAGA' ,'ARRATZU' ,'ARRIETA' ,'ARRIGORRIAGA' ,'ARTEA' ,'ARTZENTALES' ,'ATXONDO' ,'AULESTI' ,'BAKIO' ,'BALMASEDA' ,'BARAKALDO' ,'BARRIKA' ,'BASAURI' ,'BEDIA' ,'BERANGO' ,'BERMEO' ,'BERRIATUA' ,'BERRIZ' ,'BUSTURIA' ,'DERIO' ,'DIMA' ,'DURANGO' ,'EA' ,'ELANTXOBE' ,'ELORRIO' ,'ERANDIO' ,'EREÑO' ,'ERMUA' ,'ERRIGOITI' ,'ETXEBARRI' ,'ETXEBARRIA', 'ETXEBARRIa','FORUA' ,'FRUIZ' ,'GALDAKAO' ,'GALDAMES' ,'GAMIZ-FIKA' ,'GARAI' ,'GATIKA' ,'GAUTEGIZ ARTEAGA' ,'GERNIKA-LUMO' ,'GETXO' ,'GETXO ' ,'GIZABURUAGA' ,'GORDEXOLA' ,'GORLIZ' ,'GUEÑES' ,'IBARRANGELU' ,'IGORRE' ,'ISPASTER' ,'IURRETA' ,'IZURTZA' ,'KARRANTZA HARANA/VALLE DE CARRANZA' ,'KARRANTZA HARANA-VALLE DE CARRANZA' ,'KORTEZUBI' ,'LANESTOSA' ,'LARRABETZU' ,'LAUKIZ' ,'LEIOA' ,'LEKEITIO' ,'LEMOA' ,'LEMOIZ' ,'LEZAMA' ,'LOIU' ,'MALLABIA' ,'MAÑARIA' ,'MARKINA-XEMEIN' ,'MARURI-JATABE' ,'MEÑAKA' ,'MENDATA' ,'MENDEXA' ,'MORGA' ,'MUNDAKA' ,'MUNGIA' ,'MUNITIBAR-ARBATZEGI' ,'MUNITIBAR-ARBATZEGI GERRIKAITZ' ,'MURUETA' ,'MUSKIZ' ,'MUXIKA' ,'NABARNIZ' ,'ONDARROA' ,'OROZKO' ,'ORTUELLA' ,'OTXANDIO' ,'PLENTZIA' ,'PORTUGALETE' ,'SANTURTZI' ,'SESTAO' ,'SONDIKA' ,'SOPELA' ,'SOPUERTA' ,'SUKARRIETA' ,'TRUCIOS-TURTZIOZ' ,'UBIDE' ,'UGAO-MIRABALLES' ,'URDULIZ' ,'URDUÑA/ORDUÑA' ,'URDUÑA-ORDUÑA' ,'VALLE DE TRAPAGA' ,'VALLE DE TRAPAGA-TRAPAGARAN' ,'ZALDIBAR' ,'ZALLA' ,'ZAMUDIO' ,'ZARATAMO' ,'ZEANURI' ,'ZEBERIO' ,'ZIERBENA' ,'ZIORTZA-BOLIBAR' ]\n",
    "df02_correct_mun = ['Abadiño' ,'Abanto y Ciérvana-Abanto Zierbena' ,'Abanto y Ciérvana-Abanto Zierbena' ,'Ajangiz' ,'Alonsotegi' ,'Amorebieta-Etxano' ,'Amoroto' ,'Arakaldo' ,'Arantzazu' ,'Areatza' ,'Arrankudiaga' ,'Arratzu' ,'Arrieta' ,'Arrigorriaga' ,'Artea' ,'Artzentales' ,'Atxondo' ,'Aulesti' ,'Bakio' ,'Balmaseda' ,'Barakaldo' ,'Barrika' ,'Basauri' ,'Bedia' ,'Berango' ,'Bermeo' ,'Berriatua' ,'Berriz' ,'Busturia' ,'Derio' ,'Dima' ,'Durango' ,'Ea' ,'Elantxobe' ,'Elorrio' ,'Erandio' ,'Ereño' ,'Ermua' ,'Errigoiti' ,'Etxebarri' , 'Etxebarria', 'Etxebarria','Forua' ,'Fruiz' ,'Galdakao' ,'Galdames' ,'Gamiz-Fika' ,'Garai' ,'Gatika' ,'Gautegiz Arteaga' ,'Gernika-Lumo' ,'Getxo' ,'Getxo' ,'Gizaburuaga' ,'Gordexola' ,'Gorliz' ,'Güeñes' ,'Ibarrangelu' ,'Igorre' ,'Ispaster' ,'Iurreta' ,'Izurtza' ,'Karrantza Harana/Valle de Carranza' ,'Karrantza Harana/Valle de Carranza' ,'Kortezubi' ,'Lanestosa' ,'Larrabetzu' ,'Laukiz' ,'Leioa' ,'Lekeitio' ,'Lemoa' ,'Lemoiz' ,'Lezama' ,'Loiu' ,'Mallabia' ,'Mañaria' ,'Markina-Xemein' ,'Maruri-Jatabe' ,'Meñaka' ,'Mendata' ,'Mendexa' ,'Morga' ,'Mundaka' ,'Mungia' ,'Munitibar-Arbatzegi Gerrikaitz' ,'Munitibar-Arbatzegi Gerrikaitz' ,'Murueta' ,'Muskiz' ,'Muxika' ,'Nabarniz' ,'Ondarroa' ,'Orozko' ,'Ortuella' ,'Otxandio' ,'Plentzia' ,'Portugalete' ,'Santurtzi' ,'Sestao' ,'Sondika' ,'Sopela' ,'Sopuerta' ,'Sukarrieta' ,'Trucios-Turtzioz' ,'Ubide' ,'Ugao-Miraballes' ,'Urduliz' ,'Urduña/Orduña' ,'Urduña/Orduña' ,'Valle de Trápaga-Trapagaran' ,'Valle de Trápaga-Trapagaran' ,'Zaldibar' ,'Zalla' ,'Zamudio' ,'Zaratamo' ,'Zeanuri' ,'Zeberio' ,'Zierbena' ,'Ziortza-Bolibar',]\n",
    "df02.municip_name.replace(to_replace = df02_wrong_mun, value = df02_correct_mun, inplace = True)\n",
    "df02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the `species` variable contents to English\n",
    "df02.species.replace(to_replace=['AVISPA ASIÁTICA', 'AVISPA COMÚN', 'ABEJA'], value=['Vespa Velutina', 'Common Wasp', 'Wild Bee'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the contents of the `nest_locType` and `nest_status` variables to English\n",
    "# But note that this data makes is of no use from a \"forecastoing\" standpoint eventually, since we will predict with a one-year offset (and thus, use thigs like weather mostly)\n",
    "\n",
    "df02.nest_locType.replace(to_replace=['CONSTRUCCIÓN', 'ARBOLADO'], value=['Urban Environment', 'Natural Environment'], inplace=True)\n",
    "df02.nest_status.replace(to_replace=['CERRADA - ELIMINADO', 'CERRADA - NO ELIMINABLE', 'PENDIENTE DE GRUPO'], value=['Nest Terminated', 'Cannot Terminate', 'Pending classification'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dates right\n",
    "Including the addition of a `year_offset` variable to comply with the competition's rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing 'nest_foundDate' the to \"datetime\" format\n",
    "df02['nest_foundDate'] = pd.to_datetime(df02['nest_foundDate'])\n",
    "\n",
    "# Create a \"month\" variable in the main dataframe\n",
    "df02['month'] = pd.DatetimeIndex(df02['nest_foundDate']).month\n",
    "\n",
    "# Create a \"year_offset\" variable in the main dataframe\n",
    "# IMPORTANT: THIS REFLECTS OUR ASSUMPTION THAT `YEAR-1` DATA CAN BE USE TO PREDICT `YEAR` DATA, AS MANDATED BY THE COMPETITION'S BASE REQUIREMENTS\n",
    "df02['year_offset'] = pd.DatetimeIndex(df02['nest_foundDate']).year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['waspbust_id', 'year', 'nest_foundDate', 'municip_name', 'species',\n",
       "       'nest_locType', 'nest_hight', 'nest_diameter', 'nest_longitude',\n",
       "       'nest_latitude', 'nest_status', 'month', 'year_offset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating distinct dataFrames for each `species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vespa Velutina    6042\n",
       "Common Wasp        274\n",
       "Wild Bee           145\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02_vespas = df02.loc[df02.species == 'Vespa Velutina', :]\n",
    "df02_wasps = df02.loc[df02.species == 'Common Wasp', :]\n",
    "df02_bees = df02.loc[df02.species == 'Wild Bee', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6042, 13)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02_vespas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TEMPLATE dataframe with the missing municipalities and months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.drop(columns='NIDOS 2020', inplace=True)\n",
    "template.columns = ['municip_code', 'municip_name']\n",
    "template['year2019'] = 2019\n",
    "template['year2018'] = 2018\n",
    "template['year2017'] = 2017\n",
    "template = pd.melt(template, id_vars=['municip_code', 'municip_name'], value_vars=['year2019', 'year2018', 'year2017'], value_name = 'year_offset')\n",
    "template.drop(columns='variable', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,13,1):\n",
    "    template[i] = i\n",
    "template = pd.melt(template, id_vars=['municip_code', 'municip_name', 'year_offset'],\\\n",
    "                   value_vars=[1,2,3,4,5,6,7,8,9,10,11,12], value_name = 'month')\n",
    "template.drop(columns='variable', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 4)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "112*12*3 == template.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['municip_code', 'municip_name', 'year_offset', 'month'], dtype='object')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match each `municip_name` to its `municip_code` as per the competition's official template (i.e. `df01`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataFrames df01 and df02 by 'municip_name', in order to identify every wasp nest with its 'municip_code'\n",
    "# The intention is that 'all_the_queens-wasps' will be the final dataFrame to use in the ML model eventually\n",
    "\n",
    "all_the_queens_wasps = pd.merge(df02_vespas, df01, how = 'left', on = 'municip_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    48020\n",
       "Name: municip_code, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any municipalities missing from the df02 dataframe, and add them if necessary\n",
    "\n",
    "df01.municip_code[~df01.municip_code.isin(all_the_queens_wasps.municip_code.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input municipalities and months missing from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps = pd.merge(all_the_queens_wasps, template,\\\n",
    "                                      how = 'outer', left_on = ['municip_code', 'municip_name', 'year_offset', 'month'],\\\n",
    "                                      right_on = ['municip_code', 'municip_name', 'year_offset', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "waspbust_id       2394\n",
       "year              2394\n",
       "nest_foundDate    2394\n",
       "municip_name         0\n",
       "species           2394\n",
       "nest_locType      2565\n",
       "nest_hight        2394\n",
       "nest_diameter     2394\n",
       "nest_longitude    3298\n",
       "nest_latitude     3298\n",
       "nest_status       2394\n",
       "month                0\n",
       "year_offset          0\n",
       "municip_code         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps.year.fillna(value='no registers', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8436, 14)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discarding some variables\n",
    "Namely: **species** (since by now they are all Vespa Velutina only), **nest_foundDate**,**nest_longitude**, and **nest_latitude**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps.drop(columns=['nest_foundDate', 'nest_longitude', 'nest_latitude', 'species'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new categorical variable for Nest Size\n",
    "\n",
    "[Formula for nest volume](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6723431/)\n",
    "\n",
    "[Example calculation in cubic meters](https://www.easycalculation.com/shapes/volume-of-prolate-spheroid.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(aes(x='nest_hight', y='nest_diameter'), all_the_queens_wasps) + geom_point(stat='identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_the_queens_wasps['nest_volume_l'] = 4/3 * math.pi * (all_the_queens_wasps['nest_hight']/100/2)**2 * (all_the_queens_wasps['nest_diameter']/100/2) * 1000\n",
    "#all_the_queens_wasps['nest_volume_l'].fillna(0, inplace=True)\n",
    "all_the_queens_wasps['nest_size'] = all_the_queens_wasps['nest_hight'] * all_the_queens_wasps['nest_diameter']\n",
    "all_the_queens_wasps['nest_size'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     8436.000000\n",
       "mean       221.397226\n",
       "std        940.966217\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%         40.000000\n",
       "75%        240.000000\n",
       "max      63750.000000\n",
       "Name: nest_size, dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_the_queens_wasps['nest_volume_l'].describe()\n",
    "all_the_queens_wasps['nest_size'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vespaVoluminous = all_the_queens_wasps.loc[:, ['municip_code', 'nest_volume_l']].groupby(by='municip_code', as_index=False).mean()\n",
    "vespaVoluminous = all_the_queens_wasps.loc[:, ['municip_code', 'nest_size']].groupby(by='municip_code', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(aes(x='nest_volume_l'), vespaVoluminous) + geom_histogram()\n",
    "#ggplot(aes(x='nest_size'), vespaVoluminous) + geom_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vespaVoluminous['nest_size_equals'] = pd.qcut(vespaVoluminous['nest_size'], 3, labels=['small', 'mid', 'large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vespaVoluminous['nest_size_equals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vespaVoluminous['nest_volume_l'] = pd.cut(vespaVoluminous['nest_volume_l'], bins=3, labels=['small', 'mid', 'large'])\n",
    "vespaVoluminous['nest_size'] = pd.cut(vespaVoluminous['nest_size'], bins=3, labels=['small', 'mid', 'large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    79\n",
       "mid      30\n",
       "large     3\n",
       "Name: nest_size, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vespaVoluminous['nest_volume_l'].value_counts()\n",
    "vespaVoluminous['nest_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps = pd.merge(all_the_queens_wasps, vespaVoluminous, how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_the_queens_wasps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categoricals to dummy variables\n",
    "... and dropping some variables. Namely: **nest_locType**, **nest_hight**, **nest_diameter**, **nest_size_x**, **nest_size_y**, and **nest_latitude**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_big = pd.get_dummies(all_the_queens_wasps.nest_size_y)\n",
    "all_the_queens_wasps = pd.concat([all_the_queens_wasps, queen_big], axis=1)\n",
    "\n",
    "queen_cosmo = pd.get_dummies(all_the_queens_wasps.nest_locType)\n",
    "all_the_queens_wasps = pd.concat([all_the_queens_wasps, queen_cosmo], axis=1)\n",
    "\n",
    "queen_hastalavista = pd.get_dummies(all_the_queens_wasps.nest_status)\n",
    "all_the_queens_wasps = pd.concat([all_the_queens_wasps, queen_hastalavista], axis=1)\n",
    "\n",
    "all_the_queens_wasps.drop(columns=['nest_locType', 'nest_hight', 'nest_diameter', 'nest_size_y', 'nest_size_x', 'nest_status'], inplace=True)\n",
    "\n",
    "all_the_queens_wasps.rename(columns = {\"small\":\"fv_size_small\", \"mid\":\"fv_size_mid\", \"large\":\"fv_size_large\",\\\n",
    "                                      \"Natural Environment\":\"fv_type_natural\", \"Urban Environment\":\"fv_type_urban\",\\\n",
    "                                      \"Cannot Terminate\":\"fv_status_cantkill\", \"Nest Terminated\":\"fv_status_dead\", \"Pending classification\":\"fv_status_pending\"}, inplace = True)\n",
    "\n",
    "#all_the_queens_wasps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_the_queens_wasps.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the amount of wasp nests in each municipality, for each month and year, and adding up the rest of dummy categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps = all_the_queens_wasps.loc[:, ['waspbust_id', 'fv_size_small', 'fv_size_mid', 'fv_size_large', 'fv_type_natural', 'fv_type_urban',\\\n",
    "                                                    'fv_status_cantkill', 'fv_status_dead', 'fv_status_pending',\\\n",
    "                                                    'year', 'municip_name', 'municip_code', 'month', 'year_offset']]\\\n",
    ".groupby(by =['year', 'municip_name', 'municip_code', 'month', 'year_offset'], as_index=False)\\\n",
    ".agg({'waspbust_id':'count', 'fv_size_small':'sum', 'fv_size_mid':'sum', 'fv_size_large':'sum', 'fv_type_natural':'sum', 'fv_type_urban':'sum',\\\n",
    "      'fv_status_cantkill':'sum', 'fv_status_dead':'sum', 'fv_status_pending':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rename the id to NESTS, now that it has been counted\n",
    "all_the_queens_wasps.rename(columns = {\"waspbust_id\":\"NESTS\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'municip_name', 'municip_code', 'month', 'year_offset', 'NESTS',\n",
       "       'fv_size_small', 'fv_size_mid', 'fv_size_large', 'fv_type_natural',\n",
       "       'fv_type_urban', 'fv_status_cantkill', 'fv_status_dead',\n",
       "       'fv_status_pending'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all those \"outer merge\" rows with no associated year, set their NESTS to zero\n",
    "all_the_queens_wasps.loc[all_the_queens_wasps.year == 'no registers', ['NESTS']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.NESTS.sum() == df02_vespas.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that the DataFrame has the right number of rows\n",
    "all_the_queens_wasps.shape[0] == 112*12*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_the_queens_wasps.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group df03 by 'municip_code' because there are multiple rows for each municipality (and we need a 1:1 relationship)\n",
    "df03 = df03.groupby(by = 'municip_code', as_index= False).colonies_amount.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge df03 to add number of bee hives (which is a food source for the wasp) in each municipality\n",
    "# Note that NaNs (unknown amount of hives) are replaced with zeroes for the 'colonies_amount' variable\n",
    "\n",
    "all_the_queens_wasps = pd.merge(all_the_queens_wasps, df03, how = 'left', on = 'municip_code')\n",
    "all_the_queens_wasps.colonies_amount.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 15)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_the_queens_wasps.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group df04 (agricultural food sources) by municipality code, after appending variables with the amount of each type of agricultural product\n",
    "\n",
    "aux = df04.copy(deep=True)\n",
    "aux.drop(columns=['municip_name'], inplace=True)\n",
    "\n",
    "aux['food_fruit'] = np.where(aux['agriculture_type'] == 'FRUTALES', '1', '0')\n",
    "aux['food_fruit'] = aux['food_fruit'].astype('int')\n",
    "\n",
    "aux['food_apple'] = np.where(aux['agriculture_type'] == 'MANZANO', '1', '0')\n",
    "aux['food_apple'] = aux['food_apple'].astype('int')\n",
    "\n",
    "txakoli_string = df04.agriculture_type[45]\n",
    "aux['food_txakoli'] = np.where(aux['agriculture_type'] == txakoli_string, '1', '0')\n",
    "aux['food_txakoli'] = aux['food_txakoli'].astype('int')\n",
    "\n",
    "aux['food_kiwi'] = np.where(aux['agriculture_type'] == 'AKTINIDIA (KIWI)', '1', '0')\n",
    "aux['food_kiwi'] = aux['food_kiwi'].astype('int')\n",
    "\n",
    "aux['food_pear'] = np.where(aux['agriculture_type'] == 'PERAL', '1', '0')\n",
    "aux['food_pear'] = aux['food_pear'].astype('int')\n",
    "\n",
    "aux['food_blueberry'] = np.where(aux['agriculture_type'] == 'ARANDANOS', '1', '0')\n",
    "aux['food_blueberry'] = aux['food_blueberry'].astype('int')\n",
    "\n",
    "aux['food_raspberry'] = np.where(aux['agriculture_type'] == 'FRAMBUESAS', '1', '0')\n",
    "aux['food_raspberry'] = aux['food_raspberry'].astype('int')\n",
    "\n",
    "aux = aux.groupby(by='municip_code', as_index=False).sum()\n",
    "df04 = aux.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge df04 to add number of each type of food source ('agriculture_type') present in each municipality\n",
    "# Any municipality not present in df04 will get assigned 'zero' food sources for any given type of fruit\n",
    "\n",
    "all_the_queens_wasps = pd.merge(all_the_queens_wasps, df04, how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps.food_fruit.fillna(value=0, inplace=True)\n",
    "all_the_queens_wasps.food_apple.fillna(value=0, inplace=True)\n",
    "all_the_queens_wasps.food_txakoli.fillna(value=0, inplace=True)\n",
    "all_the_queens_wasps.food_kiwi.fillna(value=0, inplace=True)\n",
    "all_the_queens_wasps.food_pear.fillna(value=0, inplace=True)\n",
    "all_the_queens_wasps.food_blueberry.fillna(value=0, inplace=True)\n",
    "all_the_queens_wasps.food_raspberry.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 22)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_the_queens_wasps.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic\n",
    "Here, a very important assumption regarding which station corresponds to each municipality is being brought from the HONEYCOMB script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding weather station code to each municipality in all_the_queens_wasps. \"No municipality left behind!\"\n",
    "all_the_queens_wasps = pd.merge(all_the_queens_wasps, WBdf01, how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 23)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_the_queens_wasps.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    1344\n",
       "2017    1344\n",
       "2019    1344\n",
       "Name: year_offset, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps.year_offset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather\n",
    "\n",
    "MANDATORY ASSUMPTION: As per the competition's rules. 2020 weather data cannot be used to predict 2020's number of wasp nests.\n",
    "\n",
    "Therefore, **this merge links 2018's wasp nests to 2017's weather data for each corresponding month** (all of which falls under the $2017$ value for `year_offset`).\n",
    "\n",
    "Likewise, **2019's wasp nests are linked to 2018's weather data for the corresponding month** (all of which falls under the $2018$ value for `year_offset`).\n",
    "\n",
    "Finally, the $2019$ value for `year_offset` contains zero NESTS and the year 2019's weather which we will use to predict 2020's number of NESTS (the target variable of the competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, merge the Main 'all_the_queens_wasps' dataFrame with the weather data 'WBdf02' dataFrame\n",
    "all_the_queens_wasps = pd.merge(all_the_queens_wasps, WBdf02, how = 'left',\\\n",
    "                                      left_on = ['station_code', 'month', 'year_offset'],\\\n",
    "                                      right_on = ['station_code', 'month', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_x', 'municip_name', 'municip_code', 'month', 'year_offset',\n",
       "       'NESTS', 'fv_size_small', 'fv_size_mid', 'fv_size_large',\n",
       "       'fv_type_natural', 'fv_type_urban', 'fv_status_cantkill',\n",
       "       'fv_status_dead', 'fv_status_pending', 'colonies_amount', 'food_fruit',\n",
       "       'food_apple', 'food_txakoli', 'food_kiwi', 'food_pear',\n",
       "       'food_blueberry', 'food_raspberry', 'station_code', 'index', 'MMM',\n",
       "       'year_y', 'station_name', 'code_merge', 'merge_cod', 'weath_days_frost',\n",
       "       'weath_humidity', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel',\n",
       "       'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall',\n",
       "       'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar',\n",
       "       'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp',\n",
       "       'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that this relabels `year` from the `all_the_queens_wasps` dataframe as `year_x`, and likewise as `year_y` from the WBdf02 dataframe\n",
    "all_the_queens_wasps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = all_the_queens_wasps.loc[all_the_queens_wasps.year_offset.isin([2017, 2018]), :]\n",
    "all_the_queens_wasps_PREDICT = all_the_queens_wasps.loc[all_the_queens_wasps.year_offset.isin([2019]), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding `Population`, a publicly available dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding population by municipality\n",
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, df_population, how = 'left',\\\n",
    "                                      left_on= ['municip_code', 'year_offset'],\\\n",
    "                                      right_on = ['municip_code', 'year'])\n",
    "\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, df_population, how = 'left',\\\n",
    "                                        left_on= ['municip_code', 'year_offset'],\\\n",
    "                                        right_on = ['municip_code', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2688, 49)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 49)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_PREDICT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_PREDICT.shape[0] + all_the_queens_wasps_TRAIN.shape[0] == template.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary/duplicate columns\n",
    "all_the_queens_wasps_TRAIN.drop(columns=['year_y','code_merge', 'merge_cod', 'year_x', 'index', 'MMM'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['municip_name', 'municip_code', 'month', 'year_offset', 'NESTS',\n",
       "       'fv_size_small', 'fv_size_mid', 'fv_size_large', 'fv_type_natural',\n",
       "       'fv_type_urban', 'fv_status_cantkill', 'fv_status_dead',\n",
       "       'fv_status_pending', 'colonies_amount', 'food_fruit', 'food_apple',\n",
       "       'food_txakoli', 'food_kiwi', 'food_pear', 'food_blueberry',\n",
       "       'food_raspberry', 'station_code', 'station_name', 'weath_days_frost',\n",
       "       'weath_humidity', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel',\n",
       "       'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall',\n",
       "       'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar',\n",
       "       'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp',\n",
       "       'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind', 'year',\n",
       "       'population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_TRAIN.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_PREDICT.drop(columns=['year_y', 'code_merge', 'merge_cod', 'year_x', 'index', 'MMM'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['municip_name', 'municip_code', 'month', 'year_offset', 'NESTS',\n",
       "       'fv_size_small', 'fv_size_mid', 'fv_size_large', 'fv_type_natural',\n",
       "       'fv_type_urban', 'fv_status_cantkill', 'fv_status_dead',\n",
       "       'fv_status_pending', 'colonies_amount', 'food_fruit', 'food_apple',\n",
       "       'food_txakoli', 'food_kiwi', 'food_pear', 'food_blueberry',\n",
       "       'food_raspberry', 'station_code', 'station_name', 'weath_days_frost',\n",
       "       'weath_humidity', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel',\n",
       "       'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall',\n",
       "       'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar',\n",
       "       'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp',\n",
       "       'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind', 'year',\n",
       "       'population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_PREDICT.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_TRAIN.NESTS.sum() == df02_vespas.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_PREDICT.NESTS.sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>municip_name</th>\n",
       "      <th>municip_code</th>\n",
       "      <th>month</th>\n",
       "      <th>year_offset</th>\n",
       "      <th>NESTS</th>\n",
       "      <th>fv_size_small</th>\n",
       "      <th>fv_size_mid</th>\n",
       "      <th>fv_size_large</th>\n",
       "      <th>fv_type_natural</th>\n",
       "      <th>fv_type_urban</th>\n",
       "      <th>...</th>\n",
       "      <th>weath_solar</th>\n",
       "      <th>weath_meanTemp</th>\n",
       "      <th>weath_maxTemp</th>\n",
       "      <th>weath_maxMeanTemp</th>\n",
       "      <th>weath_minTemp</th>\n",
       "      <th>weath_meanWindM</th>\n",
       "      <th>weath_maxWindM</th>\n",
       "      <th>weath_meanDayMaxWind</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abadiño</td>\n",
       "      <td>48001</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.501449</td>\n",
       "      <td>6.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.613883</td>\n",
       "      <td>74.702995</td>\n",
       "      <td>40.082916</td>\n",
       "      <td>2019</td>\n",
       "      <td>7599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abadiño</td>\n",
       "      <td>48001</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.519191</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10.342841</td>\n",
       "      <td>74.387324</td>\n",
       "      <td>40.146571</td>\n",
       "      <td>2019</td>\n",
       "      <td>7599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abadiño</td>\n",
       "      <td>48001</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.505731</td>\n",
       "      <td>10.6</td>\n",
       "      <td>26.2</td>\n",
       "      <td>16.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.063586</td>\n",
       "      <td>75.072948</td>\n",
       "      <td>40.091499</td>\n",
       "      <td>2019</td>\n",
       "      <td>7599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abadiño</td>\n",
       "      <td>48001</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.495403</td>\n",
       "      <td>11.7</td>\n",
       "      <td>24.6</td>\n",
       "      <td>17.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>10.426616</td>\n",
       "      <td>73.978414</td>\n",
       "      <td>40.092840</td>\n",
       "      <td>2019</td>\n",
       "      <td>7599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abadiño</td>\n",
       "      <td>48001</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.519495</td>\n",
       "      <td>13.1</td>\n",
       "      <td>30.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10.908015</td>\n",
       "      <td>74.612430</td>\n",
       "      <td>40.116476</td>\n",
       "      <td>2019</td>\n",
       "      <td>7599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>Ziortza-Bolibar</td>\n",
       "      <td>48915</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.528862</td>\n",
       "      <td>19.7</td>\n",
       "      <td>34.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>14.6</td>\n",
       "      <td>11.573452</td>\n",
       "      <td>74.964378</td>\n",
       "      <td>40.291097</td>\n",
       "      <td>2019</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>Ziortza-Bolibar</td>\n",
       "      <td>48915</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.558162</td>\n",
       "      <td>17.7</td>\n",
       "      <td>30.2</td>\n",
       "      <td>23.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>11.595205</td>\n",
       "      <td>75.445151</td>\n",
       "      <td>40.208953</td>\n",
       "      <td>2019</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>Ziortza-Bolibar</td>\n",
       "      <td>48915</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.561851</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.666526</td>\n",
       "      <td>76.114760</td>\n",
       "      <td>40.173831</td>\n",
       "      <td>2019</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>Ziortza-Bolibar</td>\n",
       "      <td>48915</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.520807</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>10.706109</td>\n",
       "      <td>76.087953</td>\n",
       "      <td>40.040077</td>\n",
       "      <td>2019</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>Ziortza-Bolibar</td>\n",
       "      <td>48915</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.617186</td>\n",
       "      <td>9.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>11.060766</td>\n",
       "      <td>75.869756</td>\n",
       "      <td>40.167203</td>\n",
       "      <td>2019</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         municip_name  municip_code  month  year_offset  NESTS  fv_size_small  \\\n",
       "0             Abadiño         48001      1         2019      0              0   \n",
       "1             Abadiño         48001      2         2019      0              0   \n",
       "2             Abadiño         48001      3         2019      0              0   \n",
       "3             Abadiño         48001      4         2019      0              0   \n",
       "4             Abadiño         48001      5         2019      0              0   \n",
       "...               ...           ...    ...          ...    ...            ...   \n",
       "1339  Ziortza-Bolibar         48915      8         2019      0              1   \n",
       "1340  Ziortza-Bolibar         48915      9         2019      0              1   \n",
       "1341  Ziortza-Bolibar         48915     10         2019      0              1   \n",
       "1342  Ziortza-Bolibar         48915     11         2019      0              1   \n",
       "1343  Ziortza-Bolibar         48915     12         2019      0              1   \n",
       "\n",
       "      fv_size_mid  fv_size_large  fv_type_natural  fv_type_urban  ...  \\\n",
       "0               1              0                0              0  ...   \n",
       "1               1              0                0              0  ...   \n",
       "2               1              0                0              0  ...   \n",
       "3               1              0                0              0  ...   \n",
       "4               1              0                0              0  ...   \n",
       "...           ...            ...              ...            ...  ...   \n",
       "1339            0              0                0              0  ...   \n",
       "1340            0              0                0              0  ...   \n",
       "1341            0              0                0              0  ...   \n",
       "1342            0              0                0              0  ...   \n",
       "1343            0              0                0              0  ...   \n",
       "\n",
       "      weath_solar  weath_meanTemp  weath_maxTemp  weath_maxMeanTemp  \\\n",
       "0       12.501449             6.1           16.0                8.8   \n",
       "1       12.519191            10.0           24.6               16.1   \n",
       "2       12.505731            10.6           26.2               16.9   \n",
       "3       12.495403            11.7           24.6               17.4   \n",
       "4       12.519495            13.1           30.5               19.0   \n",
       "...           ...             ...            ...                ...   \n",
       "1339    12.528862            19.7           34.3               25.5   \n",
       "1340    12.558162            17.7           30.2               23.9   \n",
       "1341    12.561851            15.2           28.1               21.3   \n",
       "1342    12.520807            10.0           23.6               14.1   \n",
       "1343    12.617186             9.2           21.2               14.7   \n",
       "\n",
       "      weath_minTemp  weath_meanWindM  weath_maxWindM  weath_meanDayMaxWind  \\\n",
       "0               3.4        10.613883       74.702995             40.082916   \n",
       "1               4.7        10.342841       74.387324             40.146571   \n",
       "2               4.6        10.063586       75.072948             40.091499   \n",
       "3               6.4        10.426616       73.978414             40.092840   \n",
       "4               7.6        10.908015       74.612430             40.116476   \n",
       "...             ...              ...             ...                   ...   \n",
       "1339           14.6        11.573452       74.964378             40.291097   \n",
       "1340           12.5        11.595205       75.445151             40.208953   \n",
       "1341           10.6        11.666526       76.114760             40.173831   \n",
       "1342            6.5        10.706109       76.087953             40.040077   \n",
       "1343            4.9        11.060766       75.869756             40.167203   \n",
       "\n",
       "      year  population  \n",
       "0     2019        7599  \n",
       "1     2019        7599  \n",
       "2     2019        7599  \n",
       "3     2019        7599  \n",
       "4     2019        7599  \n",
       "...    ...         ...  \n",
       "1339  2019         413  \n",
       "1340  2019         413  \n",
       "1341  2019         413  \n",
       "1342  2019         413  \n",
       "1343  2019         413  \n",
       "\n",
       "[1344 rows x 43 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_PREDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering municipalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... by the size of its Vespa Velutina nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeMatters = all_the_queens_wasps_TRAIN.loc[:, ['municip_code', 'fv_size_small', 'fv_size_mid', 'fv_size_large']].groupby(by='municip_code', as_index=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeSilhouette = silueta(15, sizeMatters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), sizeSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeClusters = pd.DataFrame()\n",
    "sizeClusters['cluster_size'] = kmedias(clustersby_size, sizeMatters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    81\n",
       "3    20\n",
       "0     8\n",
       "2     2\n",
       "4     1\n",
       "Name: cluster_size, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeClusters['cluster_size'].reset_index()\n",
    "sizeClusters['cluster_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, sizeClusters['cluster_size'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, sizeClusters['cluster_size'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... by the usual environment of its wasp nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmopolitan = all_the_queens_wasps_TRAIN.loc[:, ['municip_code', 'fv_type_natural', 'fv_type_urban']].groupby(by='municip_code', as_index=True).mean()\n",
    "cosmoSilhouette = silueta(10, cosmopolitan)\n",
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), cosmoSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_cosmo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    101\n",
       "0     11\n",
       "Name: cluster_cosmo, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmoClusters = pd.DataFrame()\n",
    "cosmoClusters['cluster_cosmo'] = kmedias(clustersby_cosmo, cosmopolitan)\n",
    "cosmoClusters['cluster_cosmo'].reset_index()\n",
    "cosmoClusters['cluster_cosmo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, cosmoClusters['cluster_cosmo'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, cosmoClusters['cluster_cosmo'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... by the usual status its wasp nests are left in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivalists = all_the_queens_wasps_TRAIN.loc[:, ['municip_code', 'fv_status_cantkill', 'fv_status_dead', 'fv_status_pending']].groupby(by='municip_code', as_index=True).mean()\n",
    "surviveSilhouette = silueta(10, survivalists)\n",
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), surviveSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_survive = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     12\n",
       "Name: cluster_survive, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surviveClusters = pd.DataFrame()\n",
    "surviveClusters['cluster_survive'] = kmedias(clustersby_cosmo, survivalists)\n",
    "surviveClusters['cluster_survive'].reset_index()\n",
    "surviveClusters['cluster_survive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, surviveClusters['cluster_survive'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, surviveClusters['cluster_survive'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping all that future information (aka, future variables (`fv_...`)) from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN.drop(columns=['fv_size_small', 'fv_size_mid', 'fv_size_large', 'fv_type_natural', 'fv_type_urban', 'fv_status_cantkill', 'fv_status_dead', 'fv_status_pending'], inplace=True)\n",
    "all_the_queens_wasps_PREDICT.drop(columns=['fv_size_small', 'fv_size_mid', 'fv_size_large', 'fv_type_natural', 'fv_type_urban', 'fv_status_cantkill', 'fv_status_dead', 'fv_status_pending'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... by the availability of food sources (`food_`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodies = all_the_queens_wasps_TRAIN.loc[:, ['municip_code', 'colonies_amount', 'food_fruit', 'food_apple', 'food_txakoli', 'food_kiwi', 'food_pear', 'food_blueberry', 'food_raspberry']].groupby(by='municip_code', as_index=True).mean()\n",
    "slimSilhouette = silueta(10, foodies)\n",
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), slimSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_foodie = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    103\n",
       "1      9\n",
       "Name: cluster_food, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foodieClusters = pd.DataFrame()\n",
    "foodieClusters['cluster_food'] = kmedias(clustersby_foodie, foodies)\n",
    "foodieClusters['cluster_food'].reset_index()\n",
    "foodieClusters['cluster_food'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, foodieClusters['cluster_food'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, foodieClusters['cluster_food'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring clustering of weather variables (`weath_...`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... by Humidity-related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the dataset using MinMaxScaler, the most common approach\n",
    "\n",
    "#scalators = ['weath_days_frost', 'weath_humidity', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel', 'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall', 'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar', 'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp', 'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind']\n",
    "scalators_wet = ['municip_code', 'weath_days_frost', 'weath_humidity', 'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall', 'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar']\n",
    "\n",
    "weathercock_water = all_the_queens_wasps_TRAIN[scalators_wet].copy()\n",
    "weathercock_water.iloc[:,1:] = preprocessing.minmax_scale(weathercock_water.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathercock_water = weathercock_water.groupby(by='municip_code', as_index=True).mean()\n",
    "wetSilhouette = silueta(15, weathercock_water)\n",
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), wetSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_weather_humid = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    57\n",
       "1    55\n",
       "Name: cluster_weather_wet, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherWetClusters = pd.DataFrame()\n",
    "weatherWetClusters['cluster_weather_wet'] = kmedias(clustersby_weather_humid, weathercock_water)\n",
    "weatherWetClusters['cluster_weather_wet'].reset_index()\n",
    "weatherWetClusters['cluster_weather_wet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, weatherWetClusters['cluster_weather_wet'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, weatherWetClusters['cluster_weather_wet'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... by Temperature-related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the dataset using MinMaxScaler, the most common approach\n",
    "\n",
    "#scalators = ['weath_days_frost', 'weath_humidity', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel', 'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall', 'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar', 'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp', 'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind']\n",
    "scalators_temp = ['municip_code', 'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp']\n",
    "\n",
    "weathercock_temp = all_the_queens_wasps_TRAIN[scalators_temp].copy()\n",
    "weathercock_temp.iloc[:,1:] = preprocessing.minmax_scale(weathercock_temp.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathercock_temp = weathercock_temp.groupby(by='municip_code', as_index=True).mean()\n",
    "tempSilhouette = silueta(10, weathercock_temp)\n",
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), tempSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_weather_temp = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97\n",
       "1    15\n",
       "Name: cluster_weather_temp, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherTempClusters = pd.DataFrame()\n",
    "weatherTempClusters['cluster_weather_temp'] = kmedias(clustersby_weather_temp, weathercock_temp)\n",
    "weatherTempClusters['cluster_weather_temp'].reset_index()\n",
    "weatherTempClusters['cluster_weather_temp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, weatherTempClusters['cluster_weather_temp'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, weatherTempClusters['cluster_weather_temp'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... by Wind-related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the dataset using MinMaxScaler, the most common approach\n",
    "\n",
    "#scalators = ['weath_days_frost', 'weath_humidity', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel', 'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall', 'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar', 'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp', 'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind']\n",
    "scalators_wind = ['municip_code', 'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind']\n",
    "\n",
    "weathercock_wind = all_the_queens_wasps_TRAIN[scalators_wind].copy()\n",
    "weathercock_wind.iloc[:,1:] = preprocessing.minmax_scale(weathercock_wind.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathercock_wind = weathercock_wind.groupby(by='municip_code', as_index=True).mean()\n",
    "windSilhouette = silueta(15, weathercock_wind)\n",
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), windSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_weather_wind = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    91\n",
       "0    21\n",
       "Name: cluster_weather_wind, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherWindClusters = pd.DataFrame()\n",
    "weatherWindClusters['cluster_weather_wind'] = kmedias(clustersby_weather_wind, weathercock_wind)\n",
    "weatherWindClusters['cluster_weather_wind'].reset_index()\n",
    "weatherWindClusters['cluster_weather_wind'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, weatherWindClusters['cluster_weather_wind'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, weatherWindClusters['cluster_weather_wind'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... by Other weather variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the dataset using MinMaxScaler, the most common approach\n",
    "\n",
    "#scalators = ['weath_days_frost', 'weath_humidity', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel', 'weath_days_rain', 'weath_days_rain1mm', 'weath_accuRainfall', 'weath_10minRainfall', 'weath_1dayRainfall', 'weath_solar', 'weath_meanTemp', 'weath_maxTemp', 'weath_maxMeanTemp', 'weath_minTemp', 'weath_meanWindM', 'weath_maxWindM', 'weath_meanDayMaxWind']\n",
    "scalators_level = ['municip_code', 'weath_maxLevel', 'weath_midLevel', 'weath_minLevel']\n",
    "\n",
    "weathercock_level = all_the_queens_wasps_TRAIN[scalators_level].copy()\n",
    "weathercock_level.iloc[:,1:] = preprocessing.minmax_scale(weathercock_level.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathercock_level = weathercock_level.groupby(by='municip_code', as_index=True).mean()\n",
    "levelSilhouette = silueta(10, weathercock_level)\n",
    "#ggplot(aes(x='NumberOfClusters', y='Labels'), slimSilhouette) + geom_line() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersby_weather_level = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    101\n",
       "1     11\n",
       "Name: cluster_weather_level, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherLevelClusters = pd.DataFrame()\n",
    "weatherLevelClusters['cluster_weather_level'] = kmedias(clustersby_weather_level, weathercock_level)\n",
    "weatherLevelClusters['cluster_weather_level'].reset_index()\n",
    "weatherLevelClusters['cluster_weather_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN = pd.merge(all_the_queens_wasps_TRAIN, weatherLevelClusters['cluster_weather_level'], how = 'left', on= 'municip_code')\n",
    "all_the_queens_wasps_PREDICT = pd.merge(all_the_queens_wasps_PREDICT, weatherLevelClusters['cluster_weather_level'], how = 'left', on= 'municip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters_table = all_the_queens_wasps_TRAIN.groupby('Cluster').mean()\n",
    "#pd.value_counts(all_the_queens_wasps_TRAIN.Cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters_table.drop(columns=['Id'], inplace=True)\n",
    "#clusters_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters_table.to_excel(\"/Kopuru-VespaVelutina-Clustering.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_the_queens_wasps_TRAIN.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_the_queens_wasps_PREDICT.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>month</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_offset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "month         1    2    3    4    5    6    7    8    9    10   11   12\n",
       "year_offset                                                            \n",
       "2017         112  112  112  112  112  112  112  112  112  112  112  112\n",
       "2018         112  112  112  112  112  112  112  112  112  112  112  112\n",
       "2019         112  112  112  112  112  112  112  112  112  112  112  112"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many rows (municipalities) are there in the dataframe for each year/month combination\n",
    "pd.crosstab(all_the_queens_wasps.year_offset, all_the_queens_wasps.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n",
      "Series([], Name: municip_code, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# this loops helps verify which municipality may be missing from any given year/month combination\n",
    "for i in range(1,13,1):\n",
    "    print(df01.municip_code[~df01.municip_code.isin\\\n",
    "                  (all_the_queens_wasps.loc[(all_the_queens_wasps.month == i) &\\\n",
    "                                            (all_the_queens_wasps.year_offset == 2019),:].\\\n",
    "                   municip_code.unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_TRAIN.NESTS.sum() == df02_vespas.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_queens_wasps_PREDICT.NESTS.sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Export the TRAINING dataset for the model\n",
    "A dataset which relates the weather from a previous year (12 months ago) to an amount of NESTS in any given year (and month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_TRAIN.to_csv('WBds03_QUEENtrainMONTHS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the PREDICTION dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_queens_wasps_PREDICT.to_csv('WBds03_QUEENpredictMONTHS.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
