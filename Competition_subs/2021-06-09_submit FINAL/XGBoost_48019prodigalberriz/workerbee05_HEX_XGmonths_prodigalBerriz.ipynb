{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nkDv5dppU6B"
   },
   "source": [
    "# HEX algorithm **Kopuru Vespa Velutina Competition**\n",
    "\n",
    "**XGBoost model**\n",
    "\n",
    "Purpose: Predict the number of Nests in each of Biscay's 112 municipalities for the year 2020.\n",
    "\n",
    "Output: *(WaspBusters_20210609_batch_XGBmonths_48019prodigal.csv)*\n",
    "\n",
    "@authors:\n",
    "* mario.bejar@student.ie.edu\n",
    "* pedro.geirinhas@student.ie.edu\n",
    "* a.berrizbeitia@student.ie.edu\n",
    "* pcasaverde@student.ie.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rt-Jj2BjesTz",
    "outputId": "171cecde-0242-4aaf-82b8-0e3458dff994"
   },
   "outputs": [],
   "source": [
    "# Base packages -----------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "# Data Viz -----------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (13, 8) # to set figure size when ploting feature_importance\n",
    "\n",
    "# XGBoost -------------------------------\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance # built-in function to plot features ordered by their importance\n",
    "\n",
    "# SKLearn -----------------------------------------\n",
    "from sklearn import preprocessing # scaling data\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function that checks if final Output is ready for submission or needs revision   \n",
    "\n",
    "def check_data(HEX):\n",
    "    \n",
    "    def template_checker(HEX):\n",
    "        submission_df = (HEX[\"CODIGO MUNICIPIO\"].astype(\"string\")+HEX[\"NOMBRE MUNICIPIO\"]).sort_values().reset_index(drop=True)\n",
    "        template_df = (template[\"CODIGO MUNICIPIO\"].astype(\"string\")+template[\"NOMBRE MUNICIPIO\"]).sort_values().reset_index(drop=True)\n",
    "        check_df = pd.DataFrame({\"submission_df\":submission_df,\"template_df\":template_df})\n",
    "        check_df[\"check\"] = check_df.submission_df == check_df.template_df\n",
    "        if (check_df.check == False).any():\n",
    "            pd.options.display.max_rows = 112\n",
    "            return check_df.loc[check_df.check == False,:]\n",
    "        else:  \n",
    "            return \"All Municipality Names and Codes to be submitted match the Template\"\n",
    "    \n",
    "    print(\"Submission form Shape is\", HEX.shape)\n",
    "    print(\"Number of Municipalities is\", HEX[\"CODIGO MUNICIPIO\"].nunique())\n",
    "    print(\"The Total 2020 Nests' Prediction is\", int(HEX[\"NIDOS 2020\"].sum()))\n",
    "\n",
    "    assert HEX.shape == (112, 3), \"Error: Shape is incorrect.\"\n",
    "    assert HEX[\"CODIGO MUNICIPIO\"].nunique() == 112, \"Error: Number of unique municipalities is correct.\"    \n",
    "    return template_checker(HEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "9MLidG_FwhYB"
   },
   "outputs": [],
   "source": [
    "# Importing datasets\n",
    "\n",
    "queen_train = pd.read_csv(\"../Feeder_months/WBds03_QUEENtrainMonths.csv\", encoding=\"utf-8\") #2018+2019 test df\n",
    "queen_predict = pd.read_csv(\"../Feeder_months/WBds03_QUEENpredictMonths.csv\", encoding=\"utf-8\") #2020 prediction df\n",
    "#queen_clusters = pd.read_csv(\"../Feeder_months/WBds_CLUSTERSnests.csv\",sep=\",\")\n",
    "template = pd.read_csv(\"../../../Input_open_data/ds01_PLANTILLA-RETO-AVISPAS-KOPURU.csv\",sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for the assumptions (Clusters & Relevant Municipalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cluster labels\n",
    "\n",
    "queen_train = pd.merge(queen_train, queen_clusters, how = 'left', left_on = 'municip_code', right_on = 'municip_code')\n",
    "queen_predict = pd.merge(queen_predict, queen_clusters, how = 'left', left_on = 'municip_code', right_on = 'municip_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Municipalities to which we did not assign a Cluster, since there was no reliable data for us to predict -> Bilbao\n",
    "\n",
    "queen_train = queen_train.loc[queen_train.municip_code != 48020,:].copy()\n",
    "queen_predict = queen_predict.loc[queen_predict.municip_code != 48020,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange data into a features matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the train X & y variables\n",
    "\n",
    "# \"y\" will be the response variable (filter the number of wasp nests - \"waspbust_id\")  \n",
    "y = queen_train.NESTS\n",
    "\n",
    "# \"X\" will be the explanatory variables. Remove response variable and undesired categorical columns such as (municip code, year, etc...)\n",
    "X = queen_train.iloc[:,4:-10].drop([\"station_code\"],axis=1).copy()\n",
    "X[\"cluster\"] = queen_train.Cluster.copy()\n",
    "\n",
    "# We want to predict our response variable (number of nests in 2020). Remove response variable and undesired categorical columns such as (municip code, year, etc...)\n",
    "queen_predict2020 = queen_predict.iloc[:,4:-10].drop(\"station_code\",axis=1).copy()\n",
    "queen_predict2020[\"cluster\"] = queen_predict.Cluster.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the shape of the features and their labels match or if there are errors raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform checks of features labels & their shapes\n",
    "\n",
    "assert queen_predict2020.shape[1] == X.shape[1], \"Error: Number of columns do not match!\"\n",
    "assert (queen_predict2020.columns == X.columns).any(), \"Error: Columns labels do not match\"\n",
    "assert y.shape == (222,), \"Error: y shape is incorrect!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Step 1: Finding out the Relevant Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data for better Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the datasets using MinMaxScaler\n",
    "\n",
    "X_scaled = preprocessing.minmax_scale(X) # this creates a numpy array\n",
    "X_scaled = pd.DataFrame(X_scaled, index=X.index, columns=X.columns) # create a Pandas Dataframe == X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a class of model by importing the appropriate estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the XGBoost model and fitting with the train data\n",
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model to your data by calling the `.fit()` method of the model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the XGBoost model and fitting with the train data for each cluster\n",
    "\n",
    "model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the Relevant Variables and filtering according to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Relevant Variables in order to filter the relevant ones per Cluster\n",
    "\n",
    "# In built plot method from XGBoost\n",
    "plot_importance(model,height=0.5,xlabel=\"F-Score\",ylabel=\"Feature Importance\",grid=False)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "# Feature importance from model.feature_importances built-in attribute\n",
    "sorted_idx = model.feature_importances_.argsort()\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.barh(X_scaled.columns[sorted_idx], model.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\", fontsize=13)\n",
    "\n",
    "# Shap library Summaries\n",
    "# Shap values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_scaled)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "shap.summary_plot(shap_values, X_scaled, plot_type=\"bar\", plot_size=None, show=False)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "shap.summary_plot(shap_values, X_scaled, plot_size=None, show=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=10.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the XGBoost model and fitting with the train data without the irrelevant variables\n",
    "\n",
    "X = queen_train.loc[:, [\"population\", \"food_fruit\", \"colonies_amount\", \"weath_days_frost\", \"food_txakoli\", \"Cluster\"]].copy()\n",
    "X =  np.ascontiguousarray(X) # This line converts X to contiguous so XGBoost is not forced to convert it itself => optimize model speed and memory consumption\n",
    "\n",
    "queen_predict2020 = queen_predict.loc[:, [\"population\", \"food_fruit\", \"colonies_amount\", \"weath_days_frost\", \"food_txakoli\", \"Cluster\"]].copy()\n",
    "queen_predict2020 = np.ascontiguousarray(queen_predict2020) # This line converts X to contiguous so XGBoost is not forced to convert it itself => optimize model speed and memory consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Step 2: Prediction of 2020 Nests\n",
    "\n",
    "**Note: Variables are no longer scaled**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a class of model by importing the appropriate estimator class & Relevant Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the XGBoost model and fitting with the train data\n",
    "\n",
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearchCV to find out the best hyperparameters for our XGBoost model with our Fitted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING: TIME CONSUMING!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number homogeneous splits conducted by GridSearchCV are: 2.\n",
      "The best hyperparameters found were: {'colsample_bytree': 0.7, 'learning_rate': 0.3, 'max_depth': 8, 'min_child_weight': 0.5, 'n_estimators': 200, 'subsample': 1}.\n",
      "The best score found was: 0.2333608912456958.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.05103076, 0.04679894, 0.07347751, 0.08643031, 0.09877574,\n",
       "        0.11662865, 0.16045785, 0.20133293, 0.18913138, 0.05323887,\n",
       "        0.04672468, 0.05870509, 0.08953118, 0.11546755, 0.12483656,\n",
       "        0.16539907, 0.20070338, 0.22672284, 0.05132425, 0.05163717,\n",
       "        0.05302966, 0.08206403, 0.08927727, 0.09761763, 0.164868  ,\n",
       "        0.15799201, 0.18990123, 0.03669846, 0.04428303, 0.06704879,\n",
       "        0.08839178, 0.09183729, 0.11652076, 0.1709516 , 0.19049037,\n",
       "        0.27897823, 0.07061768, 0.04551506, 0.06982243, 0.09724569,\n",
       "        0.10499775, 0.13662958, 0.1981591 , 0.19539666, 0.23993182,\n",
       "        0.04440975, 0.04791689, 0.04476833, 0.0819515 , 0.09035861,\n",
       "        0.09769225, 0.15076172, 0.16190588, 0.20949066, 0.05337119,\n",
       "        0.05322087, 0.07834005, 0.08564925, 0.10996807, 0.14927566,\n",
       "        0.14716053, 0.21705949, 0.30592287, 0.05659294, 0.06220341,\n",
       "        0.07315493, 0.10570943, 0.12031436, 0.15468848, 0.17883098,\n",
       "        0.19898307, 0.26830125, 0.05027449, 0.04813957, 0.06247199,\n",
       "        0.07959878, 0.08650374, 0.09811568, 0.13269126, 0.17897916,\n",
       "        0.20551407, 0.05660391, 0.04825187, 0.05870903, 0.08745718,\n",
       "        0.09338796, 0.11186874, 0.14566982, 0.1826601 , 0.14440894,\n",
       "        0.05338991, 0.04765558, 0.06059611, 0.08495867, 0.10166109,\n",
       "        0.11123836, 0.17631888, 0.15456426, 0.14882684, 0.03205657,\n",
       "        0.04043567, 0.04214585, 0.07723153, 0.07977533, 0.08492887,\n",
       "        0.13167095, 0.16528964, 0.16475248, 0.04476905, 0.05308199,\n",
       "        0.06821489, 0.10039294, 0.09501576, 0.12758124, 0.18581355,\n",
       "        0.21488428, 0.16633463, 0.03793991, 0.0504514 , 0.06159544,\n",
       "        0.07808685, 0.101246  , 0.11166251, 0.15115273, 0.19641149,\n",
       "        0.13963079, 0.03552973, 0.03966892, 0.05339718, 0.07517684,\n",
       "        0.08443165, 0.10374439, 0.1416539 , 0.15608048, 0.17327523,\n",
       "        0.06539869, 0.05567873, 0.08138108, 0.08454168, 0.10865164,\n",
       "        0.10544622, 0.19566631, 0.2145946 , 0.17616606, 0.04253805,\n",
       "        0.05094242, 0.07086909, 0.08415079, 0.11795235, 0.13390088,\n",
       "        0.2010287 , 0.25202107, 0.15124094, 0.03224528, 0.05324137,\n",
       "        0.06280696, 0.08526897, 0.10360062, 0.09233797, 0.1693207 ,\n",
       "        0.16373289, 0.19622123, 0.03566003, 0.05457461, 0.06094587,\n",
       "        0.084342  , 0.08510172, 0.07998776, 0.18359208, 0.14379942,\n",
       "        0.11769581, 0.03943789, 0.0547179 , 0.05552232, 0.08435655,\n",
       "        0.08260798, 0.08446217, 0.14859855, 0.17389321, 0.10477126,\n",
       "        0.03564799, 0.04205441, 0.04472601, 0.07250369, 0.08626103,\n",
       "        0.09400988, 0.13297045, 0.16680896, 0.14906836, 0.04695094,\n",
       "        0.06018627, 0.07160294, 0.0668745 , 0.09856868, 0.08772433,\n",
       "        0.17504942, 0.18389738, 0.12552261, 0.05659604, 0.04909325,\n",
       "        0.06832302, 0.08533454, 0.09422386, 0.07945299, 0.19203806,\n",
       "        0.17596126, 0.11435127, 0.03695679, 0.04881513, 0.0541153 ,\n",
       "        0.07907712, 0.07843423, 0.09484768, 0.14814544, 0.18168604,\n",
       "        0.15276575, 0.04346728, 0.06013   , 0.0750953 , 0.08804762,\n",
       "        0.09911549, 0.09249759, 0.17443311, 0.20636392, 0.11765873,\n",
       "        0.0508064 , 0.05432415, 0.07804573, 0.08891296, 0.10084188,\n",
       "        0.07412958, 0.17625439, 0.20948529, 0.09880829, 0.03564513,\n",
       "        0.04557371, 0.05019295, 0.08018446, 0.09090686, 0.09211004,\n",
       "        0.15409744, 0.19458032, 0.14892721, 0.03755558, 0.05045807,\n",
       "        0.06030381, 0.07555282, 0.10094976, 0.1008743 , 0.15987718,\n",
       "        0.18541944, 0.20740438, 0.05904615, 0.04327583, 0.05284536,\n",
       "        0.08673084, 0.0868926 , 0.10830379, 0.15606117, 0.17183566,\n",
       "        0.22843087, 0.04127884, 0.0458622 , 0.05167627, 0.0757302 ,\n",
       "        0.08939433, 0.10555232, 0.14662194, 0.15894186, 0.1696142 ,\n",
       "        0.04391992, 0.05452108, 0.06846511, 0.10011327, 0.09868073,\n",
       "        0.13457763, 0.1876893 , 0.20155716, 0.21380877, 0.04325545,\n",
       "        0.05634844, 0.07154882, 0.11161208, 0.11782157, 0.14803207,\n",
       "        0.1486063 , 0.19862163, 0.3128463 , 0.05321062, 0.04200459,\n",
       "        0.05447626, 0.06529307, 0.10089767, 0.08440912, 0.14726102,\n",
       "        0.1684289 , 0.19157445, 0.05602765, 0.05648625, 0.07686806,\n",
       "        0.08798301, 0.12110972, 0.15230441, 0.18583786, 0.21622598,\n",
       "        0.28328192, 0.05826092, 0.05808663, 0.07456088, 0.08575666,\n",
       "        0.10616958, 0.14774978, 0.165133  , 0.22883344, 0.27197421,\n",
       "        0.04357076, 0.04519975, 0.0585376 , 0.07291424, 0.09099281,\n",
       "        0.1197747 , 0.1447649 , 0.18389261, 0.195086  , 0.050735  ,\n",
       "        0.05539691, 0.07010412, 0.08391666, 0.09508371, 0.11034179,\n",
       "        0.14774168, 0.18705428, 0.14216816, 0.05465949, 0.05692673,\n",
       "        0.06413198, 0.0754565 , 0.09689212, 0.10879958, 0.15467763,\n",
       "        0.18257368, 0.13915229, 0.04054046, 0.04805505, 0.05464947,\n",
       "        0.07227159, 0.09369731, 0.07953572, 0.13665986, 0.16027153,\n",
       "        0.18154824, 0.0519172 , 0.05848336, 0.06516409, 0.0957706 ,\n",
       "        0.10475504, 0.10959113, 0.17450798, 0.22565579, 0.13870478,\n",
       "        0.04779613, 0.05231369, 0.08217299, 0.09558535, 0.10072923,\n",
       "        0.13602424, 0.16630101, 0.19157994, 0.15852773, 0.0347681 ,\n",
       "        0.05345416, 0.05470467, 0.07757962, 0.08449101, 0.09404826,\n",
       "        0.13264918, 0.17370343, 0.18636072, 0.05591631, 0.06054127,\n",
       "        0.08644497, 0.09038174, 0.10716808, 0.13086641, 0.17392266,\n",
       "        0.21247697, 0.16339338, 0.04522169, 0.05573416, 0.07597685,\n",
       "        0.09367275, 0.11744833, 0.12188184, 0.15636575, 0.23521531,\n",
       "        0.15381479, 0.03872991, 0.04745221, 0.05542493, 0.0799278 ,\n",
       "        0.09745014, 0.10233843, 0.1508106 , 0.17334175, 0.19246733,\n",
       "        0.05475307, 0.04791605, 0.04883754, 0.08542573, 0.09022403,\n",
       "        0.08996511, 0.16731131, 0.1683085 , 0.11591089, 0.04053199,\n",
       "        0.05506003, 0.05619156, 0.08826363, 0.08083665, 0.08355737,\n",
       "        0.17528296, 0.17178559, 0.09560537, 0.03988981, 0.05084372,\n",
       "        0.04857385, 0.07578838, 0.07981062, 0.0985018 , 0.14103353,\n",
       "        0.15051949, 0.13526058, 0.04722309, 0.05633152, 0.06044626,\n",
       "        0.08498871, 0.09594786, 0.08740652, 0.16833746, 0.1833787 ,\n",
       "        0.12648582, 0.04451728, 0.05260098, 0.05620897, 0.08738482,\n",
       "        0.10065377, 0.08233464, 0.16256583, 0.18887389, 0.11848843,\n",
       "        0.03687596, 0.04675508, 0.04693902, 0.07379389, 0.08695412,\n",
       "        0.10789728, 0.15283668, 0.15531576, 0.1346947 , 0.05360067,\n",
       "        0.06003666, 0.05943906, 0.0919385 , 0.10399294, 0.08795714,\n",
       "        0.17155123, 0.18083763, 0.12282062, 0.0545634 , 0.05381978,\n",
       "        0.07059932, 0.10575914, 0.1054908 , 0.06673205, 0.18051219,\n",
       "        0.18692589, 0.10831213, 0.04194415, 0.05173361, 0.0612911 ,\n",
       "        0.06387603, 0.08934712, 0.08987248, 0.14632118, 0.16627049,\n",
       "        0.15688968, 0.03325438, 0.04203975, 0.07219934, 0.08060884,\n",
       "        0.08577836, 0.14191401, 0.15425932, 0.16943204, 0.22671998,\n",
       "        0.05519509, 0.05624902, 0.064924  , 0.07915664, 0.09699607,\n",
       "        0.11650014, 0.15620792, 0.18891323, 0.24055243, 0.04577625,\n",
       "        0.04189849, 0.04269505, 0.07756019, 0.0866158 , 0.08535016,\n",
       "        0.13064218, 0.16412175, 0.17914402, 0.05006504, 0.06478548,\n",
       "        0.05864096, 0.07900882, 0.10098875, 0.13467145, 0.17968285,\n",
       "        0.19842041, 0.21507931, 0.05177224, 0.05871642, 0.06663525,\n",
       "        0.07838964, 0.10749018, 0.13838351, 0.17509031, 0.21005321,\n",
       "        0.24312222, 0.05274069, 0.05260086, 0.05019891, 0.08631778,\n",
       "        0.09271896, 0.09440291, 0.12661445, 0.17678547, 0.1885972 ,\n",
       "        0.0531925 , 0.06005573, 0.0739361 , 0.07885313, 0.10193241,\n",
       "        0.16714132, 0.21655583, 0.24063373, 0.25920939, 0.06905317,\n",
       "        0.06303632, 0.08290362, 0.08798563, 0.10362411, 0.16900671,\n",
       "        0.18042612, 0.23908973, 0.25805068, 0.05364442, 0.05423546,\n",
       "        0.05181754, 0.06495512, 0.08316529, 0.11803317, 0.13836825,\n",
       "        0.17757273, 0.21689093, 0.05225778, 0.04630065, 0.05276501,\n",
       "        0.08071125, 0.09063196, 0.10329235, 0.16916537, 0.18128884,\n",
       "        0.13080883, 0.03660595, 0.04698336, 0.06272113, 0.09316814,\n",
       "        0.08924353, 0.10170269, 0.15817964, 0.18962216, 0.12884605,\n",
       "        0.03853953, 0.04196119, 0.04495251, 0.08698213, 0.08099687,\n",
       "        0.09098148, 0.14352763, 0.15013087, 0.15062296, 0.05410695,\n",
       "        0.04680085, 0.07620215, 0.09639347, 0.09956014, 0.11631072,\n",
       "        0.1683358 , 0.19130695, 0.13079703, 0.04422402, 0.04940379,\n",
       "        0.07204866, 0.10590696, 0.11346829, 0.11489117, 0.16972232,\n",
       "        0.18951941, 0.15718925, 0.0438782 , 0.05305254, 0.05039513,\n",
       "        0.07193267, 0.09036529, 0.08733785, 0.14451814, 0.16728354,\n",
       "        0.1683985 , 0.03777349, 0.05950284, 0.08804023, 0.08699179,\n",
       "        0.08973086, 0.11178708, 0.16987085, 0.2263099 , 0.13057458,\n",
       "        0.04756665, 0.05010307, 0.08873963, 0.08048916, 0.10378194,\n",
       "        0.11426544, 0.1798625 , 0.20394599, 0.14522469, 0.03228629,\n",
       "        0.05889714, 0.04865897, 0.06191838, 0.09589279, 0.09934402,\n",
       "        0.13984966, 0.18392146, 0.19881356, 0.03812337, 0.04093063,\n",
       "        0.06682265, 0.0809139 , 0.08528471, 0.09408188, 0.15411258,\n",
       "        0.15279233, 0.09481943, 0.0413307 , 0.04357481, 0.06113279,\n",
       "        0.07686174, 0.11339104, 0.07849228, 0.15467989, 0.1474632 ,\n",
       "        0.09425735, 0.03857601, 0.04281092, 0.04525685, 0.07458413,\n",
       "        0.09311998, 0.09098554, 0.15561783, 0.14038849, 0.11370385,\n",
       "        0.04342043, 0.05089641, 0.06593096, 0.10422134, 0.09422266,\n",
       "        0.08607709, 0.1818223 , 0.15840697, 0.11019409, 0.03697336,\n",
       "        0.05347633, 0.04881716, 0.08045006, 0.10117984, 0.07382548,\n",
       "        0.17084372, 0.17862844, 0.10386395, 0.04221559, 0.04762506,\n",
       "        0.06051338, 0.07819653, 0.08502829, 0.09908581, 0.14069271,\n",
       "        0.16388857, 0.11771417, 0.04359245, 0.06522214, 0.07417357,\n",
       "        0.10643172, 0.13309491, 0.08150589, 0.16812468, 0.15768206,\n",
       "        0.10435426, 0.04459798, 0.06191635, 0.06608629, 0.08258128,\n",
       "        0.12446022, 0.07304394, 0.19559515, 0.16428244, 0.12145734,\n",
       "        0.03505111, 0.04833877, 0.05985427, 0.07734168, 0.09014452,\n",
       "        0.09546936, 0.14619696, 0.18088329, 0.13959551]),\n",
       " 'std_fit_time': array([4.03940678e-03, 2.84981728e-03, 2.44283676e-03, 9.08398628e-03,\n",
       "        1.24275684e-03, 1.47597790e-02, 5.50389290e-03, 9.04917717e-04,\n",
       "        5.53882122e-03, 1.17263794e-02, 2.50995159e-03, 2.81071663e-03,\n",
       "        1.17902756e-02, 8.05044174e-03, 7.87198544e-03, 8.97717476e-03,\n",
       "        6.53791428e-03, 2.75813341e-02, 1.00415945e-02, 1.89375877e-03,\n",
       "        4.65285778e-03, 4.37855721e-04, 5.42712212e-03, 1.28698349e-03,\n",
       "        2.17338800e-02, 1.03553534e-02, 2.09037066e-02, 9.69767570e-04,\n",
       "        1.62827969e-03, 5.35130501e-03, 5.02872467e-03, 5.38837910e-03,\n",
       "        8.17143917e-03, 1.53582096e-02, 8.84175301e-04, 1.90459490e-02,\n",
       "        8.68296623e-03, 1.03616714e-03, 4.45997715e-03, 9.22679901e-05,\n",
       "        2.74527073e-03, 1.88384056e-02, 3.16131115e-03, 1.86514854e-03,\n",
       "        1.67465210e-03, 5.56802750e-03, 9.72747803e-05, 3.42679024e-03,\n",
       "        6.33609295e-03, 2.18307972e-03, 9.85169411e-03, 8.20696354e-03,\n",
       "        1.04955435e-02, 6.11650944e-03, 2.29406357e-03, 4.78732586e-03,\n",
       "        1.28681660e-02, 1.26287937e-02, 5.91790676e-03, 4.17363644e-03,\n",
       "        6.47664070e-03, 4.29880619e-03, 3.17585468e-03, 4.33444977e-03,\n",
       "        2.68936157e-03, 2.45809555e-04, 5.50115108e-03, 9.87267494e-03,\n",
       "        2.70116329e-03, 1.04573965e-02, 2.83348560e-03, 1.95901394e-02,\n",
       "        1.37332678e-02, 3.11064720e-03, 2.29871273e-03, 3.24642658e-03,\n",
       "        1.27527714e-02, 1.34294033e-02, 1.33959055e-02, 6.17027283e-04,\n",
       "        7.34925270e-04, 1.16467476e-02, 5.06782532e-03, 1.58727169e-03,\n",
       "        4.12654877e-03, 1.89316273e-03, 7.81333447e-03, 1.43843889e-02,\n",
       "        4.34827805e-03, 4.76241112e-03, 1.65188313e-03, 1.18350983e-03,\n",
       "        5.59127331e-03, 5.51831722e-03, 9.92178917e-04, 2.81453133e-04,\n",
       "        1.52478218e-02, 8.48591328e-03, 1.28228664e-02, 2.08163261e-03,\n",
       "        3.11410427e-03, 2.20334530e-03, 8.70823860e-04, 7.32040405e-03,\n",
       "        2.42841244e-03, 2.83646584e-03, 1.42140388e-02, 1.29437447e-03,\n",
       "        3.70454788e-03, 3.54075432e-03, 1.19075775e-02, 1.34050846e-03,\n",
       "        4.85920906e-03, 1.89864635e-03, 1.74492598e-02, 1.35798454e-02,\n",
       "        1.34253502e-02, 7.64131546e-05, 2.73907185e-03, 2.26473808e-03,\n",
       "        9.82594490e-03, 1.18063688e-02, 1.24442577e-03, 2.33876705e-03,\n",
       "        1.05654001e-02, 9.57202911e-03, 1.56867504e-03, 3.83841991e-03,\n",
       "        4.16660309e-03, 9.28282738e-04, 7.13348389e-04, 7.58397579e-03,\n",
       "        3.28171253e-03, 4.95696068e-03, 2.04412937e-02, 8.65244865e-03,\n",
       "        8.04793835e-03, 3.74078751e-03, 2.84063816e-03, 5.97405434e-03,\n",
       "        5.49852848e-03, 1.54855251e-02, 1.54528618e-02, 1.55429840e-02,\n",
       "        5.52475452e-03, 8.42928886e-03, 1.67489052e-04, 4.07552719e-03,\n",
       "        5.34057617e-05, 2.74848938e-03, 6.38997555e-03, 1.69913769e-02,\n",
       "        1.00587606e-02, 4.77671623e-04, 1.22627020e-02, 2.43198872e-03,\n",
       "        7.70568848e-03, 6.02602959e-04, 7.96139240e-03, 1.47722960e-02,\n",
       "        1.22414827e-02, 1.51169300e-03, 1.97815895e-03, 3.79204750e-04,\n",
       "        3.68106365e-03, 2.45761871e-03, 1.51697397e-02, 8.78310204e-03,\n",
       "        1.92618370e-03, 2.26271152e-03, 3.08322906e-03, 2.48014927e-03,\n",
       "        4.82547283e-03, 5.35881519e-03, 4.75859642e-03, 2.24637985e-03,\n",
       "        1.67441368e-03, 7.51292706e-03, 3.48401070e-03, 2.08246708e-03,\n",
       "        1.13928318e-03, 8.22472572e-03, 8.28707218e-03, 7.03132153e-03,\n",
       "        2.28953362e-03, 8.26311111e-03, 8.89575481e-03, 8.39829445e-04,\n",
       "        7.62724876e-03, 1.18529797e-03, 1.12894773e-02, 1.02480650e-02,\n",
       "        3.86166573e-03, 9.59897041e-03, 3.50558758e-03, 4.69696522e-03,\n",
       "        2.88760662e-03, 6.81352615e-03, 6.48593903e-03, 5.06353378e-03,\n",
       "        7.95996189e-03, 1.38177872e-02, 1.22157335e-02, 2.19011307e-03,\n",
       "        2.19202042e-02, 9.10925865e-03, 4.14514542e-03, 6.37316704e-03,\n",
       "        1.33812428e-03, 6.67572021e-06, 7.12192059e-03, 4.47034836e-04,\n",
       "        8.78667831e-03, 8.05306435e-03, 8.76307487e-04, 2.36821175e-03,\n",
       "        5.68461418e-03, 1.32048130e-03, 3.40783596e-03, 1.05906725e-02,\n",
       "        1.11941099e-02, 6.69074059e-03, 1.35627985e-02, 7.56454468e-03,\n",
       "        9.51707363e-03, 8.36491585e-04, 2.20561028e-03, 1.66141987e-03,\n",
       "        3.05628777e-03, 1.92725658e-03, 9.56296921e-04, 4.61375713e-03,\n",
       "        5.88512421e-03, 3.14879417e-03, 3.22520733e-03, 7.24363327e-03,\n",
       "        2.74932384e-03, 8.37922096e-03, 6.15072250e-03, 5.35619259e-03,\n",
       "        1.84047222e-03, 6.40392303e-04, 1.44422054e-02, 3.29387188e-03,\n",
       "        2.46083736e-03, 1.34598017e-02, 6.50298595e-03, 6.51288033e-03,\n",
       "        6.42502308e-03, 7.63773918e-04, 3.02517414e-03, 7.51829147e-03,\n",
       "        1.10995770e-03, 5.17034531e-03, 4.51672077e-03, 2.04145908e-03,\n",
       "        2.92682648e-03, 4.37474251e-03, 2.09836960e-02, 5.42807579e-03,\n",
       "        1.65787935e-02, 6.28352165e-03, 6.74867630e-03, 7.56406784e-03,\n",
       "        4.21655178e-03, 4.05502319e-03, 6.26051426e-03, 1.00660324e-02,\n",
       "        7.59065151e-03, 9.01401043e-03, 1.88767910e-03, 1.62386894e-03,\n",
       "        1.24561787e-03, 1.93893909e-03, 1.53851509e-03, 9.25099850e-03,\n",
       "        5.15937805e-04, 1.21073723e-02, 3.27634811e-03, 2.28178501e-03,\n",
       "        1.04235411e-02, 6.65271282e-03, 1.73330307e-04, 8.65113735e-03,\n",
       "        1.87135935e-02, 1.97243690e-03, 4.18674946e-03, 5.90074062e-03,\n",
       "        1.04106665e-02, 5.33533096e-03, 3.58414650e-03, 7.28845596e-03,\n",
       "        5.97321987e-03, 2.84540653e-03, 1.20376348e-02, 1.19562149e-02,\n",
       "        4.10497189e-03, 7.54833221e-04, 2.37739086e-03, 1.27272606e-02,\n",
       "        1.03365183e-02, 2.61974335e-03, 8.80837440e-03, 1.47143602e-02,\n",
       "        1.74101591e-02, 5.79631329e-03, 9.93585587e-03, 4.21476364e-03,\n",
       "        1.69205666e-03, 1.22916698e-03, 5.91814518e-03, 5.74982166e-03,\n",
       "        8.47029686e-03, 1.21164322e-03, 2.10796595e-02, 3.82018089e-03,\n",
       "        4.29213047e-03, 6.51705265e-03, 5.74505329e-03, 3.08692455e-03,\n",
       "        1.11466646e-02, 1.02696419e-02, 1.70749426e-02, 4.47511673e-04,\n",
       "        5.64670563e-03, 2.26461887e-03, 6.66618347e-04, 1.34825706e-03,\n",
       "        5.92994690e-03, 1.38678551e-02, 1.68193579e-02, 3.53229046e-03,\n",
       "        3.72660160e-03, 6.05666637e-03, 4.50468063e-03, 2.59160995e-04,\n",
       "        6.79767132e-03, 2.57611275e-03, 1.07206106e-02, 1.19662285e-03,\n",
       "        7.59804249e-03, 4.70638275e-03, 9.78493690e-03, 1.95038319e-03,\n",
       "        1.42216682e-04, 3.98588181e-03, 2.55680084e-03, 4.16588783e-03,\n",
       "        3.93867493e-04, 2.72023678e-03, 9.01544094e-03, 2.12848186e-03,\n",
       "        9.43136215e-03, 4.37736511e-03, 5.60331345e-03, 1.11190081e-02,\n",
       "        6.20210171e-03, 5.26547432e-04, 1.49433613e-02, 4.60219383e-03,\n",
       "        6.07144833e-03, 7.33268261e-03, 5.92434406e-03, 1.42674446e-02,\n",
       "        8.79836082e-03, 8.15439224e-03, 6.24418259e-04, 3.04043293e-03,\n",
       "        1.47625208e-02, 2.46524811e-03, 2.96163559e-03, 5.35821915e-03,\n",
       "        1.40289068e-02, 1.25241280e-03, 6.76894188e-03, 8.00490379e-03,\n",
       "        8.22806358e-03, 5.14018536e-03, 2.74491310e-03, 4.01616096e-04,\n",
       "        5.14614582e-03, 1.33110285e-02, 1.99091434e-03, 6.16133213e-03,\n",
       "        9.69684124e-03, 2.46798992e-02, 2.04840899e-02, 1.80232525e-03,\n",
       "        1.82390213e-04, 5.25283813e-03, 1.35750771e-02, 1.10225677e-02,\n",
       "        7.86054134e-03, 1.35236979e-02, 1.08278990e-02, 2.01036930e-02,\n",
       "        6.21414185e-03, 5.76019287e-04, 7.85207748e-03, 1.18399858e-02,\n",
       "        1.59207582e-02, 1.63233280e-03, 8.18288326e-03, 8.52441788e-03,\n",
       "        7.61806965e-03, 1.53644085e-02, 7.98642635e-03, 2.68876553e-03,\n",
       "        1.27089024e-03, 2.90846825e-03, 7.66301155e-03, 1.46101713e-02,\n",
       "        1.23603344e-02, 9.78791714e-03, 1.69694424e-03, 7.50124454e-03,\n",
       "        1.01662874e-02, 2.83777714e-03, 6.14535809e-03, 8.51869583e-04,\n",
       "        7.78388977e-03, 2.61044502e-03, 5.65910339e-03, 5.86152077e-03,\n",
       "        1.44076347e-03, 1.05797052e-02, 2.66587734e-03, 5.18774986e-03,\n",
       "        2.02548504e-03, 4.94563580e-03, 3.59141827e-03, 1.37853622e-03,\n",
       "        7.21526146e-03, 1.06847286e-03, 6.28471375e-03, 8.06295872e-03,\n",
       "        9.53400135e-03, 4.61697578e-04, 2.12823153e-02, 3.55267525e-03,\n",
       "        1.60121918e-03, 5.46574593e-03, 2.25341320e-03, 6.26242161e-03,\n",
       "        6.39235973e-03, 1.55436993e-03, 3.32844257e-03, 1.09590292e-02,\n",
       "        7.43472576e-03, 8.61084461e-03, 3.11326981e-03, 1.56760216e-03,\n",
       "        5.88428974e-03, 5.46002388e-03, 2.50434875e-03, 4.54783440e-03,\n",
       "        4.65667248e-03, 2.57766247e-03, 9.79745388e-03, 7.43114948e-03,\n",
       "        1.84059143e-03, 1.32715702e-03, 3.81636620e-03, 1.59866810e-02,\n",
       "        3.19719315e-04, 9.31048393e-03, 1.90248489e-02, 5.55872917e-03,\n",
       "        3.93974781e-03, 6.84297085e-03, 7.10248947e-04, 1.81031227e-03,\n",
       "        9.98854637e-04, 2.59435177e-03, 6.02197647e-03, 6.48474693e-03,\n",
       "        3.04579735e-03, 2.82490253e-03, 5.58364391e-03, 4.84287739e-03,\n",
       "        3.24380398e-03, 9.79185104e-04, 5.10096550e-04, 9.57608223e-04,\n",
       "        2.52079964e-03, 4.88138199e-03, 2.62975693e-04, 2.64942646e-03,\n",
       "        4.91285324e-03, 3.10516357e-03, 1.97303295e-03, 6.47151470e-03,\n",
       "        2.61604786e-03, 1.50707960e-02, 5.59794903e-03, 4.72974777e-03,\n",
       "        4.07850742e-03, 1.28362179e-02, 5.12552261e-03, 1.12040043e-02,\n",
       "        5.34296036e-04, 9.68968868e-03, 4.46331501e-03, 4.43339348e-03,\n",
       "        6.36613369e-03, 6.69169426e-03, 5.74231148e-03, 4.48441505e-03,\n",
       "        5.15031815e-03, 6.98220730e-03, 1.14002228e-02, 1.04831457e-02,\n",
       "        2.68447399e-03, 2.68125534e-03, 1.01447105e-03, 2.40683556e-03,\n",
       "        5.26094437e-03, 9.31620598e-04, 5.03540039e-04, 2.67148018e-04,\n",
       "        1.65501833e-02, 1.83272362e-02, 1.83856487e-03, 4.61781025e-03,\n",
       "        8.02075863e-03, 1.37829781e-03, 1.56441927e-02, 1.55576468e-02,\n",
       "        7.35139847e-03, 1.28030777e-04, 1.48175955e-02, 1.22915506e-02,\n",
       "        1.34873390e-03, 4.68885899e-03, 1.10385418e-02, 8.26585293e-03,\n",
       "        7.89761543e-04, 2.05457211e-03, 1.06861591e-02, 1.75077915e-02,\n",
       "        1.95467472e-03, 2.86412239e-03, 2.49993801e-03, 4.90760803e-03,\n",
       "        8.25726986e-03, 4.84979153e-03, 1.19209290e-04, 6.27732277e-03,\n",
       "        9.03320312e-03, 1.75096989e-02, 3.97717953e-03, 3.90625000e-03,\n",
       "        1.03286505e-02, 3.31878662e-03, 7.30073452e-03, 1.54933929e-02,\n",
       "        1.16975307e-02, 2.01537609e-02, 2.06007957e-02, 2.23660469e-03,\n",
       "        3.52203846e-03, 1.16932392e-03, 5.59675694e-03, 1.98669434e-02,\n",
       "        9.60838795e-03, 8.71634483e-03, 1.87027454e-03, 1.89256668e-03,\n",
       "        3.62372398e-03, 4.42659855e-03, 1.23411417e-02, 1.07769966e-02,\n",
       "        8.28397274e-03, 1.52516365e-03, 1.28029585e-02, 3.17907333e-03,\n",
       "        3.80933285e-03, 5.36692142e-03, 6.04522228e-03, 1.47640705e-03,\n",
       "        2.00593472e-03, 5.16271591e-03, 2.19094753e-03, 7.84873962e-03,\n",
       "        2.91550159e-03, 4.04655933e-03, 3.09967995e-03, 6.03950024e-03,\n",
       "        2.96008587e-03, 3.31604481e-03, 3.06701660e-03, 6.12139702e-04,\n",
       "        9.99677181e-03, 3.43763828e-03, 1.38044357e-04, 9.06062126e-03,\n",
       "        5.25712967e-04, 1.02967024e-02, 1.95205212e-03, 9.44840908e-03,\n",
       "        1.40594244e-02, 3.71897221e-03, 7.86769390e-03, 4.18949127e-03,\n",
       "        9.21130180e-04, 1.39570236e-03, 1.30369663e-02, 2.91621685e-03,\n",
       "        9.56118107e-03, 5.48911095e-03, 4.49895859e-03, 3.45706940e-06,\n",
       "        6.09993935e-04, 2.09248066e-03, 7.24089146e-03, 1.79898739e-03,\n",
       "        1.01710558e-02, 3.34680080e-03, 7.17592239e-03, 1.15823746e-02,\n",
       "        6.86514378e-03, 3.39150429e-04, 1.33063793e-02, 6.73377514e-03,\n",
       "        1.11460686e-02, 5.37860394e-03, 1.28209591e-02, 4.86087799e-03,\n",
       "        1.29805803e-02, 1.54459476e-03, 7.49301910e-03, 4.98878956e-03,\n",
       "        2.72417068e-03, 5.93161583e-03, 2.13122368e-03, 9.27281380e-03,\n",
       "        4.65655327e-03, 9.70661640e-03, 1.15455389e-02, 1.00505352e-03,\n",
       "        3.42249870e-04, 3.75831127e-03, 2.82168388e-04, 1.40535831e-03,\n",
       "        7.64369965e-03, 8.18610191e-03, 1.52047873e-02, 2.30346918e-02,\n",
       "        6.81638718e-04, 8.17894936e-04, 7.70926476e-04, 4.53293324e-03,\n",
       "        4.59265709e-03, 6.07347488e-03, 3.88884544e-03, 9.36162472e-03,\n",
       "        1.40670538e-02, 9.25743580e-03, 1.45244598e-03, 5.79798222e-03,\n",
       "        2.66444683e-03, 1.90603733e-03, 1.63829327e-03, 2.93821096e-02,\n",
       "        3.80074978e-03, 1.45034790e-02, 6.25050068e-03, 1.28006935e-03,\n",
       "        1.83916092e-03, 8.51988792e-04, 1.43939257e-02, 9.19103622e-03,\n",
       "        1.15557909e-02, 4.50396538e-03, 1.24529600e-02, 4.35483456e-03,\n",
       "        5.24926186e-03, 9.95504856e-03, 6.37292862e-04, 7.25638866e-03,\n",
       "        7.09187984e-03, 2.90632248e-04, 2.15768814e-02, 9.80103016e-03,\n",
       "        1.49309635e-03, 1.10538006e-02, 1.41978264e-03, 1.30462646e-03,\n",
       "        3.07607651e-03, 5.30838966e-04, 1.08834505e-02, 1.24094486e-02,\n",
       "        1.04932785e-02, 3.30638885e-03, 6.24418259e-03, 8.78214836e-04,\n",
       "        1.27887726e-03, 9.11986828e-03, 1.34797096e-02, 2.56443024e-03,\n",
       "        8.62181187e-03, 1.53923035e-03, 6.78443909e-03, 3.03041935e-03,\n",
       "        3.61084938e-04, 1.25637054e-02, 2.04169750e-03, 3.32009792e-03,\n",
       "        9.39178467e-03, 1.11448765e-03, 2.16543674e-03, 2.44629383e-03,\n",
       "        2.54154205e-04, 2.97951698e-03, 1.12099648e-02, 5.29646873e-03,\n",
       "        6.86323643e-03, 1.24037266e-03, 5.53309917e-03, 4.61339951e-03,\n",
       "        9.68456268e-04, 4.92918491e-03, 4.54163551e-03, 1.39280558e-02,\n",
       "        3.04114819e-03, 5.84352016e-03, 1.49238110e-03, 4.41431999e-04,\n",
       "        1.98101997e-03]),\n",
       " 'mean_score_time': array([0.00620461, 0.00424814, 0.004228  , 0.00543392, 0.00417829,\n",
       "        0.00509417, 0.00569475, 0.00469363, 0.00510752, 0.00495994,\n",
       "        0.00465   , 0.00463736, 0.00652015, 0.00750184, 0.00649142,\n",
       "        0.00490499, 0.00459099, 0.00452828, 0.00555182, 0.00530541,\n",
       "        0.00603473, 0.00411332, 0.00498128, 0.00658178, 0.0066731 ,\n",
       "        0.00448859, 0.00458026, 0.00404608, 0.00551522, 0.00337124,\n",
       "        0.00531816, 0.00592303, 0.00502694, 0.00426269, 0.00492573,\n",
       "        0.00600088, 0.00598371, 0.00377333, 0.00349128, 0.0042218 ,\n",
       "        0.00566673, 0.00429201, 0.00773227, 0.00438607, 0.00801694,\n",
       "        0.00565374, 0.003896  , 0.00366926, 0.00457978, 0.00539684,\n",
       "        0.00548482, 0.00603259, 0.00458038, 0.00961196, 0.00425053,\n",
       "        0.00313246, 0.0036937 , 0.00422168, 0.00512254, 0.00398791,\n",
       "        0.00601578, 0.00431216, 0.00947082, 0.0034529 , 0.00535333,\n",
       "        0.00511265, 0.00548661, 0.00526559, 0.00466728, 0.00451279,\n",
       "        0.00451326, 0.00875354, 0.00524437, 0.00485706, 0.00503349,\n",
       "        0.00501311, 0.00325894, 0.0047425 , 0.00500977, 0.00503719,\n",
       "        0.00643182, 0.00492704, 0.00453794, 0.00472462, 0.00401282,\n",
       "        0.00497091, 0.0053134 , 0.00520945, 0.00618052, 0.00535667,\n",
       "        0.00587749, 0.00652623, 0.00402296, 0.0057677 , 0.00395477,\n",
       "        0.00419223, 0.00443184, 0.00489533, 0.00552821, 0.00345182,\n",
       "        0.0055933 , 0.00449657, 0.00458884, 0.00373137, 0.00433266,\n",
       "        0.00513768, 0.00439513, 0.00436902, 0.0055517 , 0.0056777 ,\n",
       "        0.00542963, 0.00548887, 0.00377858, 0.00498664, 0.00579357,\n",
       "        0.00646043, 0.00517583, 0.00350928, 0.00495613, 0.00393081,\n",
       "        0.00459361, 0.00506723, 0.00414467, 0.00401354, 0.00500643,\n",
       "        0.00554466, 0.00601351, 0.00345695, 0.00453925, 0.00398958,\n",
       "        0.0050087 , 0.00401139, 0.00462842, 0.00456822, 0.00550401,\n",
       "        0.00448906, 0.00452268, 0.00348568, 0.00312567, 0.00493419,\n",
       "        0.00350356, 0.00427783, 0.00608242, 0.00416172, 0.0048275 ,\n",
       "        0.00419557, 0.00409925, 0.00499856, 0.0045172 , 0.00725687,\n",
       "        0.00383961, 0.0069896 , 0.004264  , 0.00359535, 0.00456655,\n",
       "        0.00728834, 0.00570095, 0.00450635, 0.00460625, 0.00645745,\n",
       "        0.00411069, 0.00347257, 0.00332117, 0.00598216, 0.005252  ,\n",
       "        0.00523877, 0.00383246, 0.00549531, 0.00564098, 0.00477755,\n",
       "        0.00401688, 0.00498998, 0.00444937, 0.00446773, 0.00477219,\n",
       "        0.00435948, 0.00434649, 0.0047189 , 0.0050261 , 0.0047276 ,\n",
       "        0.00590575, 0.00407398, 0.00352597, 0.00566733, 0.0075568 ,\n",
       "        0.00526917, 0.0044204 , 0.00376892, 0.00550687, 0.00408626,\n",
       "        0.0082978 , 0.00535321, 0.00383842, 0.0049963 , 0.00448811,\n",
       "        0.0042119 , 0.00493979, 0.00648761, 0.00397325, 0.00492275,\n",
       "        0.00667381, 0.00402999, 0.00548851, 0.00302017, 0.0044421 ,\n",
       "        0.00542176, 0.00445247, 0.00448787, 0.00395536, 0.00475097,\n",
       "        0.00532746, 0.00495589, 0.00549257, 0.00548005, 0.00398934,\n",
       "        0.00448287, 0.00376761, 0.0052985 , 0.00349569, 0.00442564,\n",
       "        0.00412309, 0.00390589, 0.00396562, 0.00612283, 0.00299203,\n",
       "        0.0040406 , 0.00584984, 0.00499558, 0.00449729, 0.00426114,\n",
       "        0.0039978 , 0.00299239, 0.00696063, 0.00352728, 0.00544178,\n",
       "        0.00385249, 0.00455189, 0.00568581, 0.00541639, 0.00404322,\n",
       "        0.00420666, 0.00480592, 0.00679564, 0.00358832, 0.00478852,\n",
       "        0.00406802, 0.00591838, 0.00558341, 0.00374663, 0.00399888,\n",
       "        0.00647378, 0.00510764, 0.00600982, 0.00321305, 0.0051136 ,\n",
       "        0.00450647, 0.00473106, 0.00351501, 0.00438488, 0.00406528,\n",
       "        0.00500584, 0.00448716, 0.0046016 , 0.00397611, 0.00401342,\n",
       "        0.00355184, 0.00499761, 0.00594676, 0.00649583, 0.004498  ,\n",
       "        0.00452912, 0.00508821, 0.00448966, 0.00436306, 0.00451064,\n",
       "        0.00494361, 0.00498617, 0.00500548, 0.00449967, 0.00365925,\n",
       "        0.00393128, 0.00505042, 0.00433767, 0.00493121, 0.0060786 ,\n",
       "        0.00449538, 0.00602901, 0.00559723, 0.00563562, 0.00629354,\n",
       "        0.00587523, 0.00478339, 0.00520122, 0.00375021, 0.00440013,\n",
       "        0.006338  , 0.00560176, 0.00538266, 0.00594592, 0.00395584,\n",
       "        0.00545073, 0.00400817, 0.00549972, 0.00608218, 0.00610375,\n",
       "        0.00813282, 0.00537539, 0.00551212, 0.00389695, 0.00448072,\n",
       "        0.00428843, 0.00569832, 0.00548542, 0.00596714, 0.00887907,\n",
       "        0.00513625, 0.00534678, 0.00503564, 0.00378549, 0.00401986,\n",
       "        0.00448298, 0.00598454, 0.00448251, 0.00549328, 0.00491214,\n",
       "        0.00606287, 0.00560737, 0.00498247, 0.00559902, 0.00402939,\n",
       "        0.00526845, 0.00601351, 0.0035218 , 0.00489223, 0.00512791,\n",
       "        0.00500751, 0.00442088, 0.00485444, 0.00383806, 0.00453949,\n",
       "        0.00397778, 0.00552416, 0.00396419, 0.00598419, 0.00452232,\n",
       "        0.00505638, 0.00551474, 0.0039897 , 0.00399017, 0.00540054,\n",
       "        0.00468898, 0.00398922, 0.00566959, 0.00413716, 0.00600362,\n",
       "        0.00534022, 0.00601375, 0.00397587, 0.006446  , 0.00475156,\n",
       "        0.00579512, 0.00422955, 0.00453937, 0.00542545, 0.00426841,\n",
       "        0.00618851, 0.00401366, 0.00552142, 0.00426435, 0.00474215,\n",
       "        0.00549471, 0.00563824, 0.00413442, 0.00449383, 0.00571692,\n",
       "        0.00440609, 0.0051831 , 0.00693572, 0.0038079 , 0.00353014,\n",
       "        0.00669849, 0.00453126, 0.0050441 , 0.00501215, 0.00405216,\n",
       "        0.0066731 , 0.00474453, 0.00452554, 0.00373149, 0.0044986 ,\n",
       "        0.00382912, 0.00450528, 0.00436425, 0.00452399, 0.00645447,\n",
       "        0.00531363, 0.00453603, 0.00448823, 0.00502503, 0.00579882,\n",
       "        0.00610948, 0.00659537, 0.00500524, 0.00477576, 0.00424433,\n",
       "        0.00381708, 0.00419617, 0.00425971, 0.00448763, 0.00586438,\n",
       "        0.0036037 , 0.00430393, 0.00340903, 0.00476968, 0.00490725,\n",
       "        0.00501299, 0.00501418, 0.00437212, 0.00474191, 0.00398052,\n",
       "        0.00382745, 0.00532436, 0.00669527, 0.0054723 , 0.00401425,\n",
       "        0.00458074, 0.00626004, 0.00448966, 0.00461912, 0.00502205,\n",
       "        0.00502992, 0.00561583, 0.00392687, 0.00330949, 0.00453722,\n",
       "        0.00448596, 0.00552583, 0.00462389, 0.0039525 , 0.0052017 ,\n",
       "        0.00553095, 0.00327277, 0.00450969, 0.00401402, 0.0059576 ,\n",
       "        0.00581038, 0.00597358, 0.00570643, 0.00501084, 0.00448751,\n",
       "        0.00446761, 0.00369227, 0.00517786, 0.00386441, 0.00448799,\n",
       "        0.00551629, 0.00447321, 0.00551164, 0.00556362, 0.00518537,\n",
       "        0.00453675, 0.00352716, 0.00602734, 0.00581384, 0.0059247 ,\n",
       "        0.00615478, 0.00656784, 0.00455117, 0.0054692 , 0.00494528,\n",
       "        0.00552058, 0.0045079 , 0.00478065, 0.00374579, 0.00597608,\n",
       "        0.0034256 , 0.00560153, 0.00500703, 0.0061487 , 0.00445247,\n",
       "        0.00513113, 0.00488806, 0.00522888, 0.00652921, 0.0049895 ,\n",
       "        0.00451314, 0.00426269, 0.004336  , 0.0048089 , 0.00503433,\n",
       "        0.00343728, 0.00551605, 0.00536323, 0.00547814, 0.00605571,\n",
       "        0.00517142, 0.00409555, 0.00628102, 0.00443697, 0.00548661,\n",
       "        0.004619  , 0.00471151, 0.00480139, 0.00661194, 0.00505519,\n",
       "        0.00446141, 0.00451291, 0.00487888, 0.00451493, 0.00386977,\n",
       "        0.00506437, 0.0039475 , 0.00407863, 0.00499797, 0.00484192,\n",
       "        0.00438046, 0.00402904, 0.00547874, 0.00498676, 0.00601053,\n",
       "        0.0060581 , 0.00609624, 0.00489473, 0.00391078, 0.00624979,\n",
       "        0.00349057, 0.00702417, 0.00435698, 0.00514472, 0.00494778,\n",
       "        0.00709558, 0.00424182, 0.005054  , 0.00602186, 0.00752091,\n",
       "        0.00403869, 0.00401223, 0.00492084, 0.00492668, 0.00574458,\n",
       "        0.00450349, 0.00572801, 0.00501931, 0.00441611, 0.00446212,\n",
       "        0.00698054, 0.00719154, 0.00748742, 0.00673747, 0.00566053,\n",
       "        0.00543559, 0.00442994, 0.00590456, 0.00497532, 0.00473201,\n",
       "        0.00664055, 0.00708616, 0.00748038, 0.00498676, 0.00560975,\n",
       "        0.00356317, 0.00446379, 0.00369787, 0.0039506 , 0.00550365,\n",
       "        0.00444233, 0.0063113 , 0.00643718, 0.00557125, 0.00369012,\n",
       "        0.00450504, 0.00553334, 0.00398505, 0.00481844, 0.00489116,\n",
       "        0.0069741 , 0.00301242, 0.00525069, 0.00484335, 0.0035001 ,\n",
       "        0.00291967, 0.00473905, 0.00500071, 0.00531328, 0.00362813,\n",
       "        0.00505137, 0.00456595, 0.00550127, 0.00428843, 0.00678885,\n",
       "        0.00688696, 0.00488698, 0.00400877, 0.00645506, 0.00566018,\n",
       "        0.0044961 , 0.00445306, 0.00508618, 0.00483978, 0.00299299,\n",
       "        0.00449979, 0.00595415, 0.00398481, 0.00431883, 0.00452971,\n",
       "        0.00499141, 0.00451219, 0.00602579, 0.00515497, 0.00462341,\n",
       "        0.00498533, 0.00415969, 0.00401175, 0.00469398, 0.00459993,\n",
       "        0.003649  , 0.00498736, 0.00499856, 0.00553441, 0.00477934,\n",
       "        0.00459719, 0.00483501, 0.00425744, 0.00448883, 0.00399768,\n",
       "        0.00432253, 0.0035342 , 0.00518703, 0.00749099, 0.00399148,\n",
       "        0.00458384, 0.00404203, 0.00507069, 0.00424826, 0.00465047,\n",
       "        0.00447357, 0.00573862, 0.00398171, 0.00505412, 0.00601947,\n",
       "        0.00544274, 0.00430787, 0.00428069, 0.00509655, 0.00446737,\n",
       "        0.00417101, 0.00759029, 0.00759828, 0.00419056, 0.00395203,\n",
       "        0.00572145, 0.00374269, 0.00432849, 0.00449872, 0.00349283,\n",
       "        0.00590456, 0.00345135, 0.00352097, 0.00510693, 0.00491107,\n",
       "        0.00403333, 0.00455666, 0.00437212, 0.00501156, 0.00406432,\n",
       "        0.00351405, 0.00342858, 0.00503385, 0.00530875, 0.00638485,\n",
       "        0.00498843, 0.00409627, 0.00511718, 0.00561929, 0.00474131,\n",
       "        0.0055151 , 0.00299215, 0.00448501, 0.00458181, 0.00503123,\n",
       "        0.00350595, 0.00577819, 0.0045135 , 0.0045222 , 0.00588775,\n",
       "        0.00426698, 0.00394702, 0.00462842, 0.00482988, 0.00548494,\n",
       "        0.00448692, 0.00355422, 0.00483263, 0.00354624, 0.00629091,\n",
       "        0.00506771, 0.00498664, 0.00497663, 0.00514996, 0.00580347,\n",
       "        0.00401354, 0.00476122, 0.00376546, 0.00400019, 0.00555527,\n",
       "        0.00549805, 0.00593853, 0.00448501, 0.00453043, 0.00471163,\n",
       "        0.00412631, 0.00451481, 0.00487566, 0.00377011, 0.00409377,\n",
       "        0.00395942, 0.00427532, 0.00502312, 0.00474334, 0.0059979 ,\n",
       "        0.00398827, 0.0046618 , 0.00436687, 0.00396478, 0.0071435 ,\n",
       "        0.00450468, 0.00490427, 0.00448227, 0.00465345]),\n",
       " 'std_score_time': array([3.36647034e-04, 2.57968903e-04, 7.23958015e-04, 6.29305840e-04,\n",
       "        8.08954239e-04, 1.23858452e-04, 1.23178959e-03, 3.12209129e-04,\n",
       "        1.90615654e-04, 2.70605087e-05, 1.39367580e-03, 6.45041466e-04,\n",
       "        1.53386593e-03, 5.19037247e-04, 2.50244141e-03, 8.54015350e-04,\n",
       "        1.60336494e-03, 5.18083572e-04, 1.42908096e-03, 2.82168388e-04,\n",
       "        6.49690628e-05, 1.20282173e-04, 1.66893005e-06, 4.00066376e-04,\n",
       "        4.45604324e-04, 4.97698784e-04, 4.06265259e-04, 6.79492950e-06,\n",
       "        4.68611717e-04, 4.64916229e-05, 3.34262848e-04, 1.35660172e-04,\n",
       "        4.55975533e-04, 2.68459320e-04, 6.07967377e-05, 1.95443630e-03,\n",
       "        5.96046448e-07, 2.15411186e-04, 4.98890877e-04, 1.17480755e-03,\n",
       "        6.80208206e-04, 3.00407410e-04, 2.46405602e-04, 3.49640846e-04,\n",
       "        1.29580498e-04, 1.61588192e-03, 9.04560089e-04, 6.77347183e-04,\n",
       "        5.71489334e-04, 2.40492821e-03, 4.99010086e-04, 4.85181808e-05,\n",
       "        4.09483910e-04, 1.35862827e-03, 2.61545181e-04, 1.91926956e-05,\n",
       "        8.07046890e-05, 2.30312347e-04, 9.62018967e-05, 1.00147724e-03,\n",
       "        2.00176239e-03, 2.29954720e-04, 4.98175621e-04, 4.60982323e-04,\n",
       "        6.41465187e-04, 1.09624863e-03, 7.74502754e-04, 1.27422810e-03,\n",
       "        2.94208527e-04, 4.74452972e-04, 5.21659851e-04, 2.52485275e-04,\n",
       "        2.26616859e-04, 1.08170509e-03, 9.50574875e-04, 2.63452530e-05,\n",
       "        2.74419785e-04, 1.29711628e-03, 1.03175640e-03, 9.41157341e-04,\n",
       "        4.49180603e-04, 5.90085983e-05, 4.73141670e-04, 2.62618065e-04,\n",
       "        4.84943390e-04, 1.01244450e-03, 2.66790390e-04, 2.63690948e-04,\n",
       "        1.19948387e-03, 6.27398491e-04, 3.00407410e-04, 5.41687012e-04,\n",
       "        3.87430191e-05, 1.72388554e-03, 3.63588333e-05, 2.02775002e-04,\n",
       "        5.56826591e-04, 1.39772892e-03, 1.45387650e-03, 4.61339951e-04,\n",
       "        6.05106354e-04, 1.48749352e-03, 5.81264496e-04, 9.50098038e-05,\n",
       "        4.44054604e-04, 8.37326050e-04, 6.26206398e-04, 7.31945038e-05,\n",
       "        1.53195858e-03, 7.51972198e-04, 4.42862511e-04, 1.50537491e-03,\n",
       "        2.23278999e-04, 1.19209290e-07, 2.98023224e-05, 4.81128693e-04,\n",
       "        1.13415718e-03, 5.04255295e-04, 1.05297565e-03, 2.64883041e-04,\n",
       "        6.03914261e-04, 1.07824802e-03, 7.12394714e-04, 2.38418579e-05,\n",
       "        1.01721287e-03, 1.55568123e-03, 2.70605087e-05, 4.41908836e-04,\n",
       "        1.54733658e-03, 3.57627869e-07, 1.98793411e-03, 2.19345093e-05,\n",
       "        5.58853149e-04, 5.48720360e-04, 4.77910042e-04, 1.49691105e-03,\n",
       "        4.87208366e-04, 5.06162643e-04, 8.36849213e-05, 9.23752785e-04,\n",
       "        5.15222549e-04, 2.41637230e-04, 2.09319592e-03, 7.21096992e-04,\n",
       "        1.61170959e-04, 3.03864479e-04, 5.75780869e-05, 1.00886822e-03,\n",
       "        1.46925449e-03, 8.33630562e-04, 1.02400780e-04, 1.59299374e-03,\n",
       "        2.38299370e-04, 6.03437424e-04, 4.98652458e-04, 1.21581554e-03,\n",
       "        1.68764591e-03, 6.06536865e-04, 1.56331062e-03, 1.40511990e-03,\n",
       "        2.73823738e-04, 5.16653061e-04, 6.68525696e-04, 9.96112823e-04,\n",
       "        1.75750256e-03, 1.83105469e-04, 1.67727470e-04, 5.14030457e-04,\n",
       "        1.08695030e-03, 2.78115273e-04, 5.07831573e-05, 1.13594532e-03,\n",
       "        5.40256500e-04, 1.47533417e-03, 1.96218491e-04, 7.31945038e-04,\n",
       "        2.01582909e-04, 1.19149685e-03, 3.93390656e-05, 9.10043716e-04,\n",
       "        1.57821178e-03, 1.05655193e-03, 5.00679016e-04, 4.43816185e-04,\n",
       "        4.11868095e-04, 2.33054161e-04, 4.92215157e-04, 2.22682953e-04,\n",
       "        1.51669979e-03, 1.04522705e-03, 9.31620598e-04, 3.50236893e-04,\n",
       "        1.70350075e-04, 7.86781311e-06, 4.98652458e-04, 2.25305557e-04,\n",
       "        9.29832458e-05, 1.45030022e-03, 1.59740448e-05, 9.04202461e-04,\n",
       "        4.93764877e-04, 2.40802765e-05, 1.49738789e-03, 4.44650650e-05,\n",
       "        4.54306602e-04, 9.27567482e-04, 3.68833542e-04, 4.98890877e-04,\n",
       "        3.33786011e-05, 2.54392624e-04, 4.22000885e-04, 9.28640366e-05,\n",
       "        5.17725945e-04, 5.03301620e-04, 9.97424126e-04, 5.04374504e-04,\n",
       "        7.18832016e-05, 3.10540199e-04, 5.03301620e-04, 5.62310219e-04,\n",
       "        3.22937965e-04, 2.72393227e-04, 5.79357147e-05, 1.14727020e-03,\n",
       "        1.19209290e-07, 5.11407852e-05, 1.23977661e-03, 5.72204590e-06,\n",
       "        4.88996506e-04, 7.44700432e-04, 9.60350037e-04, 1.66893005e-06,\n",
       "        2.29501724e-03, 5.08666039e-04, 3.74197960e-04, 1.36733055e-04,\n",
       "        4.36782837e-04, 3.44753265e-04, 1.69467926e-03, 8.00490379e-04,\n",
       "        7.80344009e-04, 9.32097435e-04, 1.26218796e-03, 2.31146812e-04,\n",
       "        7.99059868e-04, 7.68899918e-05, 9.21845436e-04, 5.39422035e-04,\n",
       "        2.43306160e-04, 1.00672245e-03, 1.48487091e-03, 3.88622284e-05,\n",
       "        9.28163528e-04, 2.21610069e-04, 1.94215775e-03, 1.46424770e-03,\n",
       "        3.46302986e-04, 4.73737717e-04, 4.53352928e-04, 3.52859497e-05,\n",
       "        1.04904175e-03, 1.49285793e-03, 3.54647636e-04, 3.64780426e-05,\n",
       "        2.37226486e-05, 4.77194786e-04, 9.93371010e-04, 9.58085060e-04,\n",
       "        1.50835514e-03, 5.96046448e-04, 4.85539436e-04, 2.02953815e-03,\n",
       "        5.00202179e-04, 6.77824020e-04, 4.75645065e-04, 9.54389572e-04,\n",
       "        9.97424126e-04, 1.03414059e-03, 1.66893005e-06, 3.30209732e-04,\n",
       "        9.18626785e-04, 1.57356262e-05, 1.34551525e-03, 8.34465027e-05,\n",
       "        2.07626820e-03, 1.47700310e-03, 1.98781490e-03, 4.12344933e-04,\n",
       "        2.59220600e-03, 1.69181824e-03, 2.00235844e-03, 7.46488571e-04,\n",
       "        2.99572945e-04, 7.74264336e-04, 3.90887260e-04, 1.08897686e-03,\n",
       "        1.60539150e-03, 1.32787228e-03, 1.06573105e-04, 9.17911530e-05,\n",
       "        1.56950951e-03, 2.89559364e-04, 4.84108925e-04, 1.01363659e-03,\n",
       "        2.04372406e-03, 1.94191933e-04, 1.60670280e-03, 1.36148930e-03,\n",
       "        6.08444214e-04, 4.91738319e-04, 2.35080719e-04, 1.27637386e-03,\n",
       "        4.99129295e-04, 1.97839737e-03, 1.96254253e-03, 9.76324081e-04,\n",
       "        1.35731697e-03, 9.25779343e-04, 2.51173973e-04, 5.11407852e-05,\n",
       "        4.94003296e-04, 9.98020172e-04, 4.93288040e-04, 1.50358677e-03,\n",
       "        1.43766403e-04, 1.00195408e-03, 6.21080399e-04, 2.06303596e-03,\n",
       "        1.56140327e-03, 3.81588936e-04, 1.27661228e-03, 1.94799900e-03,\n",
       "        5.28693199e-04, 9.11355019e-04, 1.08957291e-03, 2.56299973e-04,\n",
       "        5.99503517e-04, 1.35898590e-05, 1.51157379e-04, 4.51803207e-04,\n",
       "        1.01089478e-03, 2.98023224e-05, 9.72032547e-04, 3.57627869e-07,\n",
       "        1.53040886e-03, 4.86373901e-05, 5.27739525e-04, 2.38418579e-07,\n",
       "        2.38418579e-07, 4.14729118e-04, 2.97784805e-04, 9.96828079e-04,\n",
       "        6.48498535e-04, 1.47938728e-04, 1.01637840e-03, 8.29577446e-04,\n",
       "        4.97102737e-05, 5.57899475e-05, 1.44779682e-03, 5.53250313e-04,\n",
       "        1.79183483e-03, 1.32799149e-03, 4.61459160e-04, 1.57523155e-03,\n",
       "        7.17639923e-04, 1.60336494e-04, 2.41994858e-05, 4.81247902e-04,\n",
       "        2.77996063e-04, 2.44140625e-04, 5.08189201e-04, 2.48396397e-03,\n",
       "        2.63214111e-04, 4.88877296e-04, 6.71505928e-04, 4.16159630e-04,\n",
       "        8.47935677e-04, 4.97102737e-05, 5.43713570e-04, 5.10811806e-04,\n",
       "        7.14421272e-04, 5.15341759e-04, 1.03557110e-03, 1.02221966e-03,\n",
       "        4.45842743e-05, 3.06606293e-04, 7.54356384e-04, 1.45828724e-03,\n",
       "        2.57730484e-04, 5.09381294e-04, 1.44839287e-04, 1.51312351e-03,\n",
       "        6.22749329e-04, 4.63485718e-04, 4.47750092e-04, 3.28779221e-04,\n",
       "        5.27262688e-04, 4.98771667e-04, 9.00864601e-04, 1.24239922e-03,\n",
       "        1.20162964e-04, 1.12438202e-03, 1.01554394e-03, 2.20537186e-04,\n",
       "        3.18527222e-04, 1.18684769e-03, 1.93834305e-04, 7.57098198e-04,\n",
       "        4.97698784e-04, 1.41382217e-04, 5.04970551e-04, 2.70843506e-04,\n",
       "        3.43203545e-04, 6.82473183e-04, 1.67644024e-03, 1.02233887e-03,\n",
       "        8.46147537e-04, 3.82184982e-04, 2.45571136e-04, 6.83069229e-05,\n",
       "        2.07781792e-04, 1.51777267e-03, 7.84873962e-04, 1.50930882e-03,\n",
       "        2.52723694e-05, 5.75065613e-04, 7.50422478e-04, 4.99486923e-04,\n",
       "        1.10554695e-03, 1.28746033e-05, 4.31537628e-05, 1.63590908e-03,\n",
       "        3.74674797e-04, 4.95910645e-04, 5.05805016e-04, 5.00321388e-04,\n",
       "        1.58500671e-03, 1.35970116e-03, 4.17232513e-05, 1.78694725e-04,\n",
       "        1.53958797e-03, 7.02857971e-04, 5.08069992e-04, 9.72747803e-04,\n",
       "        9.70363617e-04, 1.28233433e-03, 1.00755692e-03, 1.31022930e-03,\n",
       "        9.72509384e-04, 4.99248505e-04, 4.29749489e-04, 6.59108162e-04,\n",
       "        8.38398933e-04, 6.90579414e-04, 4.98771667e-04, 1.52492523e-03,\n",
       "        5.38587570e-04, 5.23209572e-04, 1.57845020e-03, 4.31537628e-04,\n",
       "        5.22971153e-04, 5.34772873e-04, 4.35113907e-05, 8.26358795e-04,\n",
       "        9.22679901e-04, 1.58953667e-03, 2.83360481e-04, 5.62191010e-04,\n",
       "        2.47466564e-03, 5.92708588e-04, 5.35726547e-04, 4.78863716e-04,\n",
       "        5.57541847e-04, 2.43902206e-04, 9.63568687e-04, 4.34398651e-04,\n",
       "        5.87821007e-04, 1.02305412e-03, 2.15899944e-03, 4.63485718e-04,\n",
       "        6.87956810e-04, 2.22682953e-04, 7.77602196e-04, 9.84787941e-04,\n",
       "        1.24228001e-03, 4.73856926e-04, 7.59840012e-04, 6.30021095e-04,\n",
       "        9.65595245e-05, 9.49740410e-04, 4.45127487e-04, 5.80549240e-04,\n",
       "        6.20603561e-04, 4.94241714e-04, 1.06799603e-03, 1.32691860e-03,\n",
       "        1.01470947e-03, 7.87615776e-04, 4.46319580e-04, 4.99606133e-04,\n",
       "        6.42657280e-04, 3.51309776e-04, 1.84416771e-04, 5.86867332e-04,\n",
       "        1.01327896e-03, 1.64639950e-03, 5.23209572e-04, 1.05738640e-04,\n",
       "        5.25951385e-04, 1.20401382e-04, 6.49690628e-05, 9.24825668e-04,\n",
       "        6.68287277e-04, 2.00581551e-03, 6.31928444e-04, 4.99248505e-04,\n",
       "        9.84191895e-04, 5.06758690e-04, 2.38418579e-07, 2.55107880e-05,\n",
       "        2.04813480e-03, 5.39660454e-04, 1.90210342e-03, 1.10745430e-03,\n",
       "        2.93850899e-04, 4.98652458e-04, 1.04010105e-03, 3.48210335e-04,\n",
       "        1.34825706e-04, 1.16288662e-03, 1.11103058e-03, 1.24990940e-03,\n",
       "        4.24385071e-05, 9.85860825e-05, 5.35964966e-04, 1.18017197e-05,\n",
       "        2.32458115e-05, 6.54459000e-05, 8.39233398e-05, 7.57098198e-04,\n",
       "        5.13792038e-04, 7.72953033e-04, 9.96232033e-04, 5.70654869e-04,\n",
       "        5.25116920e-04, 1.99472904e-03, 1.20770931e-03, 1.53315067e-03,\n",
       "        2.19058990e-03, 1.28746033e-05, 9.08017159e-04, 5.48720360e-04,\n",
       "        6.49809837e-04, 9.86099243e-04, 4.02092934e-04, 8.28146935e-04,\n",
       "        6.63995743e-05, 4.99486923e-04, 9.97304916e-04, 6.22987747e-04,\n",
       "        4.28676605e-04, 1.01768970e-03, 2.74419785e-04, 5.81741333e-05,\n",
       "        4.80175018e-04, 5.11050224e-04, 6.70313835e-04, 6.56008720e-04,\n",
       "        1.57916546e-03, 3.12209129e-04, 4.79578972e-04, 1.97947025e-03,\n",
       "        4.64916229e-06, 2.45332718e-04, 8.34703445e-04, 1.73926353e-04,\n",
       "        2.14576721e-05, 2.06613541e-03, 1.80566311e-03, 1.73449516e-04,\n",
       "        1.45435333e-05, 4.13179398e-04, 1.15633011e-05, 1.28257275e-03,\n",
       "        3.83496284e-04, 9.32693481e-04, 1.91211700e-04, 5.15222549e-04,\n",
       "        6.87360764e-04, 1.22702122e-03, 7.37190247e-04, 9.95397568e-05,\n",
       "        4.79221344e-05, 1.13356113e-03, 6.72936440e-04, 5.07354736e-04,\n",
       "        5.35607338e-04, 1.02281570e-03, 6.11424446e-04, 1.31130219e-06,\n",
       "        4.87208366e-04, 8.00013542e-04, 4.88758087e-06, 3.29375267e-04,\n",
       "        5.40018082e-04, 9.49263573e-04, 4.76479530e-04, 9.56535339e-04,\n",
       "        1.86932087e-03, 3.72886658e-04, 4.76837158e-07, 1.70707703e-04,\n",
       "        2.22921371e-05, 7.25984573e-04, 4.88877296e-04, 9.12666321e-04,\n",
       "        1.54972076e-06, 3.73125076e-05, 1.43647194e-03, 2.06947327e-04,\n",
       "        4.36306000e-04, 3.31997871e-04, 2.67267227e-04, 4.99367714e-04,\n",
       "        7.51018524e-06, 2.88009644e-04, 4.77433205e-04, 1.19805336e-03,\n",
       "        1.35028362e-03, 2.26497650e-06, 6.77347183e-04, 1.05011463e-03,\n",
       "        1.08027458e-03, 1.57713890e-04, 6.60777092e-04, 5.12957573e-04,\n",
       "        7.51852989e-04, 2.37226486e-05, 1.37090683e-05, 1.01912022e-03,\n",
       "        1.52170658e-03, 2.70724297e-04, 2.74300575e-04, 5.70893288e-04,\n",
       "        4.33564186e-04, 6.21080399e-05, 3.60178947e-03, 5.22971153e-04,\n",
       "        1.74164772e-04, 1.08385086e-03, 3.30328941e-04, 7.51018524e-04,\n",
       "        8.02040100e-04, 4.87804413e-04, 5.73873520e-04, 1.91605091e-03,\n",
       "        4.06026840e-04, 4.81128693e-04, 1.62339211e-03, 1.25765800e-04,\n",
       "        1.33514404e-05, 4.81843948e-04, 8.41617584e-04, 9.73463058e-04,\n",
       "        9.72986221e-04, 4.77313995e-04, 4.48822975e-04, 2.22086906e-04,\n",
       "        7.26580620e-04, 3.39746475e-04, 9.98258591e-04, 1.06334686e-04,\n",
       "        1.61433220e-03, 3.03268433e-04, 1.24371052e-03, 1.52564049e-03,\n",
       "        2.38418579e-07, 4.95314598e-04, 5.91158867e-04, 1.46353245e-03,\n",
       "        5.11646271e-04, 6.88433647e-04, 5.24282455e-04, 6.26206398e-04,\n",
       "        1.39403343e-03, 6.91890717e-04, 8.84532928e-05, 6.38723373e-04,\n",
       "        1.14822388e-03, 1.49619579e-03, 4.97460365e-04, 4.35233116e-04,\n",
       "        1.00970268e-04, 5.54323196e-04, 7.20739365e-04, 2.07579136e-03,\n",
       "        9.97424126e-04, 9.69529152e-04, 1.22606754e-03, 6.97374344e-05,\n",
       "        2.21729279e-05, 1.19805336e-03, 7.24434853e-04, 8.58306885e-06,\n",
       "        5.65409660e-04, 1.48594379e-03, 9.98973846e-05, 5.02705574e-04,\n",
       "        5.05685806e-04, 8.29696655e-04, 1.13487244e-03, 4.76717949e-04,\n",
       "        1.69754028e-04, 2.19345093e-04, 1.05023384e-04, 6.67572021e-05,\n",
       "        7.63416290e-04, 3.58819962e-05, 7.53879547e-04, 1.43051147e-05,\n",
       "        9.95874405e-04, 4.28438187e-04, 4.24385071e-05, 6.13927841e-05,\n",
       "        2.82907486e-03, 5.13553619e-04, 3.31640244e-04, 4.91142273e-04,\n",
       "        1.06024742e-03]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5,\n",
       "                    1.5, 1.5, 1.5, 1.5, 1.5, 1.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50,\n",
       "                    100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50, 50,\n",
       "                    50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100, 100,\n",
       "                    100, 200, 200, 200, 50, 50, 50, 100, 100, 100, 200,\n",
       "                    200, 200, 50, 50, 50, 100, 100, 100, 200, 200, 200, 50,\n",
       "                    50, 50, 100, 100, 100, 200, 200, 200, 50, 50, 50, 100,\n",
       "                    100, 100, 200, 200, 200, 50, 50, 50, 100, 100, 100,\n",
       "                    200, 200, 200, 50, 50, 50, 100, 100, 100, 200, 200,\n",
       "                    200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1,\n",
       "                    0.3, 0.5, 1, 0.3, 0.5, 1, 0.3, 0.5, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.3},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1}],\n",
       " 'split0_test_score': array([ 0.10070126, -0.05649909,  0.09475561, -0.00933123, -0.12140346,\n",
       "         0.08847305, -0.04954089, -0.1490373 ,  0.08745743,  0.10070126,\n",
       "        -0.05649909,  0.09475561, -0.00933123, -0.12140346,  0.08847305,\n",
       "        -0.04954089, -0.1490373 ,  0.08745743,  0.06108735,  0.08458785,\n",
       "         0.11148566,  0.03264759, -0.02648737,  0.08102234, -0.03948198,\n",
       "        -0.09020567,  0.07585623,  0.13439368, -0.00492665,  0.10822035,\n",
       "         0.04419537, -0.0720294 ,  0.10128779,  0.00649576, -0.10084355,\n",
       "         0.10108678,  0.13439368, -0.00492665,  0.10822035,  0.04419537,\n",
       "        -0.0720294 ,  0.10128779,  0.00649576, -0.10084355,  0.10108678,\n",
       "         0.06468876,  0.09682658,  0.09765554,  0.02766668, -0.01554121,\n",
       "         0.07118806, -0.05827676, -0.06815745,  0.06752625,  0.07028561,\n",
       "        -0.04593866,  0.09212151, -0.0145857 , -0.12342314,  0.08473133,\n",
       "        -0.06985365, -0.15308585,  0.08456361,  0.07028561, -0.04593866,\n",
       "         0.09212151, -0.0145857 , -0.12342314,  0.08473133, -0.06985365,\n",
       "        -0.15308585,  0.08456361,  0.06915193,  0.07923385,  0.0950954 ,\n",
       "         0.01663269, -0.02751221,  0.06662536, -0.01172236, -0.09186405,\n",
       "         0.06040972, -0.05625501, -0.18571628,  0.1010024 , -0.14884917,\n",
       "        -0.21882703,  0.10077126, -0.15370265, -0.21979753,  0.10075878,\n",
       "        -0.05625501, -0.18571628,  0.1010024 , -0.14884917, -0.21882703,\n",
       "         0.10077126, -0.15370265, -0.21979753,  0.10075878, -0.03231574,\n",
       "        -0.0772125 ,  0.11416983, -0.17492916, -0.1560543 ,  0.10887621,\n",
       "        -0.2267849 , -0.16580282,  0.10766852,  0.08436042, -0.07980698,\n",
       "         0.13962372,  0.07128279, -0.10307282,  0.13950562,  0.07592062,\n",
       "        -0.10511198,  0.13950562,  0.08436042, -0.07980698,  0.13962372,\n",
       "         0.07128279, -0.10307282,  0.13950562,  0.07592062, -0.10511198,\n",
       "         0.13950562, -0.01959446, -0.05675383,  0.10369767, -0.14826956,\n",
       "        -0.1313267 ,  0.09899239, -0.19216483, -0.13860369,  0.09786184,\n",
       "         0.03470028, -0.17359834,  0.12115773,  0.03767255, -0.20715478,\n",
       "         0.12102597,  0.01701388, -0.20971262,  0.12102597,  0.03470028,\n",
       "        -0.17359834,  0.12115773,  0.03767255, -0.20715478,  0.12102597,\n",
       "         0.01701388, -0.20971262,  0.12102597,  0.00447465, -0.01533563,\n",
       "         0.11299093, -0.10432094, -0.12462927,  0.10878721, -0.08927967,\n",
       "        -0.14225281,  0.10758652, -0.19634596, -0.19058457,  0.09219751,\n",
       "        -0.2251671 , -0.19338691,  0.09220368, -0.22965092, -0.19341028,\n",
       "         0.09220368, -0.19634596, -0.19058457,  0.09219751, -0.2251671 ,\n",
       "        -0.19338691,  0.09220368, -0.22965092, -0.19341028,  0.09220368,\n",
       "        -0.1596919 , -0.32566047,  0.03114117, -0.15648104, -0.35059338,\n",
       "         0.02949826, -0.14609038, -0.35642963,  0.0292147 , -0.2241164 ,\n",
       "        -0.31065241,  0.12316954, -0.24371945, -0.32575843,  0.12316952,\n",
       "        -0.24186673, -0.32566224,  0.12316952, -0.2241164 , -0.31065241,\n",
       "         0.12316954, -0.24371945, -0.32575843,  0.12316952, -0.24186673,\n",
       "        -0.32566224,  0.12316952, -0.22905961, -0.29158913,  0.11243977,\n",
       "        -0.33856005, -0.33268035,  0.11165468, -0.30807775, -0.33304091,\n",
       "         0.11156771, -0.20762066, -0.23438362,  0.13908012, -0.22527343,\n",
       "        -0.23034794,  0.13908008, -0.2168196 , -0.23050694,  0.13908008,\n",
       "        -0.20762066, -0.23438362,  0.13908012, -0.22527343, -0.23034794,\n",
       "         0.13908008, -0.2168196 , -0.23050694,  0.13908008, -0.0520563 ,\n",
       "        -0.27707913,  0.10481725, -0.08030616, -0.31149418,  0.10341587,\n",
       "        -0.05880829, -0.31667483,  0.10330318,  0.10070126, -0.05649909,\n",
       "         0.09475561, -0.00933123, -0.12140346,  0.08847305, -0.04954089,\n",
       "        -0.1490373 ,  0.08745743,  0.10070126, -0.05649909,  0.09475561,\n",
       "        -0.00933123, -0.12140346,  0.08847305, -0.04954089, -0.1490373 ,\n",
       "         0.08745743,  0.06108735,  0.08458785,  0.11148566,  0.03264759,\n",
       "        -0.02648737,  0.08102234, -0.03948198, -0.09020567,  0.07585623,\n",
       "         0.13439368, -0.00492665,  0.10822035,  0.04419537, -0.0720294 ,\n",
       "         0.10128779,  0.00649576, -0.10084355,  0.10108678,  0.13439368,\n",
       "        -0.00492665,  0.10822035,  0.04419537, -0.0720294 ,  0.10128779,\n",
       "         0.00649576, -0.10084355,  0.10108678,  0.06468876,  0.09682658,\n",
       "         0.09765554,  0.02766668, -0.01554121,  0.07118806, -0.05827676,\n",
       "        -0.06815745,  0.06752625,  0.07028561, -0.04593866,  0.09212151,\n",
       "        -0.0145857 , -0.12342314,  0.08473133, -0.06985365, -0.15308585,\n",
       "         0.08456361,  0.07028561, -0.04593866,  0.09212151, -0.0145857 ,\n",
       "        -0.12342314,  0.08473133, -0.06985365, -0.15308585,  0.08456361,\n",
       "         0.06915193,  0.07923385,  0.0950954 ,  0.01663269, -0.02751221,\n",
       "         0.06662536, -0.01172236, -0.09186405,  0.06040972, -0.05625501,\n",
       "        -0.18571628,  0.1010024 , -0.14884917, -0.21882703,  0.10077126,\n",
       "        -0.15370265, -0.21979753,  0.10075878, -0.05625501, -0.18571628,\n",
       "         0.1010024 , -0.14884917, -0.21882703,  0.10077126, -0.15370265,\n",
       "        -0.21979753,  0.10075878, -0.03231574, -0.0772125 ,  0.11416983,\n",
       "        -0.17492916, -0.1560543 ,  0.10887621, -0.2267849 , -0.16580282,\n",
       "         0.10766852,  0.08436042, -0.07980698,  0.13962372,  0.07128279,\n",
       "        -0.10307282,  0.13950562,  0.07592062, -0.10511198,  0.13950562,\n",
       "         0.08436042, -0.07980698,  0.13962372,  0.07128279, -0.10307282,\n",
       "         0.13950562,  0.07592062, -0.10511198,  0.13950562, -0.01959446,\n",
       "        -0.05675383,  0.10369767, -0.14826956, -0.1313267 ,  0.09899239,\n",
       "        -0.19216483, -0.13860369,  0.09786184,  0.03470028, -0.17359834,\n",
       "         0.12115773,  0.03767255, -0.20715478,  0.12102597,  0.01701388,\n",
       "        -0.20971262,  0.12102597,  0.03470028, -0.17359834,  0.12115773,\n",
       "         0.03767255, -0.20715478,  0.12102597,  0.01701388, -0.20971262,\n",
       "         0.12102597,  0.00447465, -0.01533563,  0.11299093, -0.10432094,\n",
       "        -0.12462927,  0.10878721, -0.08927967, -0.14225281,  0.10758652,\n",
       "        -0.19634596, -0.19058457,  0.09219751, -0.2251671 , -0.19338691,\n",
       "         0.09220368, -0.22965092, -0.19341028,  0.09220368, -0.19634596,\n",
       "        -0.19058457,  0.09219751, -0.2251671 , -0.19338691,  0.09220368,\n",
       "        -0.22965092, -0.19341028,  0.09220368, -0.1596919 , -0.32566047,\n",
       "         0.03114117, -0.15648104, -0.35059338,  0.02949826, -0.14609038,\n",
       "        -0.35642963,  0.0292147 , -0.2241164 , -0.31065241,  0.12316954,\n",
       "        -0.24371945, -0.32575843,  0.12316952, -0.24186673, -0.32566224,\n",
       "         0.12316952, -0.2241164 , -0.31065241,  0.12316954, -0.24371945,\n",
       "        -0.32575843,  0.12316952, -0.24186673, -0.32566224,  0.12316952,\n",
       "        -0.22905961, -0.29158913,  0.11243977, -0.33856005, -0.33268035,\n",
       "         0.11165468, -0.30807775, -0.33304091,  0.11156771, -0.20762066,\n",
       "        -0.23438362,  0.13908012, -0.22527343, -0.23034794,  0.13908008,\n",
       "        -0.2168196 , -0.23050694,  0.13908008, -0.20762066, -0.23438362,\n",
       "         0.13908012, -0.22527343, -0.23034794,  0.13908008, -0.2168196 ,\n",
       "        -0.23050694,  0.13908008, -0.0520563 , -0.27707913,  0.10481725,\n",
       "        -0.08030616, -0.31149418,  0.10341587, -0.05880829, -0.31667483,\n",
       "         0.10330318,  0.01108559,  0.01145623, -0.16518408, -0.07855484,\n",
       "        -0.04926415, -0.17740944, -0.13080252, -0.06826802, -0.17812585,\n",
       "         0.01108559,  0.01145623, -0.16518408, -0.07855484, -0.04926415,\n",
       "        -0.17740944, -0.13080252, -0.06826802, -0.17812585,  0.07641764,\n",
       "         0.03705561, -0.10209072, -0.01845628, -0.0535876 , -0.12407005,\n",
       "        -0.12391618, -0.10223629, -0.12932843,  0.03161475, -0.01289923,\n",
       "        -0.19080581,  0.00631791, -0.07247057, -0.20759579, -0.09328286,\n",
       "        -0.09923748, -0.20783525,  0.03161475, -0.01289923, -0.19080581,\n",
       "         0.00631791, -0.07247057, -0.20759579, -0.09328286, -0.09923748,\n",
       "        -0.20783525,  0.06476813,  0.04643821, -0.07185103,  0.01092613,\n",
       "        -0.02575485, -0.10235394, -0.09829397, -0.06362245, -0.10860151,\n",
       "         0.02318762, -0.01802868, -0.1690756 ,  0.01733467, -0.05336283,\n",
       "        -0.18856927, -0.0970603 , -0.07519367, -0.18893386,  0.02318762,\n",
       "        -0.01802868, -0.1690756 ,  0.01733467, -0.05336283, -0.18856927,\n",
       "        -0.0970603 , -0.07519367, -0.18893386,  0.03184969,  0.00544803,\n",
       "        -0.04999454,  0.00563007, -0.06835797, -0.07741548, -0.09278995,\n",
       "        -0.11734401, -0.08525298,  0.05817447, -0.09119713, -0.21234003,\n",
       "         0.00204002, -0.12314413, -0.21244267, -0.0451548 , -0.12570311,\n",
       "        -0.21244385,  0.05817447, -0.09119713, -0.21234003,  0.00204002,\n",
       "        -0.12314413, -0.21244267, -0.0451548 , -0.12570311, -0.21244385,\n",
       "        -0.0217606 , -0.03318506, -0.05925602, -0.09403493, -0.07404162,\n",
       "        -0.06429748, -0.15347573, -0.08253457, -0.06476485,  0.00251621,\n",
       "        -0.09456831, -0.28098302, -0.06081049, -0.11754449, -0.28121159,\n",
       "        -0.09851431, -0.11873203, -0.28121159,  0.00251621, -0.09456831,\n",
       "        -0.28098302, -0.06081049, -0.11754449, -0.28121159, -0.09851431,\n",
       "        -0.11873203, -0.28121159, -0.10189816, -0.08002229, -0.10504641,\n",
       "        -0.20372181, -0.14334683, -0.11253299, -0.28884107, -0.15236261,\n",
       "        -0.11301291,  0.0572671 , -0.0710684 , -0.29592307, -0.02327077,\n",
       "        -0.09353735, -0.29627844, -0.06805877, -0.09546165, -0.29627844,\n",
       "         0.0572671 , -0.0710684 , -0.29592307, -0.02327077, -0.09353735,\n",
       "        -0.29627844, -0.06805877, -0.09546165, -0.29627844, -0.03072155,\n",
       "        -0.05390058, -0.12551306, -0.09709265, -0.11763488, -0.1294147 ,\n",
       "        -0.12873964, -0.12998205, -0.12965623, -0.18625649, -0.20477369,\n",
       "        -0.28225118, -0.23702794, -0.20608379, -0.28229366, -0.25964039,\n",
       "        -0.20630417, -0.28229366, -0.18625649, -0.20477369, -0.28225118,\n",
       "        -0.23702794, -0.20608379, -0.28229366, -0.25964039, -0.20630417,\n",
       "        -0.28229366, -0.13756997, -0.28301814, -0.14630105, -0.19814948,\n",
       "        -0.3068431 , -0.14772387, -0.23759637, -0.31022813, -0.14777746,\n",
       "        -0.21344246, -0.30475562, -0.40383764, -0.29484132, -0.30747209,\n",
       "        -0.40383767, -0.31240393, -0.307565  , -0.40383767, -0.21344246,\n",
       "        -0.30475562, -0.40383764, -0.29484132, -0.30747209, -0.40383767,\n",
       "        -0.31240393, -0.307565  , -0.40383767, -0.02220793, -0.31817439,\n",
       "        -0.11540235, -0.08539716, -0.33952029, -0.11671327, -0.14249918,\n",
       "        -0.35091173, -0.11670889, -0.17577198, -0.42057124, -0.38844966,\n",
       "        -0.21871688, -0.43139091, -0.38844966, -0.23449344, -0.431534  ,\n",
       "        -0.38844966, -0.17577198, -0.42057124, -0.38844966, -0.21871688,\n",
       "        -0.43139091, -0.38844966, -0.23449344, -0.431534  , -0.38844966,\n",
       "        -0.02432238, -0.16536675, -0.16615204, -0.13733736, -0.18235467,\n",
       "        -0.16748706, -0.13769796, -0.17916654, -0.16748983]),\n",
       " 'split1_test_score': array([ 0.12721124,  0.27635138,  0.20231133,  0.14937809,  0.29580862,\n",
       "         0.20689176,  0.18744845,  0.29728751,  0.20940839,  0.12721124,\n",
       "         0.27635138,  0.20231133,  0.14937809,  0.29580862,  0.20689176,\n",
       "         0.18744845,  0.29728751,  0.20940839,  0.10750073,  0.21118831,\n",
       "         0.28469815,  0.15727047,  0.21393095,  0.30592612,  0.11892488,\n",
       "         0.2255884 ,  0.30892146,  0.10866619,  0.26171474,  0.24991626,\n",
       "         0.12963616,  0.28463841,  0.25854748,  0.12146036,  0.28360144,\n",
       "         0.259159  ,  0.10866619,  0.26171474,  0.24991626,  0.12963616,\n",
       "         0.28463841,  0.25854748,  0.12146036,  0.28360144,  0.259159  ,\n",
       "         0.16542439,  0.23668337,  0.29219502,  0.18555792,  0.27023541,\n",
       "         0.29905116,  0.17726124,  0.29834422,  0.30001716,  0.09675983,\n",
       "         0.28759001,  0.24363269,  0.16173611,  0.29253644,  0.24935026,\n",
       "         0.17889317,  0.2976706 ,  0.24982604,  0.09675983,  0.28759001,\n",
       "         0.24363269,  0.16173611,  0.29253644,  0.24935026,  0.17889317,\n",
       "         0.2976706 ,  0.24982604,  0.16512681,  0.16636892,  0.29272244,\n",
       "         0.20977227,  0.20763601,  0.29631638,  0.19904767,  0.23084308,\n",
       "         0.29803449,  0.09988397,  0.16510402,  0.28358488,  0.17070879,\n",
       "         0.18485735,  0.28551336,  0.21055619,  0.1850939 ,  0.28560799,\n",
       "         0.09988397,  0.16510402,  0.28358488,  0.17070879,  0.18485735,\n",
       "         0.28551336,  0.21055619,  0.1850939 ,  0.28560799, -0.05589929,\n",
       "         0.14263901,  0.34153104, -0.01521891,  0.15402597,  0.34691311,\n",
       "        -0.02863906,  0.12208719,  0.34788602,  0.11012023,  0.16746368,\n",
       "         0.32633439,  0.16858404,  0.18710728,  0.32720898,  0.16061319,\n",
       "         0.19051911,  0.32721617,  0.11012023,  0.16746368,  0.32633439,\n",
       "         0.16858404,  0.18710728,  0.32720898,  0.16061319,  0.19051911,\n",
       "         0.32721617, -0.18251452,  0.15455135,  0.35464779, -0.09625457,\n",
       "         0.18153967,  0.35903502, -0.08861275,  0.17632693,  0.35977611,\n",
       "         0.20233491,  0.19900839,  0.31539235,  0.08359409,  0.21876886,\n",
       "         0.31593726,  0.03709942,  0.22133715,  0.31593725,  0.20233491,\n",
       "         0.19900839,  0.31539235,  0.08359409,  0.21876886,  0.31593726,\n",
       "         0.03709942,  0.22133715,  0.31593725, -0.08749386,  0.23428167,\n",
       "         0.33592658, -0.1025661 ,  0.26116739,  0.33948887, -0.09608507,\n",
       "         0.27062277,  0.33970961, -0.25950113, -0.00622391,  0.21929255,\n",
       "        -0.27733594,  0.0092208 ,  0.21950109, -0.28066924,  0.00970521,\n",
       "         0.2195011 , -0.25950113, -0.00622391,  0.21929255, -0.27733594,\n",
       "         0.0092208 ,  0.21950109, -0.28066924,  0.00970521,  0.2195011 ,\n",
       "        -0.22552252, -0.16641863,  0.25589468, -0.0942357 , -0.17703418,\n",
       "         0.25465041, -0.29998416, -0.17382819,  0.25438099, -0.22366246,\n",
       "        -0.02358753,  0.24814794, -0.22077943, -0.01571034,  0.24823459,\n",
       "        -0.18938732, -0.01592363,  0.24823459, -0.22366246, -0.02358753,\n",
       "         0.24814794, -0.22077943, -0.01571034,  0.24823459, -0.18938732,\n",
       "        -0.01592363,  0.24823459, -0.06650609, -0.49822593,  0.2536278 ,\n",
       "        -0.08691085, -0.49167985,  0.25470527, -0.21192395, -0.4682956 ,\n",
       "         0.25463234,  0.0510984 , -0.0230982 ,  0.24063848,  0.01955648,\n",
       "        -0.0217954 ,  0.24064358,  0.03806881, -0.0220539 ,  0.24064358,\n",
       "         0.0510984 , -0.0230982 ,  0.24063848,  0.01955648, -0.0217954 ,\n",
       "         0.24064358,  0.03806881, -0.0220539 ,  0.24064358, -0.16412115,\n",
       "        -0.21336457,  0.308097  , -0.09698221, -0.20288766,  0.30968353,\n",
       "        -0.10189712, -0.22855022,  0.30971241,  0.12721124,  0.27635138,\n",
       "         0.20231133,  0.14937809,  0.29580862,  0.20689176,  0.18744845,\n",
       "         0.29728751,  0.20940839,  0.12721124,  0.27635138,  0.20231133,\n",
       "         0.14937809,  0.29580862,  0.20689176,  0.18744845,  0.29728751,\n",
       "         0.20940839,  0.10750073,  0.21118831,  0.28469815,  0.15727047,\n",
       "         0.21393095,  0.30592612,  0.11892488,  0.2255884 ,  0.30892146,\n",
       "         0.10866619,  0.26171474,  0.24991626,  0.12963616,  0.28463841,\n",
       "         0.25854748,  0.12146036,  0.28360144,  0.259159  ,  0.10866619,\n",
       "         0.26171474,  0.24991626,  0.12963616,  0.28463841,  0.25854748,\n",
       "         0.12146036,  0.28360144,  0.259159  ,  0.16542439,  0.23668337,\n",
       "         0.29219502,  0.18555792,  0.27023541,  0.29905116,  0.17726124,\n",
       "         0.29834422,  0.30001716,  0.09675983,  0.28759001,  0.24363269,\n",
       "         0.16173611,  0.29253644,  0.24935026,  0.17889317,  0.2976706 ,\n",
       "         0.24982604,  0.09675983,  0.28759001,  0.24363269,  0.16173611,\n",
       "         0.29253644,  0.24935026,  0.17889317,  0.2976706 ,  0.24982604,\n",
       "         0.16512681,  0.16636892,  0.29272244,  0.20977227,  0.20763601,\n",
       "         0.29631638,  0.19904767,  0.23084308,  0.29803449,  0.09988397,\n",
       "         0.16510402,  0.28358488,  0.17070879,  0.18485735,  0.28551336,\n",
       "         0.21055619,  0.1850939 ,  0.28560799,  0.09988397,  0.16510402,\n",
       "         0.28358488,  0.17070879,  0.18485735,  0.28551336,  0.21055619,\n",
       "         0.1850939 ,  0.28560799, -0.05589929,  0.14263901,  0.34153104,\n",
       "        -0.01521891,  0.15402597,  0.34691311, -0.02863906,  0.12208719,\n",
       "         0.34788602,  0.11012023,  0.16746368,  0.32633439,  0.16858404,\n",
       "         0.18710728,  0.32720898,  0.16061319,  0.19051911,  0.32721617,\n",
       "         0.11012023,  0.16746368,  0.32633439,  0.16858404,  0.18710728,\n",
       "         0.32720898,  0.16061319,  0.19051911,  0.32721617, -0.18251452,\n",
       "         0.15455135,  0.35464779, -0.09625457,  0.18153967,  0.35903502,\n",
       "        -0.08861275,  0.17632693,  0.35977611,  0.20233491,  0.19900839,\n",
       "         0.31539235,  0.08359409,  0.21876886,  0.31593726,  0.03709942,\n",
       "         0.22133715,  0.31593725,  0.20233491,  0.19900839,  0.31539235,\n",
       "         0.08359409,  0.21876886,  0.31593726,  0.03709942,  0.22133715,\n",
       "         0.31593725, -0.08749386,  0.23428167,  0.33592658, -0.1025661 ,\n",
       "         0.26116739,  0.33948887, -0.09608507,  0.27062277,  0.33970961,\n",
       "        -0.25950113, -0.00622391,  0.21929255, -0.27733594,  0.0092208 ,\n",
       "         0.21950109, -0.28066924,  0.00970521,  0.2195011 , -0.25950113,\n",
       "        -0.00622391,  0.21929255, -0.27733594,  0.0092208 ,  0.21950109,\n",
       "        -0.28066924,  0.00970521,  0.2195011 , -0.22552252, -0.16641863,\n",
       "         0.25589468, -0.0942357 , -0.17703418,  0.25465041, -0.29998416,\n",
       "        -0.17382819,  0.25438099, -0.22366246, -0.02358753,  0.24814794,\n",
       "        -0.22077943, -0.01571034,  0.24823459, -0.18938732, -0.01592363,\n",
       "         0.24823459, -0.22366246, -0.02358753,  0.24814794, -0.22077943,\n",
       "        -0.01571034,  0.24823459, -0.18938732, -0.01592363,  0.24823459,\n",
       "        -0.06650609, -0.49822593,  0.2536278 , -0.08691085, -0.49167985,\n",
       "         0.25470527, -0.21192395, -0.4682956 ,  0.25463234,  0.0510984 ,\n",
       "        -0.0230982 ,  0.24063848,  0.01955648, -0.0217954 ,  0.24064358,\n",
       "         0.03806881, -0.0220539 ,  0.24064358,  0.0510984 , -0.0230982 ,\n",
       "         0.24063848,  0.01955648, -0.0217954 ,  0.24064358,  0.03806881,\n",
       "        -0.0220539 ,  0.24064358, -0.16412115, -0.21336457,  0.308097  ,\n",
       "        -0.09698221, -0.20288766,  0.30968353, -0.10189712, -0.22855022,\n",
       "         0.30971241,  0.03586884,  0.19177574,  0.04453579,  0.18353107,\n",
       "         0.21658481,  0.04461848,  0.19004589,  0.22867216,  0.0450318 ,\n",
       "         0.03586884,  0.19177574,  0.04453579,  0.18353107,  0.21658481,\n",
       "         0.04461848,  0.19004589,  0.22867216,  0.0450318 ,  0.01716169,\n",
       "         0.11005277,  0.02489229,  0.13050874,  0.16431761,  0.04153093,\n",
       "         0.17276482,  0.15815923,  0.04611703, -0.06155825,  0.16828085,\n",
       "         0.04769574,  0.14463894,  0.20112009,  0.04880712,  0.15132807,\n",
       "         0.20621667,  0.04901973, -0.06155825,  0.16828085,  0.04769574,\n",
       "         0.14463894,  0.20112009,  0.04880712,  0.15132807,  0.20621667,\n",
       "         0.04901973, -0.02663147,  0.07090808,  0.0203402 ,  0.0280599 ,\n",
       "         0.13118262,  0.03501467,  0.04674137,  0.12795773,  0.04137405,\n",
       "         0.00355042,  0.14836138,  0.04919963,  0.13825111,  0.18569008,\n",
       "         0.05082407,  0.12310615,  0.19694511,  0.05103904,  0.00355042,\n",
       "         0.14836138,  0.04919963,  0.13825111,  0.18569008,  0.05082407,\n",
       "         0.12310615,  0.19694511,  0.05103904,  0.00079386,  0.10107851,\n",
       "        -0.03652867,  0.12402571,  0.15456801, -0.03570844,  0.10685982,\n",
       "         0.14219872, -0.03065652,  0.05919057,  0.21883961, -0.03586008,\n",
       "         0.15533134,  0.23348588, -0.03505349,  0.19058211,  0.23312362,\n",
       "        -0.03504407,  0.05919057,  0.21883961, -0.03586008,  0.15533134,\n",
       "         0.23348588, -0.03505349,  0.19058211,  0.23312362, -0.03504407,\n",
       "         0.08003697,  0.16099463,  0.04783296,  0.23778475,  0.17570262,\n",
       "         0.05585963,  0.25404754,  0.18778624,  0.05618589, -0.158194  ,\n",
       "         0.21169007, -0.03879895, -0.07605469,  0.21154703, -0.03823257,\n",
       "        -0.06134417,  0.21211332, -0.03823257, -0.158194  ,  0.21169007,\n",
       "        -0.03879895, -0.07605469,  0.21154703, -0.03823257, -0.06134417,\n",
       "         0.21211332, -0.03823257,  0.10946806,  0.12751567,  0.0929676 ,\n",
       "         0.13441762,  0.09399168,  0.09645739,  0.14581718,  0.10099781,\n",
       "         0.09697942, -0.10662739,  0.2600488 , -0.0358366 , -0.02708738,\n",
       "         0.26243682, -0.03581888, -0.003194  ,  0.26324494, -0.03581888,\n",
       "        -0.10662739,  0.2600488 , -0.0358366 , -0.02708738,  0.26243682,\n",
       "        -0.03581888, -0.003194  ,  0.26324494, -0.03581888,  0.01784273,\n",
       "         0.15498337,  0.05945559,  0.1712356 ,  0.1690254 ,  0.06139614,\n",
       "         0.19921911,  0.18046772,  0.06163225, -0.44393554,  0.18802026,\n",
       "        -0.02589594, -0.41726459,  0.19883811, -0.02586621, -0.40103001,\n",
       "         0.19884671, -0.02586621, -0.44393554,  0.18802026, -0.02589594,\n",
       "        -0.41726459,  0.19883811, -0.02586621, -0.40103001,  0.19884671,\n",
       "        -0.02586621, -0.07740827,  0.15211515,  0.14408615,  0.02652039,\n",
       "         0.16645477,  0.14440032, -0.0025725 ,  0.17218055,  0.14448457,\n",
       "        -0.75732566,  0.22610968, -0.01832044, -0.78361155,  0.22815098,\n",
       "        -0.01832044, -0.78505543,  0.22829697, -0.01832044, -0.75732566,\n",
       "         0.22610968, -0.01832044, -0.78361155,  0.22815098, -0.01832044,\n",
       "        -0.78505543,  0.22829697, -0.01832044, -0.41908372,  0.02303976,\n",
       "         0.09569954, -0.38784808,  0.02045111,  0.09617571, -0.33080465,\n",
       "         0.02394824,  0.09616423, -0.50078429,  0.14409345, -0.04567296,\n",
       "        -0.42768086,  0.14524804, -0.04567297, -0.43558049,  0.14525279,\n",
       "        -0.04567297, -0.50078429,  0.14409345, -0.04567296, -0.42768086,\n",
       "         0.14524804, -0.04567297, -0.43558049,  0.14525279, -0.04567297,\n",
       "        -0.21692095, -0.15083066,  0.10644901, -0.14419829, -0.13758777,\n",
       "         0.10677064, -0.11810259, -0.13799176,  0.10677963]),\n",
       " 'mean_test_score': array([ 0.11395625,  0.10992614,  0.14853347,  0.07002343,  0.08720258,\n",
       "         0.1476824 ,  0.06895378,  0.0741251 ,  0.14843291,  0.11395625,\n",
       "         0.10992614,  0.14853347,  0.07002343,  0.08720258,  0.1476824 ,\n",
       "         0.06895378,  0.0741251 ,  0.14843291,  0.08429404,  0.14788808,\n",
       "         0.19809191,  0.09495903,  0.09372179,  0.19347423,  0.03972145,\n",
       "         0.06769136,  0.19238885,  0.12152994,  0.12839405,  0.1790683 ,\n",
       "         0.08691577,  0.1063045 ,  0.17991764,  0.06397806,  0.09137895,\n",
       "         0.18012289,  0.12152994,  0.12839405,  0.1790683 ,  0.08691577,\n",
       "         0.1063045 ,  0.17991764,  0.06397806,  0.09137895,  0.18012289,\n",
       "         0.11505657,  0.16675497,  0.19492528,  0.1066123 ,  0.1273471 ,\n",
       "         0.18511961,  0.05949224,  0.11509338,  0.18377171,  0.08352272,\n",
       "         0.12082567,  0.1678771 ,  0.07357521,  0.08455665,  0.16704079,\n",
       "         0.05451976,  0.07229238,  0.16719482,  0.08352272,  0.12082567,\n",
       "         0.1678771 ,  0.07357521,  0.08455665,  0.16704079,  0.05451976,\n",
       "         0.07229238,  0.16719482,  0.11713937,  0.12280138,  0.19390892,\n",
       "         0.11320248,  0.0900619 ,  0.18147087,  0.09366265,  0.06948951,\n",
       "         0.1792221 ,  0.02181448, -0.01030613,  0.19229364,  0.01092981,\n",
       "        -0.01698484,  0.19314231,  0.02842677, -0.01735182,  0.19318339,\n",
       "         0.02181448, -0.01030613,  0.19229364,  0.01092981, -0.01698484,\n",
       "         0.19314231,  0.02842677, -0.01735182,  0.19318339, -0.04410752,\n",
       "         0.03271325,  0.22785044, -0.09507403, -0.00101417,  0.22789466,\n",
       "        -0.12771198, -0.02185781,  0.22777727,  0.09724032,  0.04382835,\n",
       "         0.23297906,  0.11993341,  0.04201723,  0.2333573 ,  0.1182669 ,\n",
       "         0.04270356,  0.23336089,  0.09724032,  0.04382835,  0.23297906,\n",
       "         0.11993341,  0.04201723,  0.2333573 ,  0.1182669 ,  0.04270356,\n",
       "         0.23336089, -0.10105449,  0.04889876,  0.22917273, -0.12226206,\n",
       "         0.02510649,  0.2290137 , -0.14038879,  0.01886162,  0.22881898,\n",
       "         0.11851759,  0.01270502,  0.21827504,  0.06063332,  0.00580704,\n",
       "         0.21848161,  0.02705665,  0.00581226,  0.21848161,  0.11851759,\n",
       "         0.01270502,  0.21827504,  0.06063332,  0.00580704,  0.21848161,\n",
       "         0.02705665,  0.00581226,  0.21848161, -0.0415096 ,  0.10947302,\n",
       "         0.22445876, -0.10344352,  0.06826906,  0.22413804, -0.09268237,\n",
       "         0.06418498,  0.22364807, -0.22792355, -0.09840424,  0.15574503,\n",
       "        -0.25125152, -0.09208306,  0.15585239, -0.25516008, -0.09185253,\n",
       "         0.15585239, -0.22792355, -0.09840424,  0.15574503, -0.25125152,\n",
       "        -0.09208306,  0.15585239, -0.25516008, -0.09185253,  0.15585239,\n",
       "        -0.19260721, -0.24603955,  0.14351793, -0.12535837, -0.26381378,\n",
       "         0.14207434, -0.22303727, -0.26512891,  0.14179785, -0.22388943,\n",
       "        -0.16711997,  0.18565874, -0.23224944, -0.17073438,  0.18570205,\n",
       "        -0.21562703, -0.17079294,  0.18570205, -0.22388943, -0.16711997,\n",
       "         0.18565874, -0.23224944, -0.17073438,  0.18570205, -0.21562703,\n",
       "        -0.17079294,  0.18570205, -0.14778285, -0.39490753,  0.18303378,\n",
       "        -0.21273545, -0.4121801 ,  0.18317997, -0.26000085, -0.40066826,\n",
       "         0.18310002, -0.07826113, -0.12874091,  0.1898593 , -0.10285848,\n",
       "        -0.12607167,  0.18986183, -0.08937539, -0.12628042,  0.18986183,\n",
       "        -0.07826113, -0.12874091,  0.1898593 , -0.10285848, -0.12607167,\n",
       "         0.18986183, -0.08937539, -0.12628042,  0.18986183, -0.10808872,\n",
       "        -0.24522185,  0.20645712, -0.08864418, -0.25719092,  0.2065497 ,\n",
       "        -0.08035271, -0.27261253,  0.20650779,  0.11395625,  0.10992614,\n",
       "         0.14853347,  0.07002343,  0.08720258,  0.1476824 ,  0.06895378,\n",
       "         0.0741251 ,  0.14843291,  0.11395625,  0.10992614,  0.14853347,\n",
       "         0.07002343,  0.08720258,  0.1476824 ,  0.06895378,  0.0741251 ,\n",
       "         0.14843291,  0.08429404,  0.14788808,  0.19809191,  0.09495903,\n",
       "         0.09372179,  0.19347423,  0.03972145,  0.06769136,  0.19238885,\n",
       "         0.12152994,  0.12839405,  0.1790683 ,  0.08691577,  0.1063045 ,\n",
       "         0.17991764,  0.06397806,  0.09137895,  0.18012289,  0.12152994,\n",
       "         0.12839405,  0.1790683 ,  0.08691577,  0.1063045 ,  0.17991764,\n",
       "         0.06397806,  0.09137895,  0.18012289,  0.11505657,  0.16675497,\n",
       "         0.19492528,  0.1066123 ,  0.1273471 ,  0.18511961,  0.05949224,\n",
       "         0.11509338,  0.18377171,  0.08352272,  0.12082567,  0.1678771 ,\n",
       "         0.07357521,  0.08455665,  0.16704079,  0.05451976,  0.07229238,\n",
       "         0.16719482,  0.08352272,  0.12082567,  0.1678771 ,  0.07357521,\n",
       "         0.08455665,  0.16704079,  0.05451976,  0.07229238,  0.16719482,\n",
       "         0.11713937,  0.12280138,  0.19390892,  0.11320248,  0.0900619 ,\n",
       "         0.18147087,  0.09366265,  0.06948951,  0.1792221 ,  0.02181448,\n",
       "        -0.01030613,  0.19229364,  0.01092981, -0.01698484,  0.19314231,\n",
       "         0.02842677, -0.01735182,  0.19318339,  0.02181448, -0.01030613,\n",
       "         0.19229364,  0.01092981, -0.01698484,  0.19314231,  0.02842677,\n",
       "        -0.01735182,  0.19318339, -0.04410752,  0.03271325,  0.22785044,\n",
       "        -0.09507403, -0.00101417,  0.22789466, -0.12771198, -0.02185781,\n",
       "         0.22777727,  0.09724032,  0.04382835,  0.23297906,  0.11993341,\n",
       "         0.04201723,  0.2333573 ,  0.1182669 ,  0.04270356,  0.23336089,\n",
       "         0.09724032,  0.04382835,  0.23297906,  0.11993341,  0.04201723,\n",
       "         0.2333573 ,  0.1182669 ,  0.04270356,  0.23336089, -0.10105449,\n",
       "         0.04889876,  0.22917273, -0.12226206,  0.02510649,  0.2290137 ,\n",
       "        -0.14038879,  0.01886162,  0.22881898,  0.11851759,  0.01270502,\n",
       "         0.21827504,  0.06063332,  0.00580704,  0.21848161,  0.02705665,\n",
       "         0.00581226,  0.21848161,  0.11851759,  0.01270502,  0.21827504,\n",
       "         0.06063332,  0.00580704,  0.21848161,  0.02705665,  0.00581226,\n",
       "         0.21848161, -0.0415096 ,  0.10947302,  0.22445876, -0.10344352,\n",
       "         0.06826906,  0.22413804, -0.09268237,  0.06418498,  0.22364807,\n",
       "        -0.22792355, -0.09840424,  0.15574503, -0.25125152, -0.09208306,\n",
       "         0.15585239, -0.25516008, -0.09185253,  0.15585239, -0.22792355,\n",
       "        -0.09840424,  0.15574503, -0.25125152, -0.09208306,  0.15585239,\n",
       "        -0.25516008, -0.09185253,  0.15585239, -0.19260721, -0.24603955,\n",
       "         0.14351793, -0.12535837, -0.26381378,  0.14207434, -0.22303727,\n",
       "        -0.26512891,  0.14179785, -0.22388943, -0.16711997,  0.18565874,\n",
       "        -0.23224944, -0.17073438,  0.18570205, -0.21562703, -0.17079294,\n",
       "         0.18570205, -0.22388943, -0.16711997,  0.18565874, -0.23224944,\n",
       "        -0.17073438,  0.18570205, -0.21562703, -0.17079294,  0.18570205,\n",
       "        -0.14778285, -0.39490753,  0.18303378, -0.21273545, -0.4121801 ,\n",
       "         0.18317997, -0.26000085, -0.40066826,  0.18310002, -0.07826113,\n",
       "        -0.12874091,  0.1898593 , -0.10285848, -0.12607167,  0.18986183,\n",
       "        -0.08937539, -0.12628042,  0.18986183, -0.07826113, -0.12874091,\n",
       "         0.1898593 , -0.10285848, -0.12607167,  0.18986183, -0.08937539,\n",
       "        -0.12628042,  0.18986183, -0.10808872, -0.24522185,  0.20645712,\n",
       "        -0.08864418, -0.25719092,  0.2065497 , -0.08035271, -0.27261253,\n",
       "         0.20650779,  0.02347721,  0.10161598, -0.06032414,  0.05248811,\n",
       "         0.08366033, -0.06639548,  0.02962168,  0.08020207, -0.06654702,\n",
       "         0.02347721,  0.10161598, -0.06032414,  0.05248811,  0.08366033,\n",
       "        -0.06639548,  0.02962168,  0.08020207, -0.06654702,  0.04678966,\n",
       "         0.07355419, -0.03859921,  0.05602623,  0.05536501, -0.04126956,\n",
       "         0.02442432,  0.02796147, -0.0416057 , -0.01497175,  0.07769081,\n",
       "        -0.07155503,  0.07547842,  0.06432476, -0.07939433,  0.02902261,\n",
       "         0.0534896 , -0.07940776, -0.01497175,  0.07769081, -0.07155503,\n",
       "         0.07547842,  0.06432476, -0.07939433,  0.02902261,  0.0534896 ,\n",
       "        -0.07940776,  0.01906833,  0.05867315, -0.02575541,  0.01949301,\n",
       "         0.05271389, -0.03366963, -0.0257763 ,  0.03216764, -0.03361373,\n",
       "         0.01336902,  0.06516635, -0.05993799,  0.07779289,  0.06616363,\n",
       "        -0.0688726 ,  0.01302292,  0.06087572, -0.06894741,  0.01336902,\n",
       "         0.06516635, -0.05993799,  0.07779289,  0.06616363, -0.0688726 ,\n",
       "         0.01302292,  0.06087572, -0.06894741,  0.01632177,  0.05326327,\n",
       "        -0.0432616 ,  0.06482789,  0.04310502, -0.05656196,  0.00703494,\n",
       "         0.01242735, -0.05795475,  0.05868252,  0.06382124, -0.12410005,\n",
       "         0.07868568,  0.05517088, -0.12374808,  0.07271365,  0.05371025,\n",
       "        -0.12374396,  0.05868252,  0.06382124, -0.12410005,  0.07868568,\n",
       "         0.05517088, -0.12374808,  0.07271365,  0.05371025, -0.12374396,\n",
       "         0.02913818,  0.06390479, -0.00571153,  0.07187491,  0.0508305 ,\n",
       "        -0.00421893,  0.0502859 ,  0.05262583, -0.00428948, -0.0778389 ,\n",
       "         0.05856088, -0.15989099, -0.06843259,  0.04700127, -0.15972208,\n",
       "        -0.07992924,  0.04669064, -0.15972208, -0.0778389 ,  0.05856088,\n",
       "        -0.15989099, -0.06843259,  0.04700127, -0.15972208, -0.07992924,\n",
       "         0.04669064, -0.15972208,  0.00378495,  0.02374669, -0.00603941,\n",
       "        -0.03465209, -0.02467757, -0.0080378 , -0.07151195, -0.0256824 ,\n",
       "        -0.00801675, -0.02468015,  0.0944902 , -0.16587983, -0.02517907,\n",
       "         0.08444974, -0.16604866, -0.03562639,  0.08389164, -0.16604866,\n",
       "        -0.02468015,  0.0944902 , -0.16587983, -0.02517907,  0.08444974,\n",
       "        -0.16604866, -0.03562639,  0.08389164, -0.16604866, -0.00643941,\n",
       "         0.05054139, -0.03302874,  0.03707148,  0.02569526, -0.03400928,\n",
       "         0.03523973,  0.02524284, -0.03401199, -0.31509602, -0.00837671,\n",
       "        -0.15407356, -0.32714627, -0.00362284, -0.15407994, -0.3303352 ,\n",
       "        -0.00372873, -0.15407994, -0.31509602, -0.00837671, -0.15407356,\n",
       "        -0.32714627, -0.00362284, -0.15407994, -0.3303352 , -0.00372873,\n",
       "        -0.15407994, -0.10748912, -0.0654515 , -0.00110745, -0.08581455,\n",
       "        -0.07019417, -0.00166177, -0.12008443, -0.06902379, -0.00164645,\n",
       "        -0.48538406, -0.03932297, -0.21107904, -0.53922644, -0.03966056,\n",
       "        -0.21107905, -0.54872968, -0.03963401, -0.21107905, -0.48538406,\n",
       "        -0.03932297, -0.21107904, -0.53922644, -0.03966056, -0.21107905,\n",
       "        -0.54872968, -0.03963401, -0.21107905, -0.22064582, -0.14756731,\n",
       "        -0.00985141, -0.23662262, -0.15953459, -0.01026878, -0.23665192,\n",
       "        -0.16348174, -0.01027233, -0.33827813, -0.1382389 , -0.21706131,\n",
       "        -0.32319887, -0.14307144, -0.21706132, -0.33503697, -0.14314061,\n",
       "        -0.21706132, -0.33827813, -0.1382389 , -0.21706131, -0.32319887,\n",
       "        -0.14307144, -0.21706132, -0.33503697, -0.14314061, -0.21706132,\n",
       "        -0.12062167, -0.15809871, -0.02985152, -0.14076783, -0.15997122,\n",
       "        -0.03035821, -0.12790027, -0.15857915, -0.0303551 ]),\n",
       " 'std_test_score': array([1.32549910e-02, 1.66425235e-01, 5.37778595e-02, 7.93546591e-02,\n",
       "        2.08606040e-01, 5.92093567e-02, 1.18494671e-01, 2.23162405e-01,\n",
       "        6.09754797e-02, 1.32549910e-02, 1.66425235e-01, 5.37778595e-02,\n",
       "        7.93546591e-02, 2.08606040e-01, 5.92093567e-02, 1.18494671e-01,\n",
       "        2.23162405e-01, 6.09754797e-02, 2.32066871e-02, 6.33002293e-02,\n",
       "        8.66062413e-02, 6.23114391e-02, 1.20209163e-01, 1.12451890e-01,\n",
       "        7.92034262e-02, 1.57897036e-01, 1.16532612e-01, 1.28637462e-02,\n",
       "        1.33320696e-01, 7.08479539e-02, 4.27203995e-02, 1.78333905e-01,\n",
       "        7.86298419e-02, 5.74822978e-02, 1.92222498e-01, 7.90361089e-02,\n",
       "        1.28637462e-02, 1.33320696e-01, 7.08479539e-02, 4.27203995e-02,\n",
       "        1.78333905e-01, 7.86298419e-02, 5.74822978e-02, 1.92222498e-01,\n",
       "        7.90361089e-02, 5.03678157e-02, 6.99283918e-02, 9.72697411e-02,\n",
       "        7.89456224e-02, 1.42888308e-01, 1.13931553e-01, 1.17769001e-01,\n",
       "        1.83250833e-01, 1.16245452e-01, 1.32371097e-02, 1.66764330e-01,\n",
       "        7.57555872e-02, 8.81609051e-02, 2.07979793e-01, 8.23094650e-02,\n",
       "        1.24373414e-01, 2.25378224e-01, 8.26312165e-02, 1.32371097e-02,\n",
       "        1.66764330e-01, 7.57555872e-02, 8.81609051e-02, 2.07979793e-01,\n",
       "        8.23094650e-02, 1.24373414e-01, 2.25378224e-01, 8.26312165e-02,\n",
       "        4.79874351e-02, 4.35675354e-02, 9.88135172e-02, 9.65697868e-02,\n",
       "        1.17574106e-01, 1.14845506e-01, 1.05385015e-01, 1.61353565e-01,\n",
       "        1.18812385e-01, 7.80694896e-02, 1.75410151e-01, 9.12912408e-02,\n",
       "        1.59778980e-01, 2.01842189e-01, 9.23710518e-02, 1.82129421e-01,\n",
       "        2.02445717e-01, 9.24246066e-02, 7.80694896e-02, 1.75410151e-01,\n",
       "        9.12912408e-02, 1.59778980e-01, 2.01842189e-01, 9.23710518e-02,\n",
       "        1.82129421e-01, 2.02445717e-01, 9.24246066e-02, 1.17917716e-02,\n",
       "        1.09925755e-01, 1.13680603e-01, 7.98551223e-02, 1.55040132e-01,\n",
       "        1.19018453e-01, 9.90729155e-02, 1.43945008e-01, 1.20108750e-01,\n",
       "        1.28799092e-02, 1.23635330e-01, 9.33553347e-02, 4.86506253e-02,\n",
       "        1.45090049e-01, 9.38516823e-02, 4.23462853e-02, 1.47815545e-01,\n",
       "        9.38552745e-02, 1.28799092e-02, 1.23635330e-01, 9.33553347e-02,\n",
       "        4.86506253e-02, 1.45090049e-01, 9.38516823e-02, 4.23462853e-02,\n",
       "        1.47815545e-01, 9.38552745e-02, 8.14600342e-02, 1.05652586e-01,\n",
       "        1.25475060e-01, 2.60074951e-02, 1.56433186e-01, 1.30021315e-01,\n",
       "        5.17760384e-02, 1.57465311e-01, 1.30957135e-01, 8.38173159e-02,\n",
       "        1.86303364e-01, 9.71173104e-02, 2.29607729e-02, 2.12961823e-01,\n",
       "        9.74556473e-02, 1.00427691e-02, 2.15524888e-01, 9.74556437e-02,\n",
       "        8.38173159e-02, 1.86303364e-01, 9.71173104e-02, 2.29607729e-02,\n",
       "        2.12961823e-01, 9.74556473e-02, 1.00427691e-02, 2.15524888e-01,\n",
       "        9.74556437e-02, 4.59842549e-02, 1.24808650e-01, 1.11467828e-01,\n",
       "        8.77419281e-04, 1.92898331e-01, 1.15350827e-01, 3.40269954e-03,\n",
       "        2.06437791e-01, 1.16061544e-01, 3.15775849e-02, 9.21803300e-02,\n",
       "        6.35475160e-02, 2.60844213e-02, 1.01303853e-01, 6.36487083e-02,\n",
       "        2.55091598e-02, 1.01557746e-01, 6.36487086e-02, 3.15775849e-02,\n",
       "        9.21803300e-02, 6.35475160e-02, 2.60844213e-02, 1.01303853e-01,\n",
       "        6.36487083e-02, 2.55091598e-02, 1.01557746e-01, 6.36487086e-02,\n",
       "        3.29153094e-02, 7.96209199e-02, 1.12376756e-01, 3.11226696e-02,\n",
       "        8.67795973e-02, 1.12576078e-01, 7.69468932e-02, 9.13007227e-02,\n",
       "        1.12583143e-01, 2.26968484e-04, 1.43532444e-01, 6.24891986e-02,\n",
       "        1.14700091e-02, 1.55024043e-01, 6.25325331e-02, 2.62397073e-02,\n",
       "        1.54869305e-01, 6.25325335e-02, 2.26968484e-04, 1.43532444e-01,\n",
       "        6.24891986e-02, 1.14700091e-02, 1.55024043e-01, 6.25325331e-02,\n",
       "        2.62397073e-02, 1.54869305e-01, 6.25325335e-02, 8.12767584e-02,\n",
       "        1.03318402e-01, 7.05940185e-02, 1.25824602e-01, 7.94997467e-02,\n",
       "        7.15252956e-02, 4.80768992e-02, 6.76273434e-02, 7.15323162e-02,\n",
       "        1.29359530e-01, 1.05642713e-01, 5.07791789e-02, 1.22414952e-01,\n",
       "        1.04276267e-01, 5.07817525e-02, 1.27444204e-01, 1.04226519e-01,\n",
       "        5.07817524e-02, 1.29359530e-01, 1.05642713e-01, 5.07791789e-02,\n",
       "        1.22414952e-01, 1.04276267e-01, 5.07817525e-02, 1.27444204e-01,\n",
       "        1.04226519e-01, 5.07817524e-02, 5.60324231e-02, 3.18572800e-02,\n",
       "        1.01639878e-01, 8.33802629e-03, 5.43032581e-02, 1.03133833e-01,\n",
       "        2.15444129e-02, 4.40623044e-02, 1.03204611e-01, 1.32549910e-02,\n",
       "        1.66425235e-01, 5.37778595e-02, 7.93546591e-02, 2.08606040e-01,\n",
       "        5.92093567e-02, 1.18494671e-01, 2.23162405e-01, 6.09754797e-02,\n",
       "        1.32549910e-02, 1.66425235e-01, 5.37778595e-02, 7.93546591e-02,\n",
       "        2.08606040e-01, 5.92093567e-02, 1.18494671e-01, 2.23162405e-01,\n",
       "        6.09754797e-02, 2.32066871e-02, 6.33002293e-02, 8.66062413e-02,\n",
       "        6.23114391e-02, 1.20209163e-01, 1.12451890e-01, 7.92034262e-02,\n",
       "        1.57897036e-01, 1.16532612e-01, 1.28637462e-02, 1.33320696e-01,\n",
       "        7.08479539e-02, 4.27203995e-02, 1.78333905e-01, 7.86298419e-02,\n",
       "        5.74822978e-02, 1.92222498e-01, 7.90361089e-02, 1.28637462e-02,\n",
       "        1.33320696e-01, 7.08479539e-02, 4.27203995e-02, 1.78333905e-01,\n",
       "        7.86298419e-02, 5.74822978e-02, 1.92222498e-01, 7.90361089e-02,\n",
       "        5.03678157e-02, 6.99283918e-02, 9.72697411e-02, 7.89456224e-02,\n",
       "        1.42888308e-01, 1.13931553e-01, 1.17769001e-01, 1.83250833e-01,\n",
       "        1.16245452e-01, 1.32371097e-02, 1.66764330e-01, 7.57555872e-02,\n",
       "        8.81609051e-02, 2.07979793e-01, 8.23094650e-02, 1.24373414e-01,\n",
       "        2.25378224e-01, 8.26312165e-02, 1.32371097e-02, 1.66764330e-01,\n",
       "        7.57555872e-02, 8.81609051e-02, 2.07979793e-01, 8.23094650e-02,\n",
       "        1.24373414e-01, 2.25378224e-01, 8.26312165e-02, 4.79874351e-02,\n",
       "        4.35675354e-02, 9.88135172e-02, 9.65697868e-02, 1.17574106e-01,\n",
       "        1.14845506e-01, 1.05385015e-01, 1.61353565e-01, 1.18812385e-01,\n",
       "        7.80694896e-02, 1.75410151e-01, 9.12912408e-02, 1.59778980e-01,\n",
       "        2.01842189e-01, 9.23710518e-02, 1.82129421e-01, 2.02445717e-01,\n",
       "        9.24246066e-02, 7.80694896e-02, 1.75410151e-01, 9.12912408e-02,\n",
       "        1.59778980e-01, 2.01842189e-01, 9.23710518e-02, 1.82129421e-01,\n",
       "        2.02445717e-01, 9.24246066e-02, 1.17917716e-02, 1.09925755e-01,\n",
       "        1.13680603e-01, 7.98551223e-02, 1.55040132e-01, 1.19018453e-01,\n",
       "        9.90729155e-02, 1.43945008e-01, 1.20108750e-01, 1.28799092e-02,\n",
       "        1.23635330e-01, 9.33553347e-02, 4.86506253e-02, 1.45090049e-01,\n",
       "        9.38516823e-02, 4.23462853e-02, 1.47815545e-01, 9.38552745e-02,\n",
       "        1.28799092e-02, 1.23635330e-01, 9.33553347e-02, 4.86506253e-02,\n",
       "        1.45090049e-01, 9.38516823e-02, 4.23462853e-02, 1.47815545e-01,\n",
       "        9.38552745e-02, 8.14600342e-02, 1.05652586e-01, 1.25475060e-01,\n",
       "        2.60074951e-02, 1.56433186e-01, 1.30021315e-01, 5.17760384e-02,\n",
       "        1.57465311e-01, 1.30957135e-01, 8.38173159e-02, 1.86303364e-01,\n",
       "        9.71173104e-02, 2.29607729e-02, 2.12961823e-01, 9.74556473e-02,\n",
       "        1.00427691e-02, 2.15524888e-01, 9.74556437e-02, 8.38173159e-02,\n",
       "        1.86303364e-01, 9.71173104e-02, 2.29607729e-02, 2.12961823e-01,\n",
       "        9.74556473e-02, 1.00427691e-02, 2.15524888e-01, 9.74556437e-02,\n",
       "        4.59842549e-02, 1.24808650e-01, 1.11467828e-01, 8.77419281e-04,\n",
       "        1.92898331e-01, 1.15350827e-01, 3.40269954e-03, 2.06437791e-01,\n",
       "        1.16061544e-01, 3.15775849e-02, 9.21803300e-02, 6.35475160e-02,\n",
       "        2.60844213e-02, 1.01303853e-01, 6.36487083e-02, 2.55091598e-02,\n",
       "        1.01557746e-01, 6.36487086e-02, 3.15775849e-02, 9.21803300e-02,\n",
       "        6.35475160e-02, 2.60844213e-02, 1.01303853e-01, 6.36487083e-02,\n",
       "        2.55091598e-02, 1.01557746e-01, 6.36487086e-02, 3.29153094e-02,\n",
       "        7.96209199e-02, 1.12376756e-01, 3.11226696e-02, 8.67795973e-02,\n",
       "        1.12576078e-01, 7.69468932e-02, 9.13007227e-02, 1.12583143e-01,\n",
       "        2.26968484e-04, 1.43532444e-01, 6.24891986e-02, 1.14700091e-02,\n",
       "        1.55024043e-01, 6.25325331e-02, 2.62397073e-02, 1.54869305e-01,\n",
       "        6.25325335e-02, 2.26968484e-04, 1.43532444e-01, 6.24891986e-02,\n",
       "        1.14700091e-02, 1.55024043e-01, 6.25325331e-02, 2.62397073e-02,\n",
       "        1.54869305e-01, 6.25325335e-02, 8.12767584e-02, 1.03318402e-01,\n",
       "        7.05940185e-02, 1.25824602e-01, 7.94997467e-02, 7.15252956e-02,\n",
       "        4.80768992e-02, 6.76273434e-02, 7.15323162e-02, 1.29359530e-01,\n",
       "        1.05642713e-01, 5.07791789e-02, 1.22414952e-01, 1.04276267e-01,\n",
       "        5.07817525e-02, 1.27444204e-01, 1.04226519e-01, 5.07817524e-02,\n",
       "        1.29359530e-01, 1.05642713e-01, 5.07791789e-02, 1.22414952e-01,\n",
       "        1.04276267e-01, 5.07817525e-02, 1.27444204e-01, 1.04226519e-01,\n",
       "        5.07817524e-02, 5.60324231e-02, 3.18572800e-02, 1.01639878e-01,\n",
       "        8.33802629e-03, 5.43032581e-02, 1.03133833e-01, 2.15444129e-02,\n",
       "        4.40623044e-02, 1.03204611e-01, 1.23916251e-02, 9.01597528e-02,\n",
       "        1.04859936e-01, 1.31042956e-01, 1.32924481e-01, 1.11013958e-01,\n",
       "        1.60424202e-01, 1.48470086e-01, 1.11578823e-01, 1.23916251e-02,\n",
       "        9.01597528e-02, 1.04859936e-01, 1.31042956e-01, 1.32924481e-01,\n",
       "        1.11013958e-01, 1.60424202e-01, 1.48470086e-01, 1.11578823e-01,\n",
       "        2.96279751e-02, 3.64985801e-02, 6.34915027e-02, 7.44825109e-02,\n",
       "        1.08952605e-01, 8.28004898e-02, 1.48340503e-01, 1.30197761e-01,\n",
       "        8.77227283e-02, 4.65865008e-02, 9.05900402e-02, 1.19250778e-01,\n",
       "        6.91605161e-02, 1.36795333e-01, 1.28201452e-01, 1.22305467e-01,\n",
       "        1.52727073e-01, 1.28427491e-01, 4.65865008e-02, 9.05900402e-02,\n",
       "        1.19250778e-01, 6.91605161e-02, 1.36795333e-01, 1.28201452e-01,\n",
       "        1.22305467e-01, 1.52727073e-01, 1.28427491e-01, 4.56998019e-02,\n",
       "        1.22349357e-02, 4.60956130e-02, 8.56688312e-03, 7.84687363e-02,\n",
       "        6.86843086e-02, 7.25176697e-02, 9.57900898e-02, 7.49877764e-02,\n",
       "        9.81859906e-03, 8.31950290e-02, 1.09137614e-01, 6.04582241e-02,\n",
       "        1.19526451e-01, 1.19696667e-01, 1.10083224e-01, 1.36069388e-01,\n",
       "        1.19986453e-01, 9.81859906e-03, 8.31950290e-02, 1.09137614e-01,\n",
       "        6.04582241e-02, 1.19526451e-01, 1.19696667e-01, 1.10083224e-01,\n",
       "        1.36069388e-01, 1.19986453e-01, 1.55279195e-02, 4.78152383e-02,\n",
       "        6.73293142e-03, 5.91978163e-02, 1.11462992e-01, 2.08535194e-02,\n",
       "        9.98248862e-02, 1.29771367e-01, 2.72982285e-02, 5.08047971e-04,\n",
       "        1.55018372e-01, 8.82399706e-02, 7.66456595e-02, 1.78315008e-01,\n",
       "        8.86945897e-02, 1.17868456e-01, 1.79413368e-01, 8.86998889e-02,\n",
       "        5.08047971e-04, 1.55018372e-01, 8.82399706e-02, 7.66456595e-02,\n",
       "        1.78315008e-01, 8.86945897e-02, 1.17868456e-01, 1.79413368e-01,\n",
       "        8.86998889e-02, 5.08987879e-02, 9.70898442e-02, 5.35444910e-02,\n",
       "        1.65909839e-01, 1.24872123e-01, 6.00785582e-02, 2.03761637e-01,\n",
       "        1.35160402e-01, 6.04753696e-02, 8.03551042e-02, 1.53129186e-01,\n",
       "        1.21092036e-01, 7.62210067e-03, 1.64545760e-01, 1.21489512e-01,\n",
       "        1.85850678e-02, 1.65422675e-01, 1.21489510e-01, 8.03551042e-02,\n",
       "        1.53129186e-01, 1.21092036e-01, 7.62210067e-03, 1.64545760e-01,\n",
       "        1.21489512e-01, 1.85850678e-02, 1.65422675e-01, 1.21489510e-01,\n",
       "        1.05683111e-01, 1.03768981e-01, 9.90070054e-02, 1.69069715e-01,\n",
       "        1.18669256e-01, 1.04495188e-01, 2.17329127e-01, 1.26680210e-01,\n",
       "        1.04996162e-01, 8.19472407e-02, 1.65558599e-01, 1.30043237e-01,\n",
       "        1.90830413e-03, 1.77987086e-01, 1.30229782e-01, 3.24323856e-02,\n",
       "        1.79353297e-01, 1.30229783e-01, 8.19472407e-02, 1.65558599e-01,\n",
       "        1.30043237e-01, 1.90830413e-03, 1.77987086e-01, 1.30229782e-01,\n",
       "        3.24323856e-02, 1.79353297e-01, 1.30229783e-01, 2.42821376e-02,\n",
       "        1.04441973e-01, 9.24843250e-02, 1.34164125e-01, 1.43330141e-01,\n",
       "        9.54054185e-02, 1.63979376e-01, 1.55224887e-01, 9.56442397e-02,\n",
       "        1.28839525e-01, 1.96396975e-01, 1.28177621e-01, 9.01183248e-02,\n",
       "        2.02460948e-01, 1.28213725e-01, 7.06948115e-02, 2.02575442e-01,\n",
       "        1.28213725e-01, 1.28839525e-01, 1.96396975e-01, 1.28177621e-01,\n",
       "        9.01183248e-02, 2.02460948e-01, 1.28213725e-01, 7.06948115e-02,\n",
       "        2.02575442e-01, 1.28213725e-01, 3.00808546e-02, 2.17566646e-01,\n",
       "        1.45193598e-01, 1.12334938e-01, 2.36648937e-01, 1.46062095e-01,\n",
       "        1.17511933e-01, 2.41204341e-01, 1.46131012e-01, 2.71941601e-01,\n",
       "        2.65432649e-01, 1.92758600e-01, 2.44385116e-01, 2.67811536e-01,\n",
       "        1.92758616e-01, 2.36325750e-01, 2.67930983e-01, 1.92758616e-01,\n",
       "        2.71941601e-01, 2.65432649e-01, 1.92758600e-01, 2.44385116e-01,\n",
       "        2.67811536e-01, 1.92758616e-01, 2.36325750e-01, 2.67930983e-01,\n",
       "        1.92758616e-01, 1.98437892e-01, 1.70607078e-01, 1.05550946e-01,\n",
       "        1.51225462e-01, 1.79985700e-01, 1.06444494e-01, 9.41527313e-02,\n",
       "        1.87429983e-01, 1.06436557e-01, 1.62506156e-01, 2.82332347e-01,\n",
       "        1.71388349e-01, 1.04481988e-01, 2.88319473e-01, 1.71388344e-01,\n",
       "        1.00543526e-01, 2.88393395e-01, 1.71388344e-01, 1.62506156e-01,\n",
       "        2.82332347e-01, 1.71388349e-01, 1.04481988e-01, 2.88319473e-01,\n",
       "        1.71388344e-01, 1.00543526e-01, 2.88393395e-01, 1.71388344e-01,\n",
       "        9.62992831e-02, 7.26804429e-03, 1.36300526e-01, 3.43046498e-03,\n",
       "        2.23834517e-02, 1.37128851e-01, 9.79768651e-03, 2.05873905e-02,\n",
       "        1.37134730e-01]),\n",
       " 'rank_test_score': array([201, 207, 147, 289, 239, 157, 295, 273, 151, 201, 207, 147, 289,\n",
       "        239, 157, 295, 273, 151, 253, 155,  49, 225, 229,  55, 372, 301,\n",
       "         65, 175, 167, 117, 243, 215, 111, 312, 233, 107, 175, 167, 117,\n",
       "        243, 215, 111, 312, 233, 107, 199, 133,  51, 213, 171,  95, 325,\n",
       "        197,  97, 259, 179, 121, 277, 247, 129, 336, 284, 125, 259, 179,\n",
       "        121, 277, 247, 129, 336, 284, 125, 195, 173,  53, 205, 237, 105,\n",
       "        231, 293, 115, 401, 454,  67, 419, 460,  61, 384, 464,  57, 401,\n",
       "        454,  67, 419, 460,  61, 384, 464,  57, 501, 376,  21, 556, 433,\n",
       "         19, 593, 468,  23, 221, 359,   9, 183, 368,   5, 191, 364,   1,\n",
       "        221, 359,   9, 183, 368,   5, 191, 364,   1, 562, 352,  13, 575,\n",
       "        395,  15, 602, 407,  17, 187, 414,  39, 321, 428,  31, 389, 424,\n",
       "         35, 187, 414,  39, 321, 428,  31, 389, 424,  35, 497, 211,  25,\n",
       "        568, 299,  27, 554, 310,  29, 674, 558, 143, 688, 550, 139, 692,\n",
       "        546, 135, 674, 558, 143, 688, 550, 139, 692, 546, 135, 647, 686,\n",
       "        161, 583, 700, 163, 668, 702, 165, 670, 635,  91, 678, 639,  83,\n",
       "        657, 643,  87, 670, 635,  91, 678, 639,  83, 657, 643,  87, 610,\n",
       "        718, 103, 655, 722,  99, 698, 720, 101, 527, 596,  79, 564, 585,\n",
       "         71, 542, 589,  75, 527, 596,  79, 564, 585,  71, 542, 589,  75,\n",
       "        571, 684,  47, 540, 696,  43, 537, 704,  45, 201, 207, 147, 289,\n",
       "        239, 157, 295, 273, 151, 201, 207, 147, 289, 239, 157, 295, 273,\n",
       "        151, 253, 155,  49, 225, 229,  55, 372, 301,  65, 175, 167, 117,\n",
       "        243, 215, 111, 312, 233, 107, 175, 167, 117, 243, 215, 111, 312,\n",
       "        233, 107, 199, 133,  51, 213, 171,  95, 325, 197,  97, 259, 179,\n",
       "        121, 277, 247, 129, 336, 284, 125, 259, 179, 121, 277, 247, 129,\n",
       "        336, 284, 125, 195, 173,  53, 205, 237, 105, 231, 293, 115, 401,\n",
       "        454,  67, 419, 460,  61, 384, 464,  57, 401, 454,  67, 419, 460,\n",
       "         61, 384, 464,  57, 501, 376,  21, 556, 433,  19, 593, 468,  23,\n",
       "        221, 359,   9, 183, 368,   5, 191, 364,   1, 221, 359,   9, 183,\n",
       "        368,   5, 191, 364,   1, 562, 352,  13, 575, 395,  15, 602, 407,\n",
       "         17, 187, 414,  39, 321, 428,  31, 389, 424,  35, 187, 414,  39,\n",
       "        321, 428,  31, 389, 424,  35, 497, 211,  25, 568, 299,  27, 554,\n",
       "        310,  29, 674, 558, 143, 688, 550, 139, 692, 546, 135, 674, 558,\n",
       "        143, 688, 550, 139, 692, 546, 135, 647, 686, 161, 583, 700, 163,\n",
       "        668, 702, 165, 670, 635,  91, 678, 639,  83, 657, 643,  87, 670,\n",
       "        635,  91, 678, 639,  83, 657, 643,  87, 610, 718, 103, 655, 722,\n",
       "         99, 698, 720, 101, 527, 596,  79, 564, 585,  71, 542, 589,  75,\n",
       "        527, 596,  79, 564, 585,  71, 542, 589,  75, 571, 684,  47, 540,\n",
       "        696,  43, 537, 704,  45, 399, 219, 507, 347, 257, 510, 379, 263,\n",
       "        512, 399, 219, 507, 347, 257, 510, 379, 263, 512, 356, 281, 489,\n",
       "        332, 333, 496, 397, 388, 499, 458, 269, 523, 271, 308, 531, 382,\n",
       "        342, 533, 458, 269, 523, 271, 308, 531, 382, 342, 533, 406, 329,\n",
       "        476, 405, 345, 483, 477, 378, 482, 410, 305, 505, 267, 303, 516,\n",
       "        412, 319, 518, 410, 305, 505, 267, 303, 516, 412, 319, 518, 409,\n",
       "        344, 500, 307, 363, 503, 423, 418, 504, 327, 317, 581, 265, 334,\n",
       "        579, 282, 340, 577, 327, 317, 581, 265, 334, 579, 282, 340, 577,\n",
       "        381, 316, 444, 288, 349, 442, 351, 346, 443, 525, 330, 625, 514,\n",
       "        354, 623, 535, 357, 621, 525, 330, 625, 514, 354, 623, 535, 357,\n",
       "        621, 432, 398, 445, 486, 470, 448, 522, 475, 447, 471, 227, 629,\n",
       "        473, 251, 633, 487, 255, 631, 471, 227, 629, 473, 251, 633, 487,\n",
       "        255, 631, 446, 350, 481, 374, 393, 484, 375, 394, 485, 706, 449,\n",
       "        612, 710, 438, 614, 712, 440, 616, 706, 449, 612, 710, 438, 614,\n",
       "        712, 440, 616, 570, 509, 435, 539, 521, 437, 573, 520, 436, 724,\n",
       "        490, 649, 726, 494, 651, 728, 492, 651, 724, 490, 649, 726, 494,\n",
       "        651, 728, 492, 651, 667, 609, 451, 682, 620, 452, 683, 628, 453,\n",
       "        716, 600, 661, 708, 605, 665, 714, 607, 663, 716, 600, 661, 708,\n",
       "        605, 665, 714, 607, 663, 574, 618, 478, 604, 627, 480, 595, 619,\n",
       "        479])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV that will automatically split the data and give us the best estimator by:\n",
    "\n",
    "#1) Establishing hyperparameters to change \n",
    "param_grid = {\n",
    "              #\"objective\":[\"reg:squarederror\"],\n",
    "              \"learning_rate\": [0.15,0.3,0.50], \n",
    "              \"max_depth\": [7,8,9],\n",
    "              \"min_child_weight\": [0.5,1,1.5],\n",
    "              \"subsample\": [0.3,0.5,1],\n",
    "              \"colsample_bytree\": [0.7,0.8,1],\n",
    "              \"n_estimators\": [50,100,200],\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(xgb,param_grid,cv=2)\n",
    "\n",
    "#2) Fitting the model with our desired data and check for best results\n",
    "grid.fit(X, y)\n",
    "\n",
    "#) Retrieve the summary of GridSearchCV for analysis\n",
    "print(F\"The number homogeneous splits conducted by GridSearchCV are: {grid.n_splits_}.\")\n",
    "print(F\"The best hyperparameters found were: {grid.best_params_}.\")\n",
    "print(F\"The best score found was: {grid.best_score_}.\")\n",
    "\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Results:**\n",
    "\n",
    "- **`mean_test_score`: shows the result for each model iteration.**\n",
    "    - In this case \n",
    "\n",
    "\n",
    "- **`split_0`, `split_1`,etc: Check results in 1st,2nd, 3rd split, etc.**\n",
    "    - In this case\n",
    "    \n",
    "\n",
    "\n",
    "- **`std_test_score` : to check if the model is robust, meaning if we consistently obtained good results or not (high standard deviation).**\n",
    "    - In this case\n",
    "    \n",
    " **Note: Better to run it 3 times with different homogeneous splits, instead of just 1 split.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the model to new data:\n",
    "\n",
    "- For supervised learning, predict labels for unknown data using the `.predict()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction using the best hyperparameters from GridSearchCV (can be retrieved in \".best_estimator_\")\n",
    "\n",
    "prediction_2020 = grid.best_estimator_.predict(queen_predict2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Each Cluster Predictions to the original DataFrame and Save it as a `.csv file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Column with the 2020 prediction\n",
    "queen_predict[\"nests_2020\"] = prediction_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the Municipalities to insert manualy\n",
    "\n",
    "HEX_aux = pd.DataFrame({\"CODIGO MUNICIPIO\":[48020],\\\n",
    "             \"NOMBRE MUNICIPIO\":[\"Bilbao\"],\\\n",
    "             \"NIDOS 2020\":[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Z3PcQ4UnACCA"
   },
   "outputs": [],
   "source": [
    "HEX = queen_predict.loc[:,[\"municip_code\",\"municip_name_x\",\"nests_2020\"]].round() # create a new Dataframe for Kopuru submission\n",
    "HEX.columns = [\"CODIGO MUNICIPIO\",\"NOMBRE MUNICIPIO\",\"NIDOS 2020\"] # change column names to Spanish (Decidata template)\n",
    "HEX = HEX.append(HEX_aux, ignore_index=True) # Add rows of municipalities to add manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission form Shape is (112, 3)\n",
      "Number of Municipalities is 112\n",
      "The Total 2020 Nests' Prediction is 2614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All Municipality Names and Codes to be submitted match the Template'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final check\n",
    "\n",
    "check_data(HEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset max_rows to default values (used in function to see which rows did not match template)\n",
    "\n",
    "pd.reset_option(\"max_rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiPq7zXi0STt"
   },
   "outputs": [],
   "source": [
    "# Save the new dataFrame as a .csv in the current working directory on Windows\n",
    "\n",
    "HEX.to_csv(\"WaspBusters_20210609_batch_XGBmonths_48019prodigal.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "HEX draft.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
